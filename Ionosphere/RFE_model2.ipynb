{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import optuna\n",
    "# import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "#plt.style.use('fivethirtyeight')\n",
    "import xgboost as xgb\n",
    "import sklearn\n",
    "import random\n",
    "from NecessaryModules.getData import getData\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.0, 0.0, 0.99539, -0.05889, 0.85243, 0.02306, 0.83398, -0.37708, 1.0, 0.0376, 0.85243, -0.17755, 0.59755, -0.44945, 0.60536, -0.38223, 0.84356, -0.38542, 0.58212, -0.32192, 0.56971, -0.29674, 0.36946, -0.47357, 0.56811, -0.51171, 0.41078, -0.46168, 0.21266, -0.3409, 0.42267, -0.54487, 0.18641, -0.453], [1.0, 0.0, 1.0, -0.18829, 0.93035, -0.36156, -0.10868, -0.93597, 1.0, -0.04549, 0.50874, -0.67743, 0.34432, -0.69707, -0.51685, -0.97515, 0.05499, -0.62237, 0.33109, -1.0, -0.13151, -0.453, -0.18056, -0.35734, -0.20332, -0.26569, -0.20468, -0.18401, -0.1904, -0.11593, -0.16626, -0.06288, -0.13738, -0.02447], [1.0, 0.0, 1.0, -0.03365, 1.0, 0.00485, 1.0, -0.12062, 0.88965, 0.01198, 0.73082, 0.05346, 0.85443, 0.00827, 0.54591, 0.00299, 0.83775, -0.13644, 0.75535, -0.0854, 0.70887, -0.27502, 0.43385, -0.12062, 0.57528, -0.4022, 0.58984, -0.22145, 0.431, -0.17365, 0.60436, -0.2418, 0.56045, -0.38238], [1.0, 0.0, 1.0, -0.45161, 1.0, 1.0, 0.71216, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.14516, 0.54094, -0.3933, -1.0, -0.54467, -0.69975, 1.0, 0.0, 0.0, 1.0, 0.90695, 0.51613, 1.0, 1.0, -0.20099, 0.25682, 1.0, -0.32382, 1.0], [1.0, 0.0, 1.0, -0.02401, 0.9414, 0.06531, 0.92106, -0.23255, 0.77152, -0.16399, 0.52798, -0.20275, 0.56409, -0.00712, 0.34395, -0.27457, 0.5294, -0.2178, 0.45107, -0.17813, 0.05982, -0.35575, 0.02309, -0.52879, 0.03286, -0.65158, 0.1329, -0.53206, 0.02431, -0.62197, -0.05707, -0.59573, -0.04608, -0.65697], [1.0, 0.0, 0.02337, -0.00592, -0.09924, -0.11949, -0.00763, -0.11824, 0.14706, 0.06637, 0.03786, -0.06302, 0.0, 0.0, -0.04572, -0.1554, -0.00343, -0.10196, -0.11575, -0.05414, 0.01838, 0.03669, 0.01519, 0.00888, 0.03513, -0.01535, -0.0324, 0.09223, -0.07859, 0.00732, 0.0, 0.0, -0.00039, 0.12011], [1.0, 0.0, 0.97588, -0.10602, 0.94601, -0.208, 0.92806, -0.2835, 0.85996, -0.27342, 0.79766, -0.47929, 0.78225, -0.50764, 0.74628, -0.61436, 0.57945, -0.68086, 0.37852, -0.73641, 0.36324, -0.76562, 0.31898, -0.79753, 0.22792, -0.81634, 0.13659, -0.8251, 0.04606, -0.82395, -0.04262, -0.81318, -0.13832, -0.80975], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, -1.0, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.96355, -0.07198, 1.0, -0.14333, 1.0, -0.21313, 1.0, -0.36174, 0.9257, -0.43569, 0.9451, -0.40668, 0.90392, -0.46381, 0.98305, -0.35257, 0.84537, -0.6602, 0.75346, -0.60589, 0.69637, -0.64225, 0.85106, -0.6544, 0.57577, -0.69712, 0.25435, -0.63919, 0.45114, -0.72779, 0.38895, -0.7342], [1.0, 0.0, -0.01864, -0.08459, 0.0, 0.0, 0.0, 0.0, 0.1147, -0.2681, -0.45663, -0.38172, 0.0, 0.0, -0.33656, 0.38602, -0.37133, 0.15018, 0.63728, 0.22115, 0.0, 0.0, 0.0, 0.0, -0.14803, -0.01326, 0.20645, -0.02294, 0.0, 0.0, 0.16595, 0.24086, -0.08208, 0.38065], [1.0, 0.0, 1.0, 0.06655, 1.0, -0.18388, 1.0, -0.2732, 1.0, -0.43107, 1.0, -0.41349, 0.96232, -0.51874, 0.90711, -0.59017, 0.8923, -0.66474, 0.69876, -0.70997, 0.70645, -0.7632, 0.63081, -0.80544, 0.55867, -0.89128, 0.47211, -0.865, 0.40303, -0.83675, 0.30996, -0.89093, 0.22995, -0.89158], [1.0, 0.0, 1.0, -0.5421, 1.0, -1.0, 1.0, -1.0, 1.0, 0.36217, 1.0, -0.41119, 1.0, 1.0, 1.0, -1.0, 1.0, -0.29354, 1.0, -0.93599, 1.0, 1.0, 1.0, 1.0, 1.0, -0.40888, 1.0, -0.62745, 1.0, -1.0, 1.0, -1.0, 1.0, -1.0], [1.0, 0.0, 1.0, -0.16316, 1.0, -0.10169, 0.99999, -0.15197, 1.0, -0.19277, 0.94055, -0.35151, 0.95735, -0.29785, 0.93719, -0.34412, 0.94486, -0.28106, 0.90137, -0.43383, 0.86043, -0.47308, 0.82987, -0.5122, 0.8408, -0.47137, 0.76224, -0.5837, 0.65723, -0.68794, 0.68714, -0.64537, 0.64727, -0.67226], [1.0, 0.0, 1.0, -0.86701, 1.0, 0.2228, 0.85492, -0.39896, 1.0, -0.1209, 1.0, 0.35147, 1.0, 0.07772, 1.0, -0.14767, 1.0, -1.0, 1.0, -1.0, 0.61831, 0.15803, 1.0, 0.62349, 1.0, -0.17012, 1.0, 0.35924, 1.0, -0.66494, 1.0, 0.88428, 1.0, -0.18826], [1.0, 0.0, 1.0, 0.0738, 1.0, 0.0342, 1.0, -0.05563, 1.0, 0.08764, 1.0, 0.19651, 1.0, 0.20328, 1.0, 0.12785, 1.0, 0.10561, 1.0, 0.27087, 1.0, 0.44758, 1.0, 0.4175, 1.0, 0.20033, 1.0, 0.36743, 0.95603, 0.48641, 1.0, 0.32492, 1.0, 0.46712], [1.0, 0.0, 0.50932, -0.93996, 1.0, 0.26708, -0.0352, -1.0, 1.0, -1.0, 0.43685, -1.0, 0.0, 0.0, -1.0, -0.34265, -0.37681, 0.03623, 1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -0.16253, 0.92236, 0.39752, 0.26501, 0.0, 0.0, 1.0, 0.23188, 0.0, 0.0], [1.0, 0.0, 0.99645, 0.06468, 1.0, -0.01236, 0.97811, 0.02498, 0.96112, 0.02312, 0.99274, 0.07808, 0.89323, 0.10346, 0.94212, 0.05269, 0.88809, 0.1112, 0.86104, 0.08631, 0.81633, 0.1183, 0.83668, 0.14442, 0.81329, 0.13412, 0.79476, 0.13638, 0.7911, 0.15379, 0.77122, 0.1593, 0.70941, 0.12015], [0.0, 0.0, 0.0, 0.0, -1.0, -1.0, 1.0, 1.0, -1.0, 1.0, -1.0, 1.0, 1.0, -1.0, 1.0, 1.0, -1.0, -1.0, -1.0, 1.0, 1.0, -1.0, -1.0, 1.0, -1.0, 1.0, 1.0, -1.0, -1.0, 1.0, -1.0, -1.0, 1.0, -1.0], [1.0, 0.0, 0.67065, 0.02528, 0.66626, 0.05031, 0.57197, 0.18761, 0.08776, 0.34081, 0.63621, 0.12131, 0.62099, 0.14285, 0.78637, 0.10976, 0.58373, 0.18151, 0.14395, 0.41224, 0.53888, 0.21326, 0.5142, 0.22625, 0.48838, 0.23724, 0.46167, 0.24618, 0.43433, 0.25306, 0.40663, 0.25792, 1.0, 0.33036], [0.0, 0.0, 1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, -1.0, -0.71875, 1.0, 0.0, 0.0, -1.0, 1.0, 1.0, 1.0, -1.0, 1.0, 1.0, 0.5625, -1.0, 1.0, 1.0, 1.0, 1.0, -1.0, 1.0, 1.0, 1.0, 1.0], [1.0, 0.0, 1.0, -0.00612, 1.0, -0.09834, 1.0, -0.07649, 1.0, -0.10605, 1.0, -0.11073, 1.0, -0.39489, 1.0, -0.15616, 0.92124, -0.31884, 0.86473, -0.34534, 0.91693, -0.44072, 0.9606, -0.46866, 0.81874, -0.40372, 0.82681, -0.42231, 0.75784, -0.38231, 0.80448, -0.40575, 0.74354, -0.45039], [0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, 1.0, -1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, -1.0, -1.0, 1.0, -1.0, 1.0, -1.0, 1.0], [1.0, 0.0, 0.96071, 0.07088, 1.0, 0.04296, 1.0, 0.09313, 0.90169, -0.05144, 0.89263, 0.0258, 0.8325, -0.06142, 0.87534, 0.09831, 0.76544, 0.0028, 0.75206, -0.05295, 0.65961, -0.07905, 0.64158, -0.05929, 0.55677, -0.07705, 0.58051, -0.02205, 0.49664, -0.01251, 0.5131, -0.00015, 0.52099, -0.00182], [0.0, 0.0, -1.0, 1.0, 0.0, 0.0, 0.0, 0.0, -1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, -1.0, -1.0, 1.0, 1.0, 1.0, 0.0, 0.0, -1.0, -1.0, 1.0, -1.0, 1.0, 1.0, -1.0, 1.0, 0.0, 0.0], [1.0, 0.0, 1.0, -0.06182, 1.0, 0.02942, 1.0, -0.05131, 1.0, -0.01707, 1.0, -0.11726, 0.84493, -0.05202, 0.93392, -0.06598, 0.6917, -0.07379, 0.65731, -0.20367, 0.9491, -0.31558, 0.80852, -0.31654, 0.84932, -0.34838, 0.72529, -0.29174, 0.73094, -0.38576, 0.54356, -0.26284, 0.64207, -0.39487], [1.0, 0.0, 1.0, 0.5782, 1.0, -1.0, 1.0, -1.0, 1.0, -1.0, 1.0, -1.0, 1.0, -1.0, 1.0, -1.0, 1.0, -1.0, 1.0, -1.0, 1.0, -0.62796, 1.0, -1.0, 1.0, -1.0, 1.0, -1.0, 1.0, -1.0, 1.0, -1.0, 1.0, -1.0], [1.0, 0.0, 1.0, -0.08714, 1.0, -0.17263, 0.86635, -0.81779, 0.94817, 0.61053, 0.95473, -0.41382, 0.88486, -0.31736, 0.87937, -0.23433, 0.81051, -0.6218, 0.12245, -1.0, 0.90284, 0.11053, 0.62357, -0.78547, 0.55389, -0.82868, 0.48136, -0.86583, 0.4065, -0.89674, 0.32984, -0.92128, -0.13341, -1.0], [0.0, 0.0, -1.0, -1.0, 0.0, 0.0, -1.0, 1.0, 1.0, -0.375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, -1.0, -1.0, -1.0, 1.0, -1.0, 0.0, 0.0, 1.0, -1.0, -1.0, 1.0, -1.0, -1.0, 0.0, 0.0, -1.0, 1.0], [1.0, 0.0, 1.0, 0.0838, 1.0, 0.17387, 1.0, -0.13308, 0.98172, 0.6452, 1.0, 0.47904, 1.0, 0.59113, 1.0, 0.70758, 1.0, 0.82777, 1.0, 0.95099, 1.0, 1.0, 0.98042, 1.0, 0.91624, 1.0, 0.83899, 1.0, 0.74822, 1.0, 0.64358, 1.0, 0.52479, 1.0], [0.0, 0.0, -1.0, -1.0, 1.0, 1.0, 1.0, -1.0, -1.0, 1.0, 1.0, -1.0, -1.0, -1.0, 0.0, 0.0, 1.0, 1.0, -1.0, -1.0, 1.0, -1.0, 1.0, -1.0, 1.0, 1.0, 1.0, -1.0, 1.0, -1.0, -1.0, 1.0, 1.0, -1.0], [1.0, 0.0, 1.0, -0.14236, 1.0, -0.16256, 1.0, -0.23656, 1.0, -0.07514, 1.0, -0.2501, 1.0, -0.26161, 1.0, -0.21975, 1.0, -0.38606, 1.0, -0.46162, 1.0, -0.35519, 1.0, -0.59661, 1.0, -0.47643, 0.9882, -0.49687, 1.0, -0.7582, 1.0, -0.75761, 1.0, -0.84437], [1.0, 0.0, 1.0, -1.0, 1.0, 1.0, 1.0, -1.0, 1.0, -1.0, 1.0, -1.0, 1.0, -0.0184, 1.0, -1.0, 1.0, 1.0, 1.0, -0.85583, 1.0, 1.0, 1.0, -1.0, 0.0, 0.0, 1.0, 1.0, 1.0, -0.79141, 1.0, 1.0, 1.0, 1.0], [1.0, 0.0, 0.88208, -0.14639, 0.93408, -0.11057, 0.921, -0.1645, 0.88307, -0.17036, 0.88462, -0.31809, 0.85269, -0.31463, 0.82116, -0.35924, 0.80681, -0.33632, 0.75243, -0.47022, 0.70555, -0.47153, 0.6615, -0.50085, 0.61297, -0.48086, 0.56804, -0.54629, 0.50179, -0.59854, 0.47075, -0.57377, 0.42189, -0.58086], [1.0, 0.0, 0.71253, -0.02595, 0.41287, -0.23067, 0.98019, -0.09473, 0.99709, -0.10236, 1.0, -0.10951, 0.58965, 1.0, 0.83726, -1.0, 0.8227, -0.17863, 0.8076, -0.28257, -0.25914, 0.9273, 0.51933, 0.05456, 0.65493, -0.20392, 0.93124, -0.41307, 0.63811, -0.21901, 0.86136, -0.87354, -0.23186, -1.0], [1.0, 0.0, 1.0, -0.15899, 0.72314, 0.27686, 0.83443, -0.58388, 1.0, -0.28207, 1.0, -0.49863, 0.79962, -0.12527, 0.76837, 0.14638, 1.0, 0.39337, 1.0, 0.2659, 0.96354, -0.01891, 0.92599, -0.91338, 1.0, 0.14803, 1.0, -0.11582, 1.0, -0.11129, 1.0, 0.53372, 1.0, -0.57758], [1.0, 0.0, 0.66161, -1.0, 1.0, 1.0, 1.0, -0.67321, 0.80893, -0.40446, 1.0, -1.0, 1.0, -0.89375, 1.0, 0.73393, 0.17589, 0.70982, 1.0, 0.78036, 1.0, 0.85268, 1.0, -1.0, 1.0, 0.85357, 1.0, -0.08571, 0.95982, -0.3625, 1.0, 0.65268, 1.0, 0.34732], [1.0, 0.0, 1.0, 0.00433, 1.0, -0.01209, 1.0, -0.0296, 1.0, -0.07014, 0.97839, -0.06256, 1.0, -0.06544, 0.97261, -0.07917, 0.92561, -0.13665, 0.94184, -0.14327, 0.99589, -0.14248, 0.94815, -0.13565, 0.89469, -0.20851, 0.89067, -0.17909, 0.85644, -0.18552, 0.83777, -0.20101, 0.83867, -0.20766], [0.0, 0.0, 1.0, 1.0, 1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, 1.0, 1.0, 1.0, -1.0, 1.0, -1.0, 1.0, 1.0, -1.0, 1.0, 1.0, -1.0, 1.0, 1.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.91241, 0.04347, 0.94191, 0.0228, 0.94705, 0.05345, 0.93582, 0.01321, 0.91911, 0.06348, 0.92766, 0.12067, 0.92048, 0.06211, 0.88899, 0.12722, 0.83744, 0.14439, 0.80983, 0.11849, 0.77041, 0.14222, 0.75755, 0.11299, 0.7355, 0.13282, 0.66387, 0.153, 0.70925, 0.10754, 0.65258, 0.11447], [1.0, 0.0, 1.0, 0.02461, 0.99672, 0.04861, 0.97545, 0.07143, 0.61745, -1.0, 0.91036, 0.11147, 0.88462, 0.5364, 0.82077, 0.14137, 0.76929, 0.15189, 1.0, 0.41003, 0.6585, 0.16371, 0.60138, 0.16516, 0.54446, 0.1639, 0.48867, 0.16019, 0.43481, 0.15436, 0.38352, 0.14677, 1.0, 1.0], [1.0, 0.0, 1.0, 0.06538, 1.0, 0.20746, 1.0, 0.26281, 0.93051, 0.32213, 0.86773, 0.39039, 0.75474, 0.50082, 0.79555, 0.52321, 0.65954, 0.60756, 0.57619, 0.62999, 0.47807, 0.67135, 0.40553, 0.6884, 0.34384, 0.72082, 0.27712, 0.72386, 0.19296, 0.70682, 0.11372, 0.72688, 0.0699, 0.71444], [1.0, 0.0, -1.0, -1.0, 1.0, 1.0, 1.0, -0.14375, 0.0, 0.0, -1.0, 1.0, 1.0, 1.0, 0.17917, -1.0, -1.0, -1.0, 0.0875, -1.0, 1.0, -1.0, -1.0, 1.0, -1.0, -1.0, 1.0, -1.0, -1.0, -1.0, 1.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.90932, 0.08791, 0.86528, 0.16888, 1.0, 0.16598, 0.55187, 0.68154, 0.70207, 0.36719, 0.16286, 0.42739, 0.5762, 0.46086, 0.51067, 0.49618, 0.31639, 0.12967, 0.37824, 0.54462, 0.31274, 0.55826, 0.24856, 0.56527, 0.18626, 0.56605, 0.12635, 0.56101, 0.06927, 0.55061, 0.12137, 0.67739], [1.0, 0.0, -0.64286, -1.0, 1.0, 0.82857, 1.0, -1.0, 1.0, -0.23393, 1.0, 0.96161, 1.0, -0.37679, 1.0, -1.0, 1.0, 0.13839, 1.0, -1.0, 1.0, -0.03393, -0.84286, 1.0, 0.5375, 0.85714, 1.0, 1.0, 1.0, -1.0, 1.0, -1.0, 1.0, -1.0], [1.0, 0.0, 0.99025, -0.05785, 0.99793, -0.13009, 0.98663, -0.1943, 0.99374, -0.25843, 0.92738, -0.3013, 0.92651, -0.37965, 0.89812, -0.43796, 0.84922, -0.52064, 0.87433, -0.57075, 0.79016, -0.59839, 0.74725, -0.64615, 0.68282, -0.68479, 0.65247, -0.73174, 0.6101, -0.75353, 0.54752, -0.80278, 0.49195, -0.83245], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, -0.375, -1.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, 1.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 1.0, -0.0373, 1.0, -0.07383, 0.99601, -0.11039, 0.99838, -0.09931, 0.98941, -0.13814, 0.96674, -0.21695, 0.95288, -0.25099, 0.91236, -0.344, 0.90581, -0.32152, 0.89991, -0.34691, 0.87874, -0.37643, 0.86213, -0.4299, 0.83172, -0.43122, 0.81433, -0.42593, 0.77919, -0.47977, 0.75115, -0.50152], [1.0, 0.0, 0.94598, -0.02685, -1.0, 0.26131, -0.36393, 0.35639, 0.69258, -0.63427, 1.0, -0.03353, -0.2902, -0.0055, -0.54852, 0.15452, 0.91921, -0.4627, 1.0, -0.50424, -0.29735, -0.31454, -0.73864, 0.37361, 0.83872, -0.46734, 0.52208, -0.5813, 1.0, -0.61393, -0.09634, 0.20477, -0.06117, 0.41913], [1.0, 0.0, 0.98166, 0.00874, 0.98103, -0.03818, 0.97565, -0.05699, 0.95947, -0.06971, 0.99004, -0.04507, 0.94713, -0.11102, 0.93369, -0.1279, 0.94217, -0.11583, 0.79682, -0.192, 0.88274, -0.17387, 0.86257, -0.18739, 0.88487, -0.19689, 0.81813, -0.21136, 0.78546, -0.23864, 0.76911, -0.23095, 0.74323, -0.23902], [1.0, 0.0, 0.0, 0.0, 1.0, 0.51724, 0.0, 0.0, 0.10991, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, -0.22414, -0.55711, -0.83297, 0.7694, 0.63147, 0.0, 0.0, 0.53448, 0.35668, -0.90302, 0.44828, 1.0, -1.0, -1.0, 0.81573, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.84134, -0.18362, 0.43644, 0.02919, 0.93421, -0.00267, 0.87947, 0.13795, 0.81121, -0.01789, 0.88559, 0.54991, 0.91714, -0.57486, 0.75, -0.2952, 0.86676, -0.20104, 1.0, 1.0, 0.4661, -0.1629, 0.90066, -0.02778, 0.93358, -0.01158, 0.61582, -0.32298, 0.84463, -0.25706, 0.93323, -0.01425], [0.0, 0.0, 1.0, 1.0, 1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, -1.0, -1.0, 1.0, -1.0, -1.0, 1.0, 0.0, 0.0, 1.0, -1.0, 1.0, -1.0, 1.0, 1.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.9101, 1.0, -0.2697, 1.0, -0.83152, 1.0, -1.0, 1.0, -1.0, 0.72526, -1.0, -0.57779, -1.0, -0.42052, -1.0, -1.0, -0.52838, -1.0, 0.90014, -1.0, 1.0, -1.0, 1.0, -1.0, 1.0, -0.34686, 1.0, 0.34845], [1.0, 0.0, -0.67935, -1.0, -1.0, 1.0, 1.0, 0.63317, 0.03515, -1.0, -1.0, -1.0, 1.0, 1.0, 0.88683, -1.0, -1.0, 1.0, 0.8384, 1.0, 1.0, -1.0, -1.0, -1.0, -0.18856, 1.0, 1.0, -1.0, -1.0, -1.0, -1.0, 1.0, 1.0, 0.33611], [1.0, 0.0, 0.95659, 0.08143, 0.97487, -0.05667, 0.97165, -0.08484, 0.96097, -0.06561, 0.94717, 0.01279, 0.95436, -0.16795, 0.94612, -0.19497, 0.9963, -0.32268, 0.90343, -0.35902, 0.91428, -0.27316, 0.9014, -0.29807, 0.99899, -0.40747, 0.87244, -0.34586, 0.92059, -0.30619, 0.83951, -0.39061, 0.82166, -0.41173], [1.0, 0.0, 0.08333, -0.20685, -1.0, 1.0, -1.0, 1.0, 0.71875, 0.47173, -0.82143, -0.62723, -1.0, -1.0, -1.0, 1.0, -0.02753, 0.59152, -0.42113, -0.42113, -0.74628, -1.0, -1.0, -0.46801, -1.0, 0.2381, 1.0, -1.0, -1.0, -0.38914, -1.0, -1.0, -1.0, 0.61458], [1.0, 0.0, 1.0, -0.02259, 1.0, -0.04494, 1.0, -0.06682, 1.0, -0.08799, 1.0, 0.56173, 1.0, -0.12738, 1.0, -0.14522, 1.0, 0.32407, 1.0, -0.17639, 0.99484, -0.18949, 0.95601, -0.20081, 1.0, -0.92284, 0.8728, -0.21793, 0.8292, -0.2237, 0.78479, -0.22765, 0.73992, -0.22981], [0.0, 0.0, -1.0, 1.0, 1.0, -1.0, -1.0, 1.0, 0.0, 0.0, 1.0, 1.0, -1.0, -0.1875, 1.0, 1.0, -1.0, -1.0, 1.0, -1.0, -1.0, -1.0, 1.0, 1.0, 1.0, -1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, -1.0, -1.0], [1.0, 0.0, 1.0, 0.05812, 0.94525, 0.07418, 0.99952, 0.13231, 1.0, -0.01911, 0.94846, 0.07033, 0.95713, 0.14644, 0.94862, 0.11224, 0.90896, 0.20119, 0.96741, 0.16265, 0.99695, 0.14258, 0.90784, 0.1641, 0.91667, 0.22431, 0.88423, 0.23571, 0.88568, 0.22511, 0.78324, 0.29576, 0.83574, 0.31166], [1.0, 0.0, 0.17188, -1.0, -1.0, 1.0, 0.0, 0.0, 0.0, 0.0, -1.0, 1.0, 0.0, 0.0, -0.61354, -0.67708, 0.80521, 0.36146, 0.51979, 0.14375, 0.0, 0.0, -1.0, -0.27083, -0.84792, 0.9625, 1.0, 1.0, -1.0, 0.67708, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 1.0, 0.09771, 1.0, 0.12197, 1.0, 0.22574, 0.98602, 0.09237, 0.9493, 0.19211, 0.92992, 0.24288, 0.89241, 0.28343, 0.85529, 0.26721, 0.83656, 0.33129, 0.83393, 0.31698, 0.74829, 0.39597, 0.76193, 0.34658, 0.68452, 0.42746, 0.62764, 0.46031, 0.56791, 0.47033, 0.54252, 0.50903], [1.0, 0.0, 0.01667, -0.35625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12292, -0.55, 0.22813, 0.82813, 1.0, -0.42292, 0.0, 0.0, 0.08333, -1.0, -0.10625, -0.16667, 1.0, -0.76667, -1.0, 0.18854, 0.0, 0.0, 1.0, -0.27292], [1.0, 0.0, 1.0, 0.16801, 0.99352, 0.16334, 0.94616, 0.33347, 0.91759, 0.2261, 0.91408, 0.37107, 0.8425, 0.46899, 0.81011, 0.49225, 0.78473, 0.48311, 0.65091, 0.56977, 0.56553, 0.58071, 0.55586, 0.6472, 0.48311, 0.55236, 0.43317, 0.69129, 0.35684, 0.76147, 0.33921, 0.66844, 0.22101, 0.78685], [1.0, 0.0, 0.63816, 1.0, 0.20833, -1.0, 1.0, 1.0, 0.87719, 0.30921, -0.66886, 1.0, -0.05921, 0.58772, 0.01754, 0.05044, -0.51535, -1.0, 0.14254, -0.03289, 0.32675, -0.4386, -1.0, 1.0, 0.80921, -1.0, 1.0, -0.0614, 1.0, 1.0, 0.20614, -1.0, 1.0, 1.0], [1.0, 0.0, 1.0, -0.41457, 1.0, 0.76131, 0.8706, 0.18593, 1.0, -0.09925, 0.93844, 0.4799, 0.65452, -0.1608, 1.0, 0.00879, 0.97613, -0.50126, 0.80025, -0.24497, 0.88065, -0.19095, 1.0, -0.12312, 0.93593, 0.10678, 0.9289, -0.07249, 1.0, -0.27387, 0.4397, 0.19849, 0.51382, -0.05402], [1.0, 0.0, 0.84783, 0.10598, 1.0, 0.3913, 1.0, -1.0, 0.66938, 0.08424, 1.0, 0.27038, 1.0, 0.60598, 1.0, 0.35507, 1.0, 0.02672, 0.58424, -0.43025, 1.0, 0.63496, 0.8913, 0.26585, 0.91033, -0.33333, 1.0, 0.15942, 0.37681, -0.01947, 1.0, 0.22464, 1.0, 0.37409], [1.0, 0.0, 1.0, 0.28046, 1.0, 0.02477, 1.0, 0.07764, 1.0, 0.04317, 0.98762, 0.33266, 1.0, 0.05489, 1.0, 0.04384, 0.9575, -0.24598, 0.84371, -0.08668, 1.0, 0.0415, 0.99933, 0.27376, 1.0, -0.39056, 0.96414, -0.02174, 0.86747, 0.2336, 0.94578, -0.22021, 0.80355, -0.07329], [0.0, 0.0, 1.0, -1.0, 1.0, -1.0, 1.0, -1.0, 1.0, -1.0, 1.0, 1.0, 1.0, 1.0, 1.0, -1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, -1.0, 1.0, -1.0, 1.0, -1.0, 1.0, 0.65625, 0.0, 0.0, 1.0, -1.0], [1.0, 0.0, 1.0, 0.67784, 0.81309, 0.82021, 0.43019, 1.0, 0.20619, 0.80541, -0.43872, 1.0, -0.79135, 0.77092, -1.0, 0.40268, -0.39046, -0.58634, -0.97907, -0.42822, -0.73083, -0.76339, -0.37671, -0.97491, 0.41366, -1.0, 0.41778, -0.93296, 0.25773, -1.0, 0.9357, -0.35222, 0.98816, 0.03446], [1.0, 0.0, 1.0, 1.0, 1.0, -1.0, 1.0, -1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, -1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.0, 0.0, 1.0, -1.0, 1.0, -1.0], [1.0, 0.0, 1.0, 0.03529, 1.0, 0.18281, 1.0, 0.26968, 1.0, 0.25068, 1.0, 0.28778, 1.0, 0.38643, 1.0, 0.31674, 1.0, 0.65701, 1.0, 0.53846, 1.0, 0.61267, 1.0, 0.59457, 0.89593, 0.68326, 0.89502, 0.71374, 0.85611, 0.67149, 0.74389, 0.85611, 0.71493, 0.75837], [0.0, 0.0, 1.0, -1.0, 1.0, 1.0, -1.0, -1.0, 1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, 1.0, 1.0, -1.0, 1.0, -1.0, -0.75, 1.0, 1.0, -1.0, 1.0, -1.0, 1.0, -1.0, -1.0, -1.0, 0.0, 0.0, 1.0, -1.0], [1.0, 0.0, 0.96087, 0.0862, 0.9676, 0.19279, 0.96026, 0.27451, 0.98044, 0.35052, 0.92867, 0.46281, 0.86265, 0.52517, 0.8282, 0.58794, 0.73242, 0.69065, 0.69003, 0.7314, 0.54473, 0.6882, 0.48339, 0.76197, 0.40615, 0.74689, 0.33401, 0.83796, 0.24944, 0.86061, 0.13756, 0.86835, 0.09048, 0.86285], [1.0, 0.0, 0.69444, 0.38889, 0.0, 0.0, -0.32937, 0.69841, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.20635, -0.24206, 0.21032, 0.19444, 0.46429, 0.78175, 0.0, 0.0, 0.0, 0.0, 0.73413, 0.27381, 0.7619, 0.63492, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 1.0, 0.0507, 1.0, 0.10827, 1.0, 0.19498, 1.0, 0.28453, 1.0, 0.34826, 1.0, 0.38261, 0.94575, 0.42881, 0.89126, 0.50391, 0.75906, 0.58801, 0.80644, 0.59962, 0.79578, 0.62758, 0.66643, 0.63942, 0.59417, 0.69435, 0.49538, 0.72684, 0.47027, 0.71689, 0.33381, 0.75243], [0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, -1.0, 1.0, -1.0, 1.0, 1.0, 1.0, 1.0, 1.0, -1.0, 1.0, 1.0, 1.0, 1.0, 1.0, -1.0, -1.0, -1.0, 1.0, -1.0, 1.0, -1.0, 1.0, 1.0, 0.0, 0.0, 1.0, -1.0], [1.0, 0.0, 1.0, 0.04078, 1.0, 0.11982, 1.0, 0.16159, 1.0, 0.27921, 0.98703, 0.30889, 0.92745, 0.37639, 0.91118, 0.39749, 0.81939, 0.46059, 0.78619, 0.46994, 0.794, 0.56282, 0.70331, 0.58129, 0.67077, 0.59723, 0.58903, 0.6099, 0.53952, 0.60932, 0.45312, 0.63636, 0.40442, 0.62658], [0.0, 0.0, 1.0, 1.0, 1.0, -1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, -1.0, -1.0, 1.0, -1.0, 1.0, -1.0, 1.0, 1.0, -1.0, 1.0, 1.0, -1.0, 1.0, -1.0, -1.0, -1.0, 1.0], [1.0, 0.0, 1.0, 0.24168, 1.0, 0.4859, 1.0, 0.72973, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.77128, 1.0, 1.0, 1.0, 1.0, 0.74468, 1.0, 0.89647, 1.0, 0.64628, 1.0, 0.38255, 1.0, 0.10819, 1.0, -0.1737, 1.0, -0.81383, 1.0], [0.0, 0.0, 1.0, 1.0, 1.0, -1.0, 1.0, 1.0, -1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, -1.0, 1.0, -1.0, 1.0, 1.0, 1.0, 1.0, -1.0, 1.0, 1.0, 1.0, 1.0, 1.0, -1.0, -1.0, 1.0], [1.0, 0.0, 1.0, -0.06604, 1.0, 0.62937, 1.0, 0.09557, 1.0, 0.2028, 1.0, -1.0, 1.0, -0.40559, 1.0, -0.15851, 1.0, 0.04895, 1.0, -0.61538, 1.0, -0.26573, 1.0, -1.0, 1.0, -0.58042, 1.0, -0.81372, 1.0, -1.0, 1.0, -0.78555, 1.0, -0.48252], [0.0, 0.0, 1.0, -1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, -1.0, 1.0, -1.0, 1.0, 1.0, 1.0, -1.0, 1.0, 1.0, 1.0, 1.0, 1.0, -1.0, 1.0, 1.0, 1.0, -1.0, 1.0, 1.0, 1.0, -1.0], [1.0, 0.0, 0.92277, 0.07804, 0.92679, 0.16251, 0.89702, 0.24618, 0.84111, 0.35197, 0.78801, 0.42196, 0.70716, 0.46983, 0.70796, 0.56476, 0.60459, 0.642, 0.51247, 0.64924, 0.39903, 0.66975, 0.34232, 0.68343, 0.23693, 0.76146, 0.18765, 0.73885, 0.09694, 0.71038, 0.02735, 0.77072, -0.04023, 0.69509], [1.0, 0.0, 0.68198, -0.17314, 0.82332, 0.21908, 0.46643, 0.32862, 0.25795, 0.58304, 1.0, -0.15194, 0.0106, 0.44523, 0.0106, 0.38869, 0.18681, 0.41168, 0.10567, 0.36353, 0.04325, 0.30745, -0.00083, 0.24936, -0.02862, 0.19405, -0.04314, 0.14481, -0.04779, 0.10349, -0.04585, 0.07064, -0.04013, 0.04586], [1.0, 0.0, 0.74852, -0.02811, 0.6568, -0.05178, 0.80621, 0.02811, 0.85947, 0.02515, 0.63462, 0.08728, 0.71598, 0.0784, 0.73077, 0.05178, 0.7855, -0.27811, 0.65976, -0.01479, 0.78698, 0.06953, 0.34615, -0.18639, 0.65385, 0.02811, 0.61009, -0.06637, 0.5355, -0.21154, 0.59024, -0.14053, 0.56361, 0.02959], [1.0, 0.0, 0.39179, -0.06343, 0.97464, 0.04328, 1.0, 1.0, 0.35821, 0.15299, 0.54478, 0.1306, 0.61567, -0.8209, 0.57836, 0.6791, 0.66791, -0.10448, 0.46642, -0.11567, 0.65574, 0.14792, 0.83209, 0.45522, 0.47015, 0.16418, 0.49309, 0.1463, 0.32463, -0.02612, 0.39118, 0.13521, 0.34411, 0.12755], [1.0, 0.0, 0.67547, 0.04528, 0.76981, -0.10566, 0.77358, 0.03774, 0.66038, -0.04528, 0.64528, 0.01132, 0.66792, -0.13962, 0.72075, -0.02264, 0.76981, 0.08679, 0.61887, -0.07925, 0.75849, -0.23774, 0.73962, -0.14717, 0.84906, -0.15094, 0.73886, -0.05801, 0.66792, 0.02264, 0.86415, 0.03774, 0.73208, 0.00755], [1.0, 0.0, 0.72727, -0.05, 0.89241, 0.03462, 1.0, 0.72727, 0.66364, -0.05909, 0.48182, -0.16818, 0.81809, 0.09559, 0.56818, 1.0, 0.50455, 0.21818, 0.66818, 0.1, 1.0, -0.3, 0.98636, -1.0, 0.57273, 0.32727, 0.56982, 0.14673, 0.42273, 0.08182, 0.48927, 0.14643, 1.0, 1.0], [1.0, 0.0, 0.57647, -0.01569, 0.40392, 0.0, 0.38431, 0.12941, 0.4, -0.05882, 0.56471, 0.14118, 0.46667, 0.08235, 0.52549, -0.0549, 0.58039, 0.01569, 0.50196, 0.0, 0.45882, 0.06667, 0.58039, 0.08235, 0.49804, 0.00392, 0.48601, 0.10039, 0.46275, 0.08235, 0.45098, 0.23529, 0.43137, 0.17255], [1.0, 0.0, 0.41932, 0.12482, 0.35, 0.125, 0.23182, 0.27955, -0.03636, 0.44318, 0.04517, 0.36194, -0.19091, 0.33636, -0.1335, 0.27322, 0.02727, 0.40455, -0.34773, 0.12727, -0.20028, 0.05078, -0.18636, 0.36364, -0.14003, -0.04802, -0.09971, -0.07114, -1.0, -1.0, -0.02916, -0.07464, -0.00526, -0.06314], [1.0, 0.0, 0.88305, -0.21996, 1.0, 0.36373, 0.82403, 0.19206, 0.85086, 0.05901, 0.90558, -0.04292, 0.85193, 0.25, 0.77897, 0.25322, 0.69206, 0.5794, 0.7103, 0.39056, 0.73176, 0.27575, 1.0, 0.34871, 0.5676, 0.52039, 0.69811, 0.53235, 0.80901, 0.58584, 0.43026, 0.70923, 0.52361, 0.54185], [1.0, 0.0, 0.84557, -0.0858, -0.31745, -0.80553, -0.08961, -0.56435, 0.80648, 0.04576, 0.89514, -0.00763, -0.18494, 0.63966, -0.20019, -0.68065, 0.85701, -0.11344, 0.77979, -0.15729, -0.06959, 0.5081, -0.34128, 0.80934, 0.78932, -0.03718, 0.70882, -0.25288, 0.77884, -0.14109, -0.21354, -0.7817, -0.18494, -0.59867], [1.0, 0.0, 0.7087, -0.24783, 0.64348, 0.04348, 0.45217, 0.38261, 0.65217, 0.18261, 0.5, 0.26957, 0.57826, -0.23043, 0.50435, 0.37826, 0.38696, -0.42609, 0.36087, -0.26087, 0.26957, 0.11739, 0.53246, -0.03845, 0.31304, -0.12174, 0.4993, -0.04264, 0.48348, -0.04448, 0.64348, -0.25217, 0.50435, 0.14783], [1.0, 0.0, -0.5418, 0.14861, -0.33746, 0.73375, 0.52012, -0.13932, 0.31889, -0.06811, 0.20743, -0.1517, 0.47368, 0.08978, 0.56347, -0.1548, 0.16409, 0.45201, 0.33746, 0.03406, 0.50464, 0.07121, -0.63777, -0.6161, 1.0, 0.65635, 0.41348, -0.40116, -0.1517, 0.11146, 0.02399, 0.5582, 0.52632, -0.08978], [1.0, 0.0, 0.29202, 0.13582, 0.45331, 0.16808, 0.51783, -0.00509, 0.52632, 0.20883, 0.52462, -0.16638, 0.47368, -0.04754, 0.55518, 0.03905, 0.81664, -0.22411, 0.42445, -0.04244, 0.34975, 0.06621, 0.28183, -0.20883, 0.51731, -0.03176, 0.50369, -0.03351, 0.34635, 0.09847, 0.70798, -0.01868, 0.39559, -0.03226], [1.0, 0.0, 0.79157, 0.16851, 0.0, 0.0, 0.56541, 0.06874, 0.39468, 1.0, 0.38359, 0.99557, -0.02439, 0.53215, 0.23725, 0.1286, -0.02661, 0.95122, -0.50998, 0.84922, -0.102, 0.38803, -0.42572, 0.23725, -0.91574, 0.8071, -0.34146, 0.88248, -1.0, 0.69401, -1.0, 0.1286, 0.0, 0.0], [1.0, 0.0, 0.90116, 0.16607, 0.79299, 0.37379, 0.7299, 0.50515, 0.59784, 0.72997, 0.44303, 0.81152, 0.24412, 0.87493, 0.06438, 0.85038, -0.12611, 0.87396, -0.28739, 0.79617, -0.46635, 0.65924, -0.57135, 0.53805, -0.68159, 0.39951, -0.71844, 0.25835, -0.72369, 0.11218, -0.71475, -0.05525, -0.67699, -0.19904], [1.0, 0.0, 0.97714, 0.19049, 0.82683, 0.46259, 0.71771, 0.58732, 0.47968, 0.84278, 0.31409, 0.92643, 0.10289, 0.93945, -0.13254, 0.8429, -0.3202, 0.91624, -0.52145, 0.79525, -0.68274, 0.49508, -0.77408, 0.33537, -0.85376, 0.17849, -0.83314, -0.01358, -0.82366, -0.19321, -0.67289, -0.33662, -0.59943, -0.497], [1.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.50814, -0.78502, 0.60586, 0.32899, -1.0, -0.41368, 0.0, 0.0, 0.0, 0.0, 1.0, -0.2671, 0.36482, -0.63518, 0.97068, -1.0, -1.0, -1.0, 1.0, -0.59609, -1.0, -1.0, -1.0, -1.0, 1.0, -1.0, 0.0, 0.0], [1.0, 0.0, 0.74084, 0.04974, 0.79074, 0.02543, 0.78575, 0.03793, 0.6623, 0.09948, 0.67801, 0.31152, 0.75934, 0.07348, 0.74695, 0.08442, 0.70681, -0.07853, 0.63613, 0.0, 0.70021, 0.11355, 0.68183, 0.12185, 0.67016, 0.15445, 0.64158, 0.13608, 0.65707, 0.17539, 0.59759, 0.14697, 0.57455, 0.15114], [1.0, 0.0, 1.0, -1.0, 0.0, 0.0, 0.77941, -0.99265, 0.80882, 0.55147, -0.41912, -0.94853, 0.0, 0.0, 0.0, 0.0, 0.72059, -0.77206, 0.73529, -0.60294, 0.0, 0.0, 0.18382, -1.0, -1.0, -1.0, -1.0, -1.0, 1.0, -1.0, 1.0, -1.0, 0.0, 0.0], [1.0, 0.0, 1.0, 0.01709, 0.96215, -0.03142, 1.0, -0.03436, 1.0, -0.05071, 0.99026, -0.07092, 0.99173, -0.09002, 1.0, -0.15727, 1.0, -0.14257, 0.9831, -0.11813, 1.0, -0.18519, 1.0, -0.19272, 0.98971, -0.22083, 0.9649, -0.20243, 0.94599, -0.17123, 0.96436, -0.22561, 0.87011, -0.23296], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.95704, -0.12095, 0.63318, -0.1269, 0.96365, -0.18242, 0.97026, 0.0846, 0.92003, -0.01124, 0.83543, -0.24719, 1.0, -0.31395, 0.99273, -0.21216, 0.98678, -0.21018, 1.0, -0.27165, 0.93126, -0.39458, 1.0, -0.19233, 0.88793, -0.31565, 0.81428, -0.23728, 0.89095, -0.31857, 0.69531, -0.41573], [1.0, 0.0, 0.28409, -0.31818, 0.0, 0.0, 0.68182, -1.0, 0.30682, 0.95833, 0.64394, 0.06439, 0.34848, -0.84848, 0.0, 0.0, 0.59091, -0.35985, 0.45076, -0.80682, 0.0, 0.0, 0.0, 0.0, 0.24242, 0.17803, 1.0, -0.23864, 0.06061, -0.48485, 0.16288, -0.70076, 0.0, 0.0], [1.0, 0.0, 0.9449, -0.49311, 1.0, -0.03692, 0.98898, -0.87052, 0.90083, 0.66942, 1.0, -0.10104, 1.0, -0.12493, 1.0, -0.15017, 1.0, -0.17681, 1.0, -0.20491, 1.0, -0.23452, 1.0, -0.26571, 1.0, -0.29852, 1.0, -0.33304, 1.0, -0.36931, 1.0, -0.4074, 1.0, -0.44739], [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.62195, 1.0, 0.0, 0.0, 0.0, 0.0, 0.36585, -0.71951, 0.56098, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.10976, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.99449, 0.00526, 0.84082, -0.11313, 0.88237, -0.16431, 0.99061, -0.06257, 0.96484, -0.07496, 0.85221, 0.02966, 0.87161, -0.20848, 0.93881, -0.12977, 0.98298, -0.08935, 0.89876, 0.00075, 0.87836, -0.05882, 0.93368, -0.19872, 0.87579, -0.17806, 0.94294, -0.16581, 0.80253, -0.25741, 0.76586, -0.27794], [1.0, 0.0, 0.10135, 0.10811, 0.0, 0.0, 0.0, 0.0, 0.5473, 0.82432, 0.31081, 1.0, 0.0, 0.0, 0.0, 0.0, 0.37162, -1.0, 0.33108, -1.0, 0.0, 0.0, 0.0, 0.0, -0.42568, -1.0, 1.0, -1.0, 0.55405, -0.23649, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 1.0, -0.57224, 0.9915, -0.73371, 0.89518, -0.9745, 1.0, -0.35818, 1.0, -0.23229, 0.6289, -0.86402, 1.0, -0.57535, 1.0, -0.79603, 0.76771, -0.88952, 0.96601, -1.0, 0.7012, -0.74896, 0.61946, -0.76904, 0.53777, -0.77986, 0.8102, -1.0, 1.0, -1.0, 0.30445, -0.76112], [1.0, 0.0, 0.65909, -0.62879, 0.0, 0.0, 0.0, 0.0, 0.77273, 1.0, 1.0, -0.2803, 0.0, 0.0, 0.0, 0.0, 0.62121, -0.22727, 0.84091, -1.0, 1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 1.0, -0.93939, -0.12879, -0.93182, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.86284, 0.1931, 0.8092, 0.41149, 0.67203, 0.55785, 0.54559, 0.69962, 0.36705, 0.81533, 0.19617, 0.85671, -0.04061, 0.86284, -0.17241, 0.75785, -0.341, 0.65747, -0.48199, 0.56092, -0.6023, 0.40996, -0.59234, 0.25747, -0.63038, 0.08818, -0.57241, -0.07816, -0.54866, -0.19923, -0.42912, -0.31954], [1.0, 0.0, 0.42, -0.61, 0.0, 0.0, 1.0, -1.0, 0.9, 1.0, 0.43, 0.64, 0.0, 0.0, 0.0, 0.0, 0.67, -0.29, 0.84, -1.0, 0.0, 0.0, 0.0, 0.0, 0.21, 0.68, 1.0, 0.22, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 1.0, 0.23395, 0.91404, 0.52013, 0.7802, 0.72144, 0.4766, 0.84222, 0.27639, 0.9173, 0.09467, 0.88248, -0.2198, 0.91404, -0.34168, 0.75517, -0.5136, 0.64527, -0.64527, 0.44614, -0.74102, 0.29162, -0.70838, 0.03591, -0.71731, -0.11943, -0.64962, -0.28183, -0.51251, -0.44505, -0.37432, -0.53319], [1.0, 0.0, 0.91353, 0.81586, -0.72973, 1.0, -0.39466, 0.55735, 0.05405, 0.2973, -0.18599, -0.10241, -0.03158, -0.0897, 0.01401, -0.03403, 0.01108, -0.00537, 0.00342, 0.00097, 0.00048, 0.00075, -3e-05, 0.00019, -3e-05, 2e-05, -1e-05, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.21429, -0.09524, 0.33333, 0.07143, 0.19048, 0.19048, 0.2381, 0.09524, 0.40476, 0.02381, 0.30952, -0.04762, 0.30952, -0.04762, 0.28571, -0.11905, 0.33333, 0.04762, 0.30952, 0.0, 0.21429, -0.11905, 0.35714, -0.04762, 0.22109, -0.0229, 0.19048, 0.0, 0.16997, -0.02034, 0.14694, -0.01877], [1.0, 0.0, 1.0, -0.14754, 1.0, 0.04918, 0.57377, -0.01639, 0.65574, 0.01639, 0.85246, -0.03279, 0.72131, 0.0, 0.68852, -0.16393, 0.19672, -0.14754, 0.65558, -0.17176, 0.67213, 0.03279, 1.0, -0.29508, 0.31148, -0.34426, 0.52385, -0.20325, 0.32787, -0.03279, 0.27869, -0.44262, 0.4918, -0.06557], [1.0, 0.0, 0.98182, 0.0, 0.88627, 0.03131, 0.86249, 0.04572, 0.8, 0.0, 0.69091, 0.04545, 0.79343, 0.08436, 0.77118, 0.09579, 0.62727, 0.25455, 0.68182, 0.12727, 0.70674, 0.12608, 0.68604, 0.13493, 0.74545, 0.22727, 0.64581, 0.15088, 0.67273, 0.02727, 0.60715, 0.16465, 0.5884, 0.17077], [1.0, 0.0, 0.39286, 0.52381, -0.78824, 0.11342, -0.16628, -0.76378, 0.66667, 0.0119, 0.82143, 0.40476, -0.6723, 0.30729, -0.34797, -0.63668, 0.46429, 0.15476, 0.54762, 0.05952, -0.5183, 0.44961, -0.47651, -0.47594, 0.32143, 0.70238, 0.51971, 0.38848, 0.57143, 0.39286, -0.54891, -0.29915, 0.25441, -0.55837], [1.0, 0.0, 0.86889, -0.07111, 1.0, -0.02494, 1.0, -0.06889, 0.87778, 0.00222, 0.83556, -0.06444, 1.0, -0.07287, 1.0, -0.2, 0.86889, 0.05333, 0.88, -0.03778, 1.0, -0.11526, 1.0, -0.18667, 0.84444, 0.03556, 1.0, -0.14162, 0.82222, -0.14667, 1.0, -0.15609, 1.0, -0.44222], [1.0, 0.0, 0.43636, -0.12727, 0.58182, -0.14545, 0.18182, -0.67273, 0.34545, -0.03636, 0.29091, -0.05455, 0.29091, 0.29091, 0.36364, -0.41818, 0.2, -0.01818, 0.36364, 0.05455, 0.12727, 0.49091, 0.61818, 0.16364, 0.32727, 0.16364, 0.41098, -0.07027, 0.34545, -0.05455, 0.12727, -0.36364, 0.29091, -0.29091], [1.0, 0.0, 1.0, -0.92453, 1.0, 0.75472, 0.49057, -0.0566, 0.62264, 0.0, 1.0, -0.00054, 0.45283, 0.07547, 0.62264, -0.0566, 0.98878, -0.00085, 0.5283, 0.0, 0.5283, 0.07547, 0.9519, -0.00112, 1.0, 0.79245, 0.92192, -0.00128, 0.9434, -1.0, 1.0, 0.43396, 0.43396, -0.11321], [1.0, 0.0, 0.7381, 0.83333, -0.7619, -0.2381, 0.33333, -0.14286, 0.45238, -0.14286, -0.67285, 0.12808, 0.33333, 0.0, 0.28571, -0.07143, -0.38214, 0.51163, 0.2381, 0.02381, 0.45238, 0.04762, 0.16667, -0.2619, -0.57255, -0.10234, 0.24889, -0.51079, 1.0, 0.0, -0.66667, -0.04762, 0.2619, 0.02381], [1.0, 0.0, 0.4375, 0.04167, 0.58333, -0.10417, 0.39583, 0.0, 0.33333, -0.0625, 0.47917, 0.0, 0.29167, 0.10417, 0.54167, 0.02083, 0.4375, -0.22917, 0.35417, -0.22917, 0.33333, 0.08333, 0.25, 0.1875, 0.39583, -0.1875, 0.44012, -0.10064, 0.41667, -0.08333, 0.58333, -0.3125, 0.33333, -0.0625], [1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.47744, -0.89098, -0.51504, 0.45489, -0.95489, 0.28571, 0.64662, 1.0, 0.0, 0.0, 0.0, 0.0, 0.6203, 0.20301, -1.0, -1.0, 1.0, -1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.95217, 0.06595, 0.93614, 0.1303, 0.90996, 0.19152, 0.84881, -0.49962, 0.90023, 0.6132, 0.77937, 0.34328, 0.72254, 0.37988, 0.66145, 0.40844, 0.95472, 0.59862, 0.53258, 0.44088, 0.46773, 0.44511, 0.4044, 0.44199, 0.34374, 0.43221, 0.9033, 1.0, 0.23405, 0.3962, 0.18632, 0.37191], [1.0, 0.0, 0.5984, 0.40332, 0.82809, 0.80521, 0.76001, 0.70709, 0.8401, -0.10984, 0.97311, 0.07981, 0.95824, -0.85727, 0.91962, 0.88444, 0.95452, -0.05206, 0.88673, 0.18135, 0.98484, -0.69594, 0.8667, -0.85755, 0.28604, -0.30063, 1.0, 0.17076, 0.62958, 0.42677, 0.87757, 0.81007, 0.81979, 0.68822], [1.0, 0.0, 0.95882, 0.10129, 1.0, -0.01918, 0.98313, 0.02555, 0.96974, -0.09316, 0.98955, -0.02716, 0.9798, -0.03096, 1.0, -0.05343, 1.0, -0.05179, 0.9384, 0.01557, 0.9762, -0.09284, 0.97889, -0.05318, 0.91567, -0.15675, 0.95677, -0.06995, 0.90978, 0.01307, 1.0, -0.10797, 0.93144, -0.06888], [1.0, 0.0, 0.0, 0.0, -0.33672, 0.85388, 0.0, 0.0, 0.68869, -1.0, 0.97078, 0.31385, -0.26048, -0.59212, -0.30241, 0.65565, 0.94155, 0.16391, 0.0, 0.0, 0.0, 0.0, -0.18043, -1.0, 0.0, 0.0, 1.0, -1.0, 0.0, 0.0, 0.04447, 0.61881, 0.0, 0.0], [1.0, 0.0, 0.96933, 0.00876, 1.0, 0.00843, 0.98658, -0.00763, 0.97868, -0.02844, 0.9982, -0.0351, 1.0, -0.01271, 1.0, -0.02581, 1.0, -0.01175, 0.98485, 0.00025, 1.0, -0.02612, 1.0, -0.04744, 0.96019, -0.04527, 0.99188, -0.03473, 0.9702, -0.02478, 1.0, -0.03855, 0.9842, -0.04112], [1.0, 0.0, 0.0, 0.0, 0.98919, -0.22703, 0.18919, -0.05405, 0.0, 0.0, 0.93243, 0.07297, 1.0, -0.2, 1.0, 0.07027, 1.0, -0.11351, 0.0, 0.0, 1.0, -0.21081, 1.0, -0.41622, 0.0, 0.0, 1.0, -0.17568, 0.0, 0.0, 1.0, -0.25946, 0.28919, -0.15676], [1.0, 0.0, 0.64122, 0.01403, 0.34146, -0.02439, 0.52751, 0.03466, 0.19512, 0.12195, 0.43313, 0.04755, 0.21951, 0.04878, 0.29268, 0.0, 0.36585, 0.0, 0.31707, 0.07317, 0.26829, 0.12195, 0.23698, 0.05813, 0.21951, 0.09756, 0.19304, 0.05641, 0.1741, 0.05504, 0.19512, 0.0, 0.17073, 0.07317], [1.0, 0.0, 1.0, 1.0, 1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, -1.0, 1.0, 1.0, 1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 1.0, -0.27778, 0.0, 0.0, 1.0, -1.0, 1.0, 1.0, 1.0, -1.0, 0.0, 0.0], [1.0, 0.0, 0.34694, 0.20408, 0.46939, 0.2449, 0.40816, 0.20408, 0.46939, 0.44898, 0.30612, 0.59184, 0.12245, 0.55102, 0.0, 0.5102, -0.06122, 0.55102, -0.20408, 0.55102, -0.28571, 0.44898, -0.28571, 0.32653, -0.61224, 0.22449, -0.46579, 0.14895, -0.59184, 0.18367, -0.34694, 0.0, -0.26531, -0.2449], [1.0, 0.0, 0.0, 0.0, 1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, -0.25342, 1.0, 0.23288, 1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, -1.0, 0.0, 0.0, 1.0, -1.0, 0.0, 0.0], [1.0, 0.0, 0.89706, 0.38235, 0.91176, 0.375, 0.74265, 0.67647, 0.45588, 0.77941, 0.19118, 0.88971, -0.02206, 0.86029, -0.20588, 0.82353, -0.375, 0.67647, -0.5, 0.47794, -0.73529, 0.38235, -0.86029, 0.08824, -0.74265, -0.125, -0.67925, -0.24131, -0.55147, -0.42647, -0.44118, -0.50735, -0.28676, -0.56618], [1.0, 0.0, -1.0, 0.28105, 0.22222, 0.15033, -0.75693, -0.70984, -0.30719, 0.71242, -1.0, 1.0, -0.81699, 0.33987, -0.79085, -0.02614, -0.98039, -0.83007, -0.60131, -0.54248, -0.04575, -0.83007, 0.94118, -0.94118, -1.0, -0.43137, 0.74385, 0.09176, -1.0, 0.05229, 0.18301, 0.02614, -0.40201, -0.48241], [1.0, 0.0, 0.26667, -0.1, 0.53333, 0.0, 0.33333, -0.13333, 0.36667, 0.11667, 0.56667, 0.01667, 0.71667, 0.08333, 0.7, -0.06667, 0.53333, 0.2, 0.41667, -0.01667, 0.31667, 0.2, 0.7, 0.0, 0.25, 0.13333, 0.46214, 0.05439, 0.4, 0.03333, 0.46667, 0.03333, 0.41667, -0.05], [1.0, 0.0, -0.26667, 0.4, -0.27303, 0.12159, -0.17778, -0.04444, 0.06192, -0.06879, 0.04461, 0.02575, -0.00885, 0.02726, -0.01586, -0.00166, -0.00093, -0.00883, 0.0047, -0.00153, 0.00138, 0.00238, -0.00114, 0.00102, -0.00069, -0.0005, 0.00019, -0.00043, 0.00026, 5e-05, 0.0, 0.00015, -8e-05, 2e-05], [1.0, 0.0, 1.0, -0.37838, 0.64865, 0.2973, 0.64865, -0.24324, 0.86486, 0.18919, 1.0, -0.27027, 0.51351, 0.0, 0.62162, -0.05405, 0.32432, -0.21622, 0.71833, -0.17666, 0.62162, 0.05405, 0.75676, 0.13514, 0.35135, -0.2973, 0.61031, -0.22163, 0.58478, -0.23027, 0.72973, -0.59459, 0.51351, -0.24324], [1.0, 0.0, 0.94531, -0.03516, -1.0, -0.33203, -1.0, -0.01563, 0.97266, 0.01172, 0.93359, -0.01953, -1.0, 0.16406, -1.0, -0.00391, 0.95313, -0.03516, 0.92188, -0.02734, -0.99219, 0.11719, -0.93359, 0.34766, 0.95703, -0.00391, 0.82041, 0.13758, 0.90234, -0.06641, -1.0, -0.1875, -1.0, -0.34375], [1.0, 0.0, 0.95202, 0.02254, 0.93757, -0.01272, 0.93526, 0.01214, 0.96705, -0.01734, 0.96936, 0.0052, 0.95665, -0.03064, 0.9526, -0.00405, 0.9948, -0.02659, 0.99769, 0.01792, 0.93584, -0.04971, 0.93815, -0.0237, 0.97052, -0.04451, 0.96215, -0.01647, 0.97399, 0.01908, 0.95434, -0.0341, 0.95838, 0.00809], [1.0, 0.0, 1.0, -0.05529, 1.0, -1.0, 0.5, -0.11111, 0.36111, -0.22222, 1.0, -0.25712, 0.16667, -0.11111, 1.0, -0.3466, 1.0, -0.38853, 1.0, -0.42862, 0.0, -0.25, 1.0, -0.50333, 1.0, -0.27778, 1.0, -0.57092, 1.0, -0.27778, 1.0, -0.63156, 1.0, -0.65935], [1.0, 0.0, 0.31034, -0.10345, 0.24138, -0.10345, 0.2069, -0.06897, 0.07405, -0.05431, 0.03649, -0.03689, 0.01707, -0.02383, 0.00741, -0.01482, 0.00281, -0.00893, 0.00078, -0.00523, -3e-05, -0.00299, -0.00028, -0.00166, -0.00031, -0.0009, -0.00025, -0.00048, -0.00018, -0.00024, -0.00012, -0.00012, -8e-05, -6e-05], [1.0, 0.0, 0.62745, -0.07843, 0.72549, 0.0, 0.60784, -0.07843, 0.62745, -0.11765, 0.68627, -0.11765, 0.66667, -0.13725, 0.64706, -0.09804, 0.54902, -0.11765, 0.54902, -0.21569, 0.58824, -0.19608, 0.66667, -0.23529, 0.45098, -0.2549, 0.52409, -0.24668, 0.56863, -0.31373, 0.43137, -0.21569, 0.47059, -0.27451], [1.0, 0.0, 0.25, 0.16667, 0.46667, 0.26667, 0.19036, 0.23966, 0.07766, 0.19939, 0.0107, 0.14922, -0.02367, 0.10188, -0.03685, 0.06317, -0.03766, 0.03458, -0.0323, 0.01532, -0.02474, 0.00357, -0.01726, -0.00273, -0.01097, -0.00539, -0.00621, -0.00586, -0.00294, -0.0052, -0.00089, -0.00408, 0.00025, -0.00291], [1.0, 0.0, -0.65625, 0.15625, 0.0625, 0.0, 0.0, 0.0625, 0.625, 0.0625, 0.1875, 0.0, -0.03125, 0.09375, 0.0625, 0.0, 0.15625, -0.15625, 0.4375, -0.375, 0.0, -0.09375, 0.0, 0.0, 0.03125, -0.46875, 0.03125, 0.0, -0.71875, 0.03125, -0.03125, 0.0, 0.0, 0.09375], [1.0, 0.0, 1.0, -0.01081, 1.0, -0.02703, 1.0, -0.06486, 0.95135, -0.01622, 0.98919, -0.03243, 0.98919, 0.08649, 1.0, -0.06486, 0.95135, 0.09189, 0.97838, -0.00541, 1.0, 0.06486, 1.0, 0.04324, 0.97838, 0.09189, 0.98556, 0.01251, 1.0, -0.03243, 1.0, 0.02703, 1.0, -0.07027], [1.0, 0.0, 0.85271, 0.05426, 1.0, 0.08069, 1.0, 1.0, 0.91473, -0.00775, 0.83721, 0.03876, 1.0, 0.27153, 1.0, 1.0, 0.81395, 0.04651, 0.90698, 0.11628, 1.0, 0.5067, 1.0, -1.0, 0.8062, 0.03876, 1.0, 0.71613, 0.84496, 0.06977, 1.0, 0.87317, 1.0, 1.0], [1.0, 0.0, 0.90374, -0.01604, 1.0, 0.08021, 1.0, 0.01604, 0.93048, 0.00535, 0.93583, -0.01604, 1.0, 0.0, 1.0, 0.06417, 1.0, 0.04813, 0.91444, 0.04278, 0.96791, 0.02139, 0.9893, -0.01604, 0.96257, 0.05348, 0.96974, 0.04452, 0.87701, 0.0107, 1.0, 0.09091, 0.97861, 0.06417], [1.0, 0.0, -0.205, 0.2875, 0.23, 0.1, 0.2825, 0.3175, 0.3225, 0.35, 0.36285, -0.34617, 0.0925, 0.275, -0.095, 0.21, -0.0875, 0.235, -0.34187, 0.31408, -0.48, -0.08, 0.29908, 0.33176, -0.58, -0.24, 0.3219, -0.28475, -0.47, 0.185, -0.27104, -0.31228, 0.40445, 0.0305], [1.0, 0.0, 0.6, 0.03333, 0.63333, 0.06667, 0.7, 0.06667, 0.7, 0.0, 0.63333, 0.0, 0.8, 0.0, 0.73333, 0.0, 0.7, 0.1, 0.66667, 0.1, 0.73333, -0.03333, 0.76667, 0.0, 0.63333, 0.13333, 0.65932, 0.10168, 0.6, 0.13333, 0.6, 0.16667, 0.63333, 0.16667], [1.0, 0.0, 0.05866, -0.00838, 0.06704, 0.00838, 0.0, -0.01117, 0.00559, -0.03911, 0.01676, -0.07542, -0.00559, 0.05307, 0.06425, -0.03352, 0.0, 0.09497, -0.06425, 0.07542, -0.04749, 0.02514, 0.02793, -0.00559, 0.00838, 0.00559, 0.10335, -0.00838, 0.03073, -0.00279, 0.04469, 0.0, 0.04749, -0.03352], [1.0, 0.0, 0.94653, 0.28713, 0.72554, 0.67248, 0.47564, 0.82455, 0.01267, 0.89109, -0.24871, 0.84475, -0.47644, 0.56079, -0.75881, 0.41743, -0.66455, 0.07208, -0.65426, -0.19525, -0.52475, -0.44, -0.30851, -0.55089, -0.04119, -0.64792, 0.16085, -0.5642, 0.36752, -0.41901, 0.46059, -0.22535, 0.50376, -0.0598], [1.0, 0.0, 0.0546, 0.01437, -0.02586, 0.04598, 0.01437, 0.04598, -0.07759, 0.00862, 0.01724, -0.06609, -0.03736, 0.0431, -0.08333, -0.04598, -0.09483, 0.08046, -0.04023, 0.05172, 0.02011, 0.02299, -0.03736, -0.01149, 0.03161, -0.00862, 0.00862, 0.01724, 0.02586, 0.01149, 0.02586, 0.01149, -0.04598, -0.00575], [1.0, 0.0, 0.72414, -0.01084, 0.79704, 0.01084, 0.8, 0.00197, 0.79015, 0.01084, 0.78424, -0.00985, 0.8335, 0.03251, 0.85123, 0.01675, 0.80099, -0.00788, 0.79113, -0.02956, 0.75961, 0.0335, 0.74778, 0.05517, 0.72611, -0.01478, 0.78041, 0.00612, 0.74089, -0.05025, 0.82956, 0.02956, 0.79015, 0.00788], [1.0, 0.0, 0.03852, 0.02568, 0.00428, 0.0, 0.01997, -0.01997, 0.0214, -0.04993, -0.0485, -0.01284, 0.01427, -0.02282, 0.0, -0.03281, -0.04708, -0.02853, -0.01712, 0.03566, 0.0214, 0.00428, 0.05136, -0.02282, 0.05136, 0.01854, 0.03994, 0.01569, 0.01997, 0.00713, -0.02568, -0.01854, -0.01427, 0.01997], [1.0, 0.0, 0.4709, 0.22751, 0.42328, 0.33598, 0.25661, 0.47619, 0.01852, 0.49471, -0.02116, 0.53968, -0.34127, 0.31217, -0.4127, 0.3254, -0.51587, 0.06878, -0.5, -0.1164, -0.14815, -0.1455, -0.14815, -0.38095, -0.2328, 0.00265, 0.03574, -0.31739, 0.15873, -0.21693, 0.24868, -0.24339, 0.2672, 0.04233], [1.0, 0.0, 0.08696, 0.00686, 0.13959, -0.04119, 0.10526, -0.08238, 0.12586, -0.06178, 0.23341, -0.01144, 0.12357, 0.0778, 0.14645, -0.13501, 0.29062, -0.04805, 0.18993, 0.07323, 0.1167, 0.0, 0.11213, -0.00229, 0.15103, -0.10297, 0.08467, 0.01373, 0.11213, -0.06636, 0.09611, -0.07323, 0.1167, -0.06865], [1.0, 0.0, 0.94333, 0.38574, 0.48263, 0.64534, 0.21572, 0.77514, -0.55941, 0.64899, -0.73675, 0.42048, -0.76051, 0.0, -0.62706, -0.31079, -0.38391, -0.62157, -0.12797, -0.69287, 0.49909, -0.6362, 0.71481, -0.3766, 0.73857, -0.05484, 0.60098, 0.30384, 0.45521, 0.60512, 0.02742, 0.54479, -0.21572, 0.50457], [1.0, 0.0, 0.01975, 0.00705, 0.0409, -0.00846, 0.02116, 0.01128, 0.01128, 0.04372, 0.00282, 0.00141, 0.01975, -0.03103, -0.01975, 0.06065, -0.0409, 0.0268, -0.02398, -0.00423, 0.04372, -0.02539, 0.01834, 0.0, 0.0, -0.01269, 0.01834, -0.01128, 0.00564, -0.01551, -0.01693, -0.02398, 0.00705, 0.0], [1.0, 0.0, 0.85736, 0.00075, 0.81927, -0.05676, 0.77521, -0.04182, 0.84317, 0.09037, 0.86258, 0.11949, 0.88051, -0.06124, 0.78342, 0.0351, 0.83719, -0.06796, 0.8357, -0.1419, 0.88125, 0.01195, 0.90515, 0.0224, 0.79686, -0.01942, 0.82383, -0.03678, 0.88125, -0.06423, 0.73936, -0.01942, 0.79089, -0.09186], [1.0, 0.0, 1.0, -1.0, 1.0, 1.0, -1.0, 1.0, 1.0, -1.0, 1.0, -1.0, -1.0, -1.0, -1.0, 1.0, 1.0, 1.0, 1.0, 1.0, -1.0, 1.0, 1.0, -1.0, 1.0, -1.0, 1.0, 1.0, 1.0, 1.0, -1.0, 1.0, -1.0, 1.0], [1.0, 0.0, 0.85209, 0.39252, 0.38887, 0.76432, 0.08858, 0.98903, -0.42625, 0.88744, -0.76229, 0.4998, -0.93092, 0.10768, -0.859, -0.31044, -0.6603, -0.55262, -0.1926, -0.86063, 0.28444, -0.80496, 0.64649, -0.3523, 0.77814, -0.23324, 0.71698, 0.21343, 0.3783, 0.5831, 0.19667, 0.66315, -0.11215, 0.64933], [1.0, 0.0, 1.0, 1.0, 1.0, 0.5125, 0.625, -1.0, 1.0, 1.0, 0.025, 0.03125, 1.0, 1.0, 0.0, 0.0, 1.0, -1.0, 1.0, 1.0, 1.0, 1.0, 0.3125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, -0.94375, 1.0, 0.0, 0.0], [1.0, 0.0, 1.0, 0.54902, 0.62745, 1.0, 0.01961, 1.0, -0.4902, 0.92157, -0.82353, 0.58824, -1.0, 0.11765, -0.96078, -0.33333, -0.64706, -0.68627, -0.23529, -0.86275, 0.35294, -1.0, 0.7451, -0.72549, 0.92157, -0.21569, 0.92874, 0.21876, 0.72549, 0.56863, 0.23529, 0.90196, -0.11765, 0.90196], [1.0, 0.0, 0.0, 0.0, -1.0, -1.0, -1.0, 1.0, 0.0, 0.0, -1.0, 1.0, 1.0, 1.0, 1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -1.0, 1.0, 1.0, 0.4375, 1.0, -1.0, 0.0, 0.0, -1.0, -1.0, -1.0, 1.0], [1.0, 0.0, 0.44444, 0.44444, 0.53695, 0.90763, -0.22222, 1.0, -0.33333, 0.88889, -1.0, 0.33333, -1.0, -0.11111, -1.0, -0.22222, -0.66667, -0.77778, 0.55556, -1.0, -0.22222, -0.77778, 0.77778, -0.22222, 0.33333, 0.0, 0.9212, 0.45019, 0.57454, 0.84353, 0.22222, 1.0, -0.55556, 1.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.5, 0.5, 0.75, 0.0, 0.91201, 0.12094, 0.89067, 0.1421, 0.86922, 0.16228, 0.75, 0.25, 0.75, 0.5, 0.75, 0.0, 1.0, -0.25, 0.5, 0.5, 0.73944, 0.26388, 0.75, 0.25, 0.69635, 0.29074, 0.67493, 0.30293], [0.0, 0.0, -1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, -1.0, 1.0, -1.0, 1.0, -1.0, -1.0, -1.0, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, 1.0, -1.0, 1.0, 1.0, -1.0, -1.0, 0.0, 0.0], [1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.66667, 0.11111, 1.0, -0.11111, 0.88889, -0.11111, 1.0, -0.22222, 0.77778, 0.0, 0.77778, 0.0, 1.0, -0.11111, 0.77778, -0.11111, 0.66667, -0.11111, 0.66667, 0.0, 0.90347, -0.05352, 1.0, 0.11111, 0.88889, -0.11111, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, 1.0, 0.75, 0.0, 0.0, 0.0, 0.0, -1.0, 1.0, 0.0, 0.0, 1.0, -1.0, -1.0, -1.0, 1.0, 1.0, 0.0, 0.0], [1.0, 0.0, 1.0, 0.45455, 1.0, -0.45455, 1.0, 0.09091, 1.0, -0.09091, 1.0, 0.0, 1.0, -0.27273, 1.0, -0.18182, 1.0, 0.09091, 1.0, 0.0, 1.0, -0.36364, 1.0, 0.09091, 1.0, -0.09091, 1.0, -0.04914, 1.0, 0.45455, 1.0, -0.27273, 1.0, -0.18182], [1.0, 0.0, 0.62121, -0.63636, 0.0, 0.0, 0.0, 0.0, 0.3447, 0.28788, 0.42803, 0.39394, -0.07576, 0.51894, 0.36364, 0.31439, -0.53788, 0.32955, 0.12121, -0.14773, 0.01894, -0.53409, -0.57576, 0.17803, 0.29167, -0.27273, 0.25758, -0.57576, 0.43182, 0.24242, 0.18182, -0.02273, 0.17045, -0.41667], [1.0, 0.0, 1.0, 0.11765, 1.0, 0.23529, 1.0, 0.41176, 1.0, 0.05882, 1.0, 0.23529, 1.0, 0.11765, 1.0, 0.47059, 1.0, -0.05882, 1.0, -0.11765, 1.0, 0.35294, 1.0, 0.41176, 1.0, -0.11765, 1.0, 0.20225, 1.0, 0.05882, 1.0, 0.35294, 1.0, 0.23529], [1.0, 0.0, 0.0, 0.0, -1.0, -0.62766, 1.0, 0.51064, 0.07979, -0.23404, -1.0, -0.3617, 0.12766, -0.59043, 1.0, -1.0, 0.0, 0.0, 0.82979, -0.07979, -0.25, 1.0, 0.17021, -0.70745, 0.0, 0.0, -0.19149, -0.46809, -0.2234, -0.48936, 0.74468, 0.90426, -0.67553, 0.45745], [1.0, 0.0, 0.91667, 0.29167, 0.83333, -0.16667, 0.70833, 0.25, 0.875, -0.08333, 0.91667, 0.04167, 0.83333, 0.125, 0.70833, 0.0, 0.875, 0.04167, 1.0, 0.08333, 0.66667, -0.08333, 0.75, 0.16667, 0.83333, -0.125, 0.83796, 0.05503, 1.0, 0.20833, 0.70833, 0.0, 0.70833, 0.04167], [1.0, 0.0, 0.1859, -0.16667, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11538, -0.19071, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.05128, -0.06571, 0.07853, 0.08974, 0.17308, -0.10897, 0.125, 0.09615, 0.02564, -0.04808, 0.16827, 0.19551], [1.0, 0.0, 1.0, -0.08183, 1.0, -0.11326, 0.99246, -0.29802, 1.0, -0.33075, 0.96662, -0.34281, 0.85788, -0.47265, 0.91904, -0.4817, 0.73084, -0.65224, 0.68131, -0.63544, 0.8245, -0.78316, 0.58829, -0.74785, 0.67033, -0.96296, 0.48757, -0.85669, 0.37941, -0.83893, 0.24117, -0.88846, 0.29221, -0.89621], [1.0, 0.0, 1.0, 1.0, -1.0, 1.0, -1.0, -0.82456, 0.34649, 0.21053, 0.46053, 0.07018, 0.22807, 0.05702, 0.35088, 0.34649, 0.72807, -0.03947, 0.22807, 0.5307, 0.0, 0.0, -0.29825, -0.16228, 1.0, -0.66667, 1.0, -1.0, 1.0, -0.24561, 0.35088, 0.20175, 0.82895, 0.07895], [1.0, 0.0, 1.0, 0.24077, 0.99815, 0.00369, 0.80244, -0.30133, 0.89919, -0.23486, 0.70643, -0.24077, 0.73855, -0.30539, 0.71492, -0.36078, 0.47194, -0.61189, 0.40473, -0.55059, 0.61041, -0.39328, 0.53176, -0.32681, 0.23966, -0.52142, 0.29208, -0.4839, 0.12777, -0.39143, 0.15657, -0.51329, 0.18353, -0.46603], [0.0, 0.0, -1.0, 1.0, 1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 1.0, -1.0, 1.0, 1.0, 0.0, 0.0, 1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, -1.0, 1.0, 1.0, -1.0, -1.0, 1.0, -1.0, -1.0, 0.0, 0.0], [1.0, 0.0, 0.92247, -0.19448, 0.96419, -0.17674, 0.87024, -0.22602, 0.81702, -0.2707, 0.79271, -0.28909, 0.70302, -0.49639, 0.63338, -0.49967, 0.37254, -0.70729, 0.2707, -0.72109, 0.40506, -0.54172, 0.33509, -0.59691, 0.1475, -0.63601, 0.09312, -0.59589, -0.07162, -0.54928, -0.0184, -0.54074, -0.07457, -0.47898], [1.0, 0.0, -1.0, -1.0, -0.50694, 1.0, 1.0, -1.0, 1.0, 0.53819, 0.0, 0.0, 0.23958, -1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, -0.71528, 1.0, 0.33333, -1.0, 1.0, -1.0, 0.69792, -1.0, 0.47569, 1.0], [1.0, 0.0, 0.84177, 0.4346, 0.5, 0.7616, 0.09916, 0.9346, -0.37764, 0.88186, -0.72363, 0.61181, -0.93882, 0.19409, -0.86709, -0.25527, -0.62869, -0.65612, -0.25105, -0.85654, 0.16245, -0.86498, 0.51477, -0.66878, 0.74895, -0.28903, 0.77937, 0.07933, 0.64135, 0.42827, 0.31435, 0.62447, -0.00422, 0.69409], [1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, -1.0, -1.0, -1.0, 1.0, 1.0, 1.0, -1.0, 0.0, 0.0, 1.0, -1.0, 1.0, 1.0, 0.0, 0.0, 1.0, -1.0, -1.0, -1.0, 1.0, 1.0, -1.0, 1.0, -1.0, 1.0, 0.0, 0.0], [1.0, 0.0, 1.0, 0.63548, 1.0, 1.0, 0.77123, 1.0, -0.33333, 1.0, -1.0, 1.0, 0.0, 1.0, -1.0, 1.0, -1.0, 0.0, -1.0, -0.66667, -1.0, -0.92536, -1.0, -0.33333, -0.33333, -1.0, 0.19235, -1.0, 1.0, -1.0, 0.0, -1.0, 1.0, -0.66667], [0.0, 0.0, -1.0, 1.0, -1.0, -1.0, 0.0, 0.0, -1.0, 1.0, 1.0, -1.0, -1.0, -1.0, -1.0, 1.0, 0.0, 0.0, -1.0, -1.0, -1.0, 1.0, 0.0, 0.0, 1.0, -1.0, 1.0, 1.0, 1.0, -1.0, 1.0, 1.0, 0.0, 0.0], [1.0, 0.0, 1.0, 0.06843, 1.0, 0.14211, 1.0, 0.22108, 1.0, -0.125, 1.0, 0.39495, 1.0, 0.48981, 1.0, 0.58986, -0.375, 1.0, 1.0, 0.0, 1.0, 0.92001, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.25, 1.0, 1.0, 1.0, 1.0], [0.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, -1.0, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, 1.0, 1.0, 1.0, -1.0, 1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.64947, -0.07896, 0.58264, -0.1438, -0.13129, -0.21384, 0.29796, 0.04403, 0.38096, -0.26339, 0.28931, -0.31997, 0.03459, -0.18947, 0.20269, -0.29441, 0.15196, -0.29052, 0.09513, -0.31525, 0.06556, -0.26795, 0.03004, -0.25124, -0.00046, -0.2321, -0.02612, -0.21129, -0.04717, -0.1895, 0.01336, -0.27201], [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, -0.33333, 0.16667, 0.26042, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.19792, -0.21875, -0.16667, 0.90625, -1.0, 0.5, 0.04167, 0.75, -0.22917, -1.0, -0.125, -0.27083, -0.19792, -0.9375], [1.0, 0.0, 1.0, 0.05149, 0.99363, 0.10123, 0.96142, 0.14756, 0.95513, -0.26496, 0.66026, 0.54701, 0.80426, 0.25283, 0.73781, 0.2738, 0.66775, 0.28714, 0.59615, 0.29304, 0.52494, 0.292, 0.45582, 0.28476, 0.39023, 0.27226, 0.3293, 0.25553, 0.27381, 0.23568, 0.22427, 0.21378, 0.18086, 0.19083], [1.0, 0.0, 1.0, -0.09524, -1.0, -1.0, -1.0, -1.0, 1.0, 0.31746, 0.81349, 0.7619, -1.0, -1.0, -1.0, 1.0, 0.47364, 1.0, 1.0, 1.0, 0.68839, -1.0, -1.0, -1.0, 0.82937, 0.36508, 1.0, 1.0, 1.0, 0.50794, -1.0, -0.3254, -1.0, 0.72831], [1.0, 0.0, 0.93669, -0.0019, 0.60761, 0.43204, 0.92314, -0.40129, 0.93123, 0.16828, 0.96197, 0.09061, 0.99676, 0.08172, 0.91586, 0.05097, 0.84628, -0.25324, 0.87379, -0.14482, 0.84871, 0.26133, 0.75081, -0.03641, 0.84547, -0.02589, 0.87293, -0.02302, 0.98544, 0.09385, 0.78317, -0.10194, 0.85841, -0.14725], [1.0, 0.0, 1.0, -1.0, 1.0, 1.0, 1.0, 1.0, 1.0, -0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, -1.0, 1.0, 1.0, 1.0, 0.625, 1.0, -0.75, -0.75, 1.0, 1.0, 1.0], [1.0, 0.0, 1.0, 0.23058, 1.0, -0.78509, 1.0, -0.10401, 1.0, 0.15414, 1.0, 0.2782, 0.9812, -0.06861, 1.0, 0.0661, 0.95802, -0.18954, 0.83584, -0.15633, 0.974, 0.03728, 0.99624, 0.09242, 1.0, -0.01253, 0.96238, -0.04597, 0.91165, 0.03885, 1.0, -0.13722, 0.96523, -0.11717], [1.0, 0.0, 0.36876, -1.0, -1.0, -1.0, -0.07661, 1.0, 1.0, 0.95041, 0.74597, -0.3871, -1.0, -0.79313, -0.09677, 1.0, 0.48684, 0.46502, 0.31755, -0.27461, -0.14343, -0.20188, -0.11976, 0.06895, 0.03021, 0.06639, 0.03443, -0.01186, -0.00403, -0.01672, -0.00761, 0.00108, 0.00015, 0.00325], [1.0, 0.0, 0.79847, 0.38265, 0.80804, -0.16964, 1.0, -0.07653, 0.98151, -0.07398, 0.70217, 0.20663, 0.99745, 0.02105, 0.98214, 0.02487, 1.0, -0.13074, 0.95663, 0.07717, 1.0, 0.00191, 0.90306, 0.30804, 1.0, -0.14541, 1.0, -0.00394, 0.75638, 0.07908, 1.0, -0.1875, 1.0, -0.0574], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, -1.0, 0.0, 0.0, 1.0, 1.0, 1.0, -1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, -1.0, 0.0, 0.0], [1.0, 0.0, 1.0, -0.28428, 1.0, -0.25346, 0.94623, -0.35094, 1.0, -0.30566, 0.92736, -0.49057, 0.90818, -0.44119, 0.75723, -0.58899, 0.69748, -0.58019, 0.59623, -0.57579, 0.68459, -0.70975, 0.54465, -0.87327, 0.49214, -0.73333, 0.35504, -0.76054, 0.26352, -0.78239, 0.16604, -0.73145, 0.13994, -0.7], [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.85, -1.0, 0.0, 0.0, 1.0, -1.0, 0.0, 0.0, -1.0, -1.0, -1.0, -1.0, 1.0, -1.0, -0.6, -1.0, 1.0, 1.0, -1.0, -0.2, 1.0, -1.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 1.0, 0.09091, 0.95455, -0.09091, 0.77273, 0.0, 1.0, 0.0, 0.95455, 0.0, 1.0, 0.04545, 0.90909, -0.04545, 1.0, 0.0, 1.0, 0.0, 0.86364, 0.09091, 0.77273, 0.09091, 0.90909, 0.04545, 0.91541, 0.02897, 0.95455, 0.09091, 0.86364, -0.09091, 0.86364, 0.04545], [0.0, 0.0, 0.0, 0.0, -1.0, 1.0, 1.0, 1.0, -1.0, -1.0, 0.0, 0.0, -1.0, -1.0, -1.0, -0.3125, -1.0, -1.0, 1.0, -1.0, 1.0, -1.0, 0.0, 0.0, 1.0, -1.0, -1.0, -1.0, 0.0, 0.0, 1.0, -1.0, 0.0, 0.0], [1.0, 0.0, 0.91176, -0.08824, 0.97059, 0.17647, 0.82353, 0.08824, 0.91176, -0.02941, 0.97059, -0.17647, 0.97059, 0.14706, 0.94118, 0.02941, 1.0, 0.0, 1.0, 0.0, 0.76471, 0.11765, 0.88235, 0.02941, 0.85294, 0.02941, 0.92663, 0.026, 0.94118, -0.11765, 0.97059, 0.05882, 0.91176, 0.05882], [1.0, 0.0, -1.0, 1.0, -1.0, 0.15244, 0.28354, 1.0, -1.0, 1.0, -1.0, -1.0, 1.0, 1.0, -1.0, -0.23476, 0.28301, -1.0, 1.0, 1.0, -0.31402, -1.0, -1.0, -1.0, 1.0, -1.0, -1.0, -0.03578, 1.0, -1.0, -1.0, -0.32317, 0.14939, 1.0], [1.0, 0.0, 0.47368, -0.10526, 0.83781, 0.01756, 0.83155, 0.02615, 0.68421, -0.05263, 0.68421, 0.0, 0.79856, 0.05028, 0.78315, 0.05756, 0.84211, 0.47368, 1.0, 0.05263, 0.7255, 0.07631, 0.70301, 0.08141, 0.42105, 0.21053, 0.65419, 0.08968, 0.52632, -0.21053, 0.6015, 0.09534, 0.57418, 0.09719], [1.0, 0.0, -0.00641, -0.5, 0.0, 0.0, -0.01923, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3141, 0.92949, -0.35256, 0.74359, -0.34615, -0.80769, 0.0, 0.0, -0.61538, -0.51282, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 1.0, 0.45455, 1.0, 0.54545, 0.81818, 0.63636, 1.0, -0.09091, 1.0, 0.0, 0.81818, -0.45455, 0.63636, 0.27273, 1.0, -0.63636, 1.0, -0.27273, 0.90909, -0.45455, 1.0, 0.0775, 1.0, -0.09091, 1.0, 0.08867, 1.0, 0.36364, 1.0, 0.63636, 0.72727, 0.27273], [0.0, 0.0, -1.0, -1.0, 1.0, -1.0, -1.0, 1.0, 0.0, 0.0, 1.0, -1.0, 1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -1.0, 1.0, 1.0, -1.0, -1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.5, 0.0, 0.0], [1.0, 0.0, 0.45455, 0.09091, 0.63636, 0.09091, 0.27273, 0.18182, 0.63636, 0.0, 0.36364, -0.09091, 0.45455, -0.09091, 0.48612, -0.01343, 0.63636, -0.18182, 0.45455, 0.0, 0.36364, -0.09091, 0.27273, 0.18182, 0.36364, -0.09091, 0.34442, -0.01768, 0.27273, 0.0, 0.36364, 0.0, 0.28985, -0.01832], [1.0, 0.0, -1.0, -0.59677, 0.0, 0.0, -1.0, 0.64516, -0.87097, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.29839, 0.23387, 1.0, 0.51613, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 1.0, 0.14286, 1.0, 0.71429, 1.0, 0.71429, 1.0, -0.14286, 0.85714, -0.14286, 1.0, 0.02534, 1.0, 0.0, 0.42857, -0.14286, 1.0, 0.03617, 1.0, -0.28571, 1.0, 0.0, 0.28571, -0.28571, 1.0, 0.04891, 1.0, 0.05182, 1.0, 0.57143, 1.0, 0.0], [0.0, 0.0, 1.0, 1.0, 1.0, -1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, -1.0, 1.0, 1.0, 1.0, -1.0, 1.0, -1.0, 1.0, 1.0, 1.0, 1.0, 1.0, -1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], [1.0, 0.0, 0.87032, 0.46972, 0.53945, 0.82161, 0.1038, 0.95275, -0.38033, 0.87916, -0.73939, 0.58226, -0.92099, 0.16731, -0.82417, -0.24942, -0.59383, -0.63342, -0.24012, -0.82881, 0.18823, -0.78699, 0.51557, -0.5743, 0.69274, -0.24843, 0.69097, 0.10484, 0.52798, 0.39762, 0.25974, 0.56573, -0.06739, 0.57552], [0.0, 0.0, 1.0, -1.0, 1.0, 1.0, 1.0, -1.0, 1.0, 1.0, 1.0, -1.0, 1.0, -1.0, 1.0, -1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, -1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, -1.0], [1.0, 0.0, 0.92657, 0.04174, 0.89266, 0.15766, 0.86098, 0.19791, 0.83675, 0.36526, 0.80619, 0.40198, 0.76221, 0.40552, 0.66586, 0.4836, 0.60101, 0.51752, 0.53392, 0.5218, 0.48435, 0.54212, 0.42546, 0.55684, 0.3334, 0.55274, 0.26978, 0.54214, 0.22307, 0.53448, 0.14312, 0.49124, 0.11573, 0.46571], [0.0, 0.0, 1.0, 1.0, 1.0, -1.0, 1.0, -1.0, 1.0, 1.0, 0.0, 0.0, 1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0], [1.0, 0.0, 0.93537, 0.13645, 0.93716, 0.25359, 0.85705, 0.38779, 0.79039, 0.47127, 0.72352, 0.59942, 0.6526, 0.75, 0.5083, 0.73586, 0.41629, 0.82742, 0.25539, 0.85952, 0.13712, 0.85615, 0.00494, 0.88869, -0.07361, 0.7978, -0.20995, 0.78004, -0.33169, 0.71454, -0.38532, 0.64363, -0.47419, 0.55835], [0.0, 0.0, 1.0, -1.0, -1.0, 1.0, -1.0, 1.0, 1.0, 1.0, 1.0, 1.0, -1.0, -1.0, -1.0, -1.0, 1.0, 1.0, 1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 1.0, 0.0, 1.0, -1.0, 1.0, -1.0, -1.0, 1.0, -1.0, 1.0], [1.0, 0.0, 0.80627, 0.13069, 0.73061, 0.24323, 0.64615, 0.19038, 0.36923, 0.45577, 0.44793, 0.46439, 0.25, 0.57308, 0.25192, 0.37115, 0.15215, 0.51877, -0.09808, 0.575, -0.03462, 0.42885, -0.08856, 0.44424, -0.14943, 0.40006, -0.1994, 0.34976, -0.23832, 0.29541, -0.26634, 0.23896, -0.23846, 0.31154], [0.0, 0.0, 1.0, -1.0, 1.0, 1.0, 1.0, -1.0, 1.0, 1.0, 1.0, -1.0, 1.0, 1.0, 1.0, -1.0, 1.0, -1.0, 1.0, 1.0, 1.0, 1.0, 1.0, -1.0, 1.0, -1.0, 1.0, -1.0, 1.0, 1.0, 1.0, -1.0, 1.0, 1.0], [1.0, 0.0, 0.97467, 0.13082, 0.9412, 0.20036, 0.88783, 0.32248, 0.89009, 0.32711, 0.8555, 0.45217, 0.72298, 0.52284, 0.69946, 0.5882, 0.58548, 0.66893, 0.48869, 0.70398, 0.44245, 0.68159, 0.35289, 0.75622, 0.26832, 0.7621, 0.16813, 0.78541, 0.07497, 0.80439, -0.02962, 0.77702, -0.10289, 0.74242], [0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, -1.0, 0.0, 0.0, -1.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.92308, 0.15451, 0.86399, 0.29757, 0.72582, 0.3679, 0.70588, 0.5683, 0.57449, 0.62719, 0.4327, 0.74676, 0.31705, 0.67697, 0.19128, 0.76818, 0.04686, 0.76171, -0.12064, 0.76969, -0.18479, 0.71327, -0.29291, 0.65708, -0.38798, 0.58553, -0.46799, 0.50131, -0.53146, 0.40732, -0.56231, 0.35095], [0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, -1.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.88804, 0.38138, 0.65926, 0.69431, 0.29148, 0.87892, -0.06726, 0.90135, -0.39597, 0.80441, -0.64574, 0.56502, -0.8296, 0.26906, -0.7894, -0.08205, -0.6278, -0.30942, -0.46637, -0.55605, -0.16449, -0.64338, 0.09562, -0.61055, 0.30406, -0.48392, 0.43227, -0.29838, 0.47029, -0.09461, 0.42152, 0.12556], [0.0, 0.0, 1.0, -1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, -1.0, 1.0, 1.0, 1.0, 1.0, 1.0, -1.0, 1.0, -1.0, 1.0, -1.0, 1.0, -1.0, 1.0, 1.0, 1.0, -1.0, 1.0, 1.0, 1.0, 1.0], [1.0, 0.0, 0.73523, -0.38293, 0.80151, 0.10278, 0.78826, 0.15266, 0.5558, 0.05252, 1.0, 0.21225, 0.71947, 0.28954, 0.68798, 0.32925, 0.49672, 0.17287, 0.64333, -0.02845, 0.57399, 0.42528, 0.5312, 0.44872, 0.9453, 0.57549, 0.44174, 0.482, 0.12473, 1.0, 0.3507, 0.49721, 0.30588, 0.49831], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.94649, 0.00892, 0.97287, -0.0026, 0.98922, 0.00372, 0.95801, 0.01598, 0.94054, 0.0353, 0.97213, 0.04719, 0.98625, 0.01858, 0.94277, 0.07135, 0.98551, -0.00706, 0.9777, 0.0498, 0.96358, 0.07098, 0.93274, 0.08101, 0.95243, 0.04356, 0.97473, 0.00818, 0.97845, 0.07061, 1.0, -0.0026], [0.0, 0.0, 1.0, 1.0, -1.0, -1.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, -1.0, 0.0, 0.0, -1.0, -1.0, -1.0, -1.0], [1.0, 0.0, 0.50466, -0.169, 0.71442, 0.01513, 0.71063, 0.02258, 0.68065, 0.01282, 0.34615, 0.05594, 0.6905, 0.04393, 0.68101, 0.05058, 0.67023, 0.05692, 0.63403, -0.04662, 0.64503, 0.06856, 0.63077, 0.07381, 0.84033, 0.18065, 0.59935, 0.08304, 0.38228, 0.0676, 0.56466, 0.09046, 0.54632, 0.09346], [1.0, 0.0, 0.68729, 1.0, 0.91973, -0.76087, 0.81773, 0.04348, 0.76087, 0.10702, 0.86789, 0.73746, 0.70067, 0.18227, 0.7592, 0.13712, 0.93478, -0.25084, 0.70736, 0.18729, 0.64883, 0.24582, 0.60201, 0.77425, 1.0, -0.53846, 0.89262, 0.22216, 0.7107, 0.53846, 1.0, -0.06522, 0.56522, 0.23913], [1.0, 0.0, 0.76296, -0.07778, 1.0, -0.2963, 1.0, -0.85741, 0.8, 0.06111, 0.45556, -0.42778, 1.0, -0.12581, 1.0, -0.83519, 0.49259, 0.01852, 0.82222, -0.05926, 0.98215, -0.19938, 1.0, 0.22037, 0.6963, -0.26481, 0.92148, -0.24549, 0.78889, 0.02037, 0.87492, -0.27105, 1.0, -0.57037], [1.0, 0.0, 0.38521, 0.15564, 0.41245, 0.07393, 0.26459, 0.24125, 0.23346, 0.1323, 0.19455, 0.25292, 0.24514, 0.36965, 0.08949, 0.22957, -0.03891, 0.36965, 0.05058, 0.24903, 0.24903, 0.09728, 0.07782, 0.29961, -0.02494, 0.28482, -0.06024, 0.26256, -0.14786, 0.14786, -0.09339, 0.31128, -0.19066, 0.28794], [1.0, 0.0, 0.5754, -0.03175, 0.75198, -0.05357, 0.61508, -0.0119, 0.53968, 0.03373, 0.61706, 0.09921, 0.59127, -0.02381, 0.62698, 0.0119, 0.70833, 0.02579, 0.60317, 0.01587, 0.47817, -0.02778, 0.59127, 0.0377, 0.5, 0.03968, 0.61291, -0.01237, 0.61706, -0.13492, 0.68849, -0.01389, 0.625, -0.03175], [1.0, 0.0, 0.06404, -0.15271, -0.04433, 0.05911, 0.08374, -0.02463, -0.01478, 0.18719, 0.06404, 0.0, 0.12315, -0.09852, 0.05911, 0.0, 0.0197, -0.02956, -0.12808, -0.2069, 0.06897, 0.01478, 0.06897, 0.02956, 0.07882, 0.16256, 0.28079, -0.04926, -0.05911, -0.0936, 0.04433, 0.05419, 0.07389, -0.10837], [1.0, 0.0, 0.61857, 0.1085, 0.70694, -0.06935, 0.70358, 0.01678, 0.74273, 0.00224, 0.71029, 0.15772, 0.71588, -0.00224, 0.79754, 0.066, 0.83669, -0.16555, 0.6868, -0.0906, 0.62528, -0.01342, 0.60962, 0.11745, 0.71253, -0.09508, 0.69845, -0.01673, 0.63311, 0.0481, 0.78859, -0.05145, 0.65213, -0.04698], [1.0, 0.0, 0.25316, 0.35949, 0.0, 0.0, -0.2962, -1.0, 0.0, 0.0, 0.07595, -0.07342, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00759, 0.68101, -0.2, 0.33671, -0.1038, 0.35696, 0.0557, -1.0, 0.0, 0.0, 0.06329, -1.0, 0.0, 0.0], [1.0, 0.0, 0.88103, -0.00857, 0.89818, -0.02465, 0.94105, -0.01822, 0.89175, -0.12755, 0.82208, -0.10932, 0.88853, 0.01179, 0.90782, -0.13719, 0.87138, -0.06109, 0.90782, -0.02358, 0.87996, -0.14577, 0.82851, -0.12433, 0.90139, -0.19507, 0.88245, -0.14903, 0.84352, -0.12862, 0.88424, -0.18542, 0.91747, -0.16827], [1.0, 0.0, 0.42708, -0.5, 0.0, 0.0, 0.0, 0.0, 0.46458, 0.51042, 0.58958, 0.02083, 0.0, 0.0, 0.0, 0.0, 0.16458, -0.45417, 0.59167, -0.18333, 0.0, 0.0, 0.0, 0.0, 0.9875, -0.40833, -1.0, -1.0, -0.27917, -0.75625, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.88853, 0.01631, 0.92007, 0.01305, 0.92442, 0.01359, 0.89179, -0.10223, 0.90103, -0.08428, 0.9304, -0.01033, 0.93094, -0.08918, 0.86025, -0.05057, 0.89451, -0.04024, 0.88418, -0.12126, 0.88907, -0.11909, 0.8298, -0.14138, 0.86453, -0.11808, 0.85536, -0.13051, 0.83524, -0.12452, 0.86786, -0.12235], [1.0, 0.0, 0.0, 0.0, 1.0, 0.12889, 0.88444, -0.02, 0.0, 0.0, 1.0, -0.42444, 1.0, 0.19556, 1.0, -0.05333, 1.0, -0.81556, 0.0, 0.0, 1.0, -0.04, 1.0, -0.18667, 0.0, 0.0, 1.0, -1.0, 0.0, 0.0, 1.0, 0.11778, 0.90667, -0.09556], [1.0, 0.0, 0.81143, 0.03714, 0.85143, -0.00143, 0.79, 0.00714, 0.79571, -0.04286, 0.87571, 0.0, 0.85571, -0.06714, 0.86429, 0.00286, 0.82857, -0.05429, 0.81, -0.11857, 0.76857, -0.08429, 0.84286, -0.05, 0.77, -0.06857, 0.81598, -0.08669, 0.82571, -0.10429, 0.81429, -0.05, 0.82143, -0.15143], [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -1.0, 1.0, 1.0, 0.55172, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.4987, 0.01818, 0.43117, -0.0961, 0.50649, -0.04156, 0.5013, 0.0961, 0.44675, 0.05974, 0.55844, -0.11948, 0.51688, -0.03636, 0.52727, -0.05974, 0.55325, -0.01039, 0.48571, -0.03377, 0.49091, -0.01039, 0.59221, 0.0, 0.53215, -0.0328, 0.43117, 0.03377, 0.54545, -0.05455, 0.58961, -0.08571], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 1.0, 0.5, 1.0, 0.25, 0.25, 1.0, 0.16851, 0.9118, -0.13336, 0.80454, -0.34107, 0.60793, -0.4382, 0.37856, -0.43663, 0.16709, -0.36676, 0.00678, -0.26477, -0.09025, -0.16178, -0.12964, -0.07782, -0.12744, -0.02089, -0.10242, 0.01033, -0.07036, 0.02224, -0.04142, 0.02249, -0.02017], [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, -1.0, -1.0, 0.0, 0.0, 1.0, -0.11111, 0.0, 0.0, 0.0, 0.0, -1.0, 1.0, 1.0, 1.0, 1.0, -1.0, 0.0, 0.0, 1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0], [1.0, 0.0, 0.87048, 0.38027, 0.64099, 0.69212, 0.31347, 0.86625, -0.03933, 0.9074, -0.42173, 0.79346, -0.70561, 0.5156, -0.81049, 0.22735, -0.81136, -0.12539, -0.67474, -0.38102, -0.38334, -0.62861, -0.13013, -0.70762, 0.15552, -0.66421, 0.38544, -0.51568, 0.52573, -0.29897, 0.56239, -0.05938, 0.5146, 0.16645], [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -1.0, 1.0, 0.0, 0.0, 1.0, 0.37333, -0.12, -0.12, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, 1.0, -1.0, 0.0, 0.0, 1.0, 0.22667, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.88179, 0.43491, 0.59573, 0.77655, 0.19672, 0.94537, -0.24103, 0.92544, -0.62526, 0.71257, -0.86443, 0.33652, -0.92384, -0.05338, -0.77356, -0.44707, -0.4695, -0.73285, -0.10237, -0.82217, 0.26384, -0.7757, 0.55984, -0.5591, 0.72147, -0.24433, 0.72478, 0.09599, 0.58137, 0.38915, 0.34749, 0.57656], [1.0, 0.0, 0.32834, 0.0252, 0.15236, 0.21278, 0.14919, 0.74003, -0.25706, 0.92324, -0.10312, 0.1938, -0.61352, 0.25786, -0.94053, -0.05409, -0.13117, -0.14329, -0.30315, -0.44615, -0.11409, -0.85597, 0.02668, -0.22786, 0.27942, -0.06295, 0.33737, -0.11876, 0.27657, -0.11409, 0.15078, 0.13296, 0.12197, 0.20468], [1.0, 0.0, 0.83427, 0.39121, 0.5404, 0.78579, 0.12326, 0.89402, -0.33221, 0.83578, -0.70086, 0.59564, -0.86622, 0.21909, -0.84442, -0.24164, -0.59714, -0.61894, -0.19354, -0.87787, 0.12439, -0.89064, 0.51109, -0.72454, 0.79143, -0.27734, 0.83008, 0.08718, 0.66592, 0.49079, 0.37542, 0.70011, -0.03983, 0.79444], [1.0, 0.0, 0.62335, -0.0349, 0.59085, 0.00481, 0.60409, -0.07461, 0.63177, 0.00963, 0.62455, -0.07461, 0.67028, 0.0722, 0.62936, -0.08424, 0.67509, 0.09146, 0.67148, 0.0, 0.58965, 0.10108, 0.5006, 0.03129, 0.65945, 0.14079, 0.60463, 0.02019, 0.51384, 0.04452, 0.61733, -0.00963, 0.61372, -0.09146], [1.0, 0.0, 0.74449, -0.0239, 0.70772, 0.03309, 0.72243, 0.16912, 0.79228, 0.07721, 0.81434, 0.43934, 0.63787, 0.00551, 0.70772, 0.21691, 1.0, 0.06066, 0.61029, 0.05147, 0.67463, 0.04228, 0.52022, -0.25, 0.72978, -0.15809, 0.61727, 0.07124, 0.30882, 0.0864, 0.55916, 0.07458, 0.60294, 0.21691], [1.0, 0.0, 0.61538, 0.18923, 0.78157, 0.0178, 0.77486, 0.02647, 0.65077, -0.10308, 0.77538, 0.08, 0.73961, 0.0506, 0.72322, 0.05776, 0.68615, -0.08923, 0.61692, 0.16308, 0.66233, 0.07573, 0.63878, 0.08041, 0.60154, -0.07231, 0.58803, 0.08767, 0.55077, 0.25692, 0.53389, 0.09207, 0.50609, 0.09322], [1.0, 0.0, 0.68317, 0.05375, 0.84803, 0.00202, 0.84341, 0.00301, 0.843, 0.09901, 0.75813, 0.04102, 0.81892, 0.00585, 0.80738, 0.00673, 0.80622, -0.12447, 0.77935, -0.03536, 0.76365, 0.00909, 0.74635, 0.00978, 0.79632, -0.04243, 0.70824, 0.01096, 0.62235, 0.11598, 0.66624, 0.0119, 0.64407, 0.01227], [1.0, 0.0, 0.5, 0.0, 0.38696, 0.10435, 0.4913, 0.06522, 0.46957, -0.03913, 0.35652, -0.12609, 0.45652, 0.04783, 0.50435, 0.02609, 0.35652, 0.19565, 0.42174, 0.14783, 0.42174, -0.02609, 0.32174, -0.11304, 0.47391, -0.0087, 0.41789, 0.06908, 0.38696, 0.03913, 0.35217, 0.14783, 0.44783, 0.17391], [1.0, 0.0, 0.7983, 0.09417, 0.78129, 0.20656, 0.71628, 0.28068, 0.6932, 0.41252, 0.65917, 0.50122, 0.57898, 0.60814, 0.4921, 0.58445, 0.33354, 0.67861, 0.29587, 0.63548, 0.09599, 0.68104, 0.02066, 0.72236, -0.08748, 0.63183, -0.11925, 0.60696, -0.18226, 0.56015, -0.25516, 0.51701, -0.27339, 0.42467], [1.0, 0.0, 1.0, 0.09802, 1.0, 0.25101, 0.9839, 0.33044, 0.80365, 0.5302, 0.74977, 0.60297, 0.56937, 0.71942, 0.55311, 0.74079, 0.29452, 0.82193, 0.21137, 0.79777, 0.09709, 0.82162, -0.01734, 0.7987, -0.15144, 0.75596, -0.22839, 0.69187, -0.31713, 0.60948, -0.40291, 0.54522, -0.42815, 0.44534], [1.0, 0.0, 0.8941, 0.13425, 0.87001, 0.31543, 0.78896, 0.43388, 0.63388, 0.59975, 0.54003, 0.71016, 0.39699, 0.76161, 0.24266, 0.79523, 0.09134, 0.79598, -0.09159, 0.76261, -0.20201, 0.66926, -0.30263, 0.6261, -0.40552, 0.50489, -0.46215, 0.40753, -0.50314, 0.27252, -0.52823, 0.19172, -0.48808, 0.05972], [1.0, 0.0, 0.94631, 0.17498, 0.90946, 0.33143, 0.85096, 0.4996, 0.73678, 0.63842, 0.59215, 0.73838, 0.48698, 0.83614, 0.30459, 0.90665, 0.17959, 0.93429, -0.00701, 0.93109, -0.1888, 0.89383, -0.33023, 0.82492, -0.46534, 0.76482, -0.58563, 0.66335, -0.67929, 0.52564, -0.75321, 0.42488, -0.8121, 0.26092], [1.0, 0.0, 0.91767, 0.18198, 0.8609, 0.35543, 0.72873, 0.45747, 0.60425, 0.69865, 0.50376, 0.74922, 0.361, 0.81795, 0.15664, 0.83558, 0.00396, 0.8521, -0.1639, 0.77853, -0.35996, 0.76193, -0.43087, 0.65385, -0.5314, 0.53886, -0.60328, 0.40972, -0.64511, 0.27338, -0.6571, 0.13667, -0.64056, 0.05394], [1.0, 0.0, 0.76627, 0.21106, 0.63935, 0.38112, 0.48409, 0.525, 0.15, 0.22273, 0.13753, 0.59565, -0.07727, 0.44545, 0.0, 0.48636, -0.27491, 0.42014, -0.56136, 0.36818, -0.36591, 0.18864, -0.40533, 0.07588, -0.38483, -0.03229, -0.33942, -0.12486, -0.2754, -0.19714, -0.19962, -0.24648, -0.11894, -0.27218], [1.0, 0.0, 0.5894, -0.60927, 0.8543, 0.55298, 0.81126, 0.07285, 0.56623, 0.16225, 0.32781, 0.24172, 0.50331, 0.12252, 0.63907, 0.19868, 0.71854, 0.42715, 0.54305, 0.13907, 0.65232, 0.27815, 0.68874, 0.07285, 0.51872, 0.26653, 0.49013, 0.27687, 0.46216, 0.28574, 0.43484, 0.29324, 0.40821, 0.29942], [1.0, 0.0, 1.0, 0.11385, 0.70019, -0.12144, 0.81594, 0.09677, 0.71157, 0.01139, 0.56167, -0.0778, 0.6907, 0.12524, 0.58634, 0.03985, 0.53131, -0.03416, 0.6945, 0.16888, 0.72676, 0.07211, 0.32068, 0.05882, 0.53321, 0.37381, 0.4909, 0.17951, 0.1518, 0.32448, 0.44141, 0.18897, 0.56167, 0.1518], [1.0, 0.0, 0.84843, 0.06794, 0.80562, -0.02299, 0.77031, -0.03299, 0.66725, -0.0662, 0.59582, -0.07666, 0.6726, -0.05771, 0.6426, -0.06438, 0.39199, 0.0453, 0.71254, 0.01394, 0.5597, -0.08039, 0.5343, -0.08453, 0.47038, -0.22822, 0.48659, -0.09128, 0.52613, -0.08537, 0.44277, -0.09621, 0.42223, -0.09808], [1.0, 0.0, 1.0, 0.08013, 0.96775, -0.00482, 0.96683, -0.00722, 0.8798, -0.03923, 1.0, 0.01419, 0.96186, -0.01436, 0.95947, -0.01671, 0.98497, 0.01002, 0.91152, -0.08848, 0.95016, -0.02364, 0.94636, -0.02591, 0.98164, 0.02003, 0.93772, -0.03034, 1.0, -0.05843, 0.92774, -0.03464, 0.92226, -0.03673], [1.0, 0.0, 0.47938, -0.12371, 0.42784, -0.12371, 0.70103, -0.39175, 0.73196, 0.07216, 0.26289, -0.21649, 0.49485, 0.15979, 0.45361, -0.11856, 0.42268, 0.06186, 0.5, -0.2732, 0.54639, 0.18557, 0.42268, 0.08247, 0.70619, 0.19588, 0.53396, -0.12447, 0.15464, -0.26289, 0.47423, 0.04124, 0.45361, -0.51546], [1.0, 0.0, 0.6351, -0.04388, 0.7653, 0.02968, 0.61432, 0.36028, 0.65358, -0.00462, 0.64203, 0.08314, 0.79446, -0.43418, 0.72517, 0.54965, 0.59584, 0.13857, 0.6351, 0.2194, 0.63279, -0.25404, 0.70951, 0.15359, 0.64665, 0.23095, 0.68775, 0.17704, 0.61663, 0.07621, 0.66316, 0.19841, 0.69053, 0.36721], [1.0, 0.0, 0.50112, -0.03596, 0.61124, 0.01348, 0.58876, 0.01573, 0.58876, 0.02472, 0.66742, -0.00449, 0.71685, -0.04719, 0.66517, 0.00899, 0.57303, 0.02472, 0.64719, -0.07416, 0.56854, 0.14157, 0.57528, -0.03596, 0.46517, 0.04944, 0.56588, 0.00824, 0.4764, -0.03596, 0.54607, 0.10562, 0.60674, -0.0809], [1.0, 0.0, 0.71521, -0.00647, 0.66667, -0.04207, 0.63107, -0.05178, 0.77994, 0.08091, 0.67314, 0.09709, 0.64725, 0.15858, 0.60194, -0.01942, 0.54369, -0.04531, 0.46926, -0.10032, 0.64725, 0.14887, 0.39159, 0.21683, 0.52427, -0.05502, 0.45105, 0.0004, 0.31392, -0.06796, 0.49191, -0.1068, 0.30421, -0.05178], [1.0, 0.0, 0.68148, 0.1037, 0.77037, 0.03457, 0.65185, 0.08148, 0.60988, -0.00494, 0.79012, 0.11852, 0.59753, 0.04938, 0.62469, 0.0963, 0.78272, -0.17531, 0.73827, -0.10864, 0.48642, 0.00988, 0.60988, 0.08148, 0.66667, -0.1284, 0.63773, -0.02451, 0.76543, 0.02222, 0.61235, -0.0716, 0.51358, -0.04691], [1.0, 0.0, 0.60678, -0.02712, 0.67119, 0.04068, 0.52881, -0.04407, 0.50508, 0.03729, 0.70508, -0.07797, 0.57966, -0.02034, 0.5322, 0.07797, 0.64068, 0.11864, 0.56949, -0.02373, 0.5322, 0.00678, 0.71525, -0.0339, 0.52881, -0.0339, 0.57262, 0.0075, 0.58644, -0.00339, 0.58983, -0.02712, 0.50169, 0.0678], [1.0, 0.0, 0.49515, 0.09709, 0.29612, 0.05825, 0.34951, 0.0, 0.57282, -0.02427, 0.58252, 0.02427, 0.33495, 0.04854, 0.52427, 0.00485, 0.47087, -0.1068, 0.43204, 0.00485, 0.34951, 0.05825, 0.18932, 0.25728, 0.31068, -0.15049, 0.36547, 0.03815, 0.3932, 0.17476, 0.26214, 0.0, 0.37379, -0.01942], [1.0, 0.0, 0.98822, 0.02187, 0.93102, 0.341, 0.83904, 0.35222, 0.74706, 0.48906, 0.73584, 0.51879, 0.55076, 0.60179, 0.4313, 0.66237, 0.318, 0.70443, 0.28379, 0.68873, 0.07515, 0.73696, 0.06338, 0.71284, -0.16489, 0.69714, -0.16556, 0.6051, -0.16209, 0.55805, -0.34717, 0.44195, -0.33483, 0.37465], [1.0, 0.0, 0.97905, 0.1581, 0.90112, 0.35237, 0.82039, 0.48561, 0.7176, 0.64888, 0.58827, 0.73743, 0.40349, 0.83156, 0.2514, 0.84804, 0.047, 0.85475, -0.12193, 0.79749, -0.2618, 0.80754, -0.37835, 0.71676, -0.51034, 0.58324, -0.57587, 0.4604, -0.61899, 0.30796, -0.65754, 0.18345, -0.64134, 0.02968], [1.0, 0.0, 0.99701, 0.21677, 0.91966, 0.4703, 0.76902, 0.62415, 0.53312, 0.7812, 0.36774, 0.88291, 0.10107, 0.83312, -0.06827, 0.89274, -0.28269, 0.72073, -0.43707, 0.61688, -0.55769, 0.4812, -0.65, 0.35534, -0.64658, 0.15908, -0.66651, 0.02277, -0.64872, -0.13462, -0.54615, -0.22949, -0.47201, -0.35032], [1.0, 0.0, 0.94331, 0.19959, 0.96132, 0.40803, 0.80514, 0.56569, 0.56687, 0.7083, 0.41836, 0.8323, 0.14939, 0.89489, 0.05167, 0.93682, -0.24742, 0.83939, -0.42811, 0.75554, -0.50251, 0.62563, -0.65515, 0.50428, -0.68851, 0.30912, -0.77097, 0.15619, -0.75406, -0.04399, -0.75199, -0.17921, -0.66932, -0.34367], [1.0, 0.0, 0.93972, 0.28082, 0.80486, 0.52821, 0.58167, 0.73151, 0.34961, 0.80511, 0.10797, 0.90403, -0.20015, 0.89335, -0.3973, 0.82163, -0.58835, 0.62867, -0.76305, 0.40368, -0.81262, 0.18888, -0.81317, -0.04284, -0.75273, -0.26883, -0.63237, -0.46438, -0.46422, -0.61446, -0.26389, -0.70835, -0.08937, -0.71273], [1.0, 0.0, 0.89835, 0.35157, 0.67333, 0.62233, 0.43898, 0.94353, -0.03643, 0.8051, -0.22838, 0.75334, -0.25137, 0.48816, -0.57377, 0.28415, -0.6675, 0.10591, -0.47359, -0.06193, -0.81056, -0.06011, -0.33197, -0.47592, -0.12897, -0.5362, 0.07158, -0.51925, 0.24321, -0.43478, 0.36586, -0.30057, 0.42805, 0.13297], [1.0, 0.0, 0.29073, 0.10025, 0.23308, 0.17293, 0.03759, 0.34336, 0.1203, 0.26316, 0.06266, 0.21303, -0.04725, 0.12767, -0.06333, 0.07907, -0.06328, 0.04097, -0.05431, 0.01408, -0.04166, -0.0028, -0.02876, -0.01176, -0.01755, -0.01505, -0.00886, -0.01475, -0.0028, -0.0125, 0.00096, -0.00948, 0.0029, -0.00647], [1.0, 0.0, 0.58459, -0.35526, 1.0, 0.35338, 0.75376, -0.00564, 0.82519, 0.19361, 0.50188, -0.27632, 0.65977, 0.06391, 0.69737, 0.14662, 0.72368, -0.42669, 0.76128, 0.04511, 0.66917, 0.20489, 0.84774, -0.40977, 0.6485, -0.04699, 0.56836, -0.10571, 0.5282, -0.13346, 0.15602, -0.12218, 0.44767, -0.10309], [1.0, 0.0, 0.83609, 0.13215, 0.72171, 0.06059, 0.65829, 0.08315, 0.23888, 0.12961, 0.43837, 0.2033, 0.49418, 0.12686, 0.44747, 0.13507, 0.29352, 0.02922, 0.48158, 0.15756, 0.32835, 0.14616, 0.29495, 0.14638, 0.26436, 0.1453, 0.23641, 0.14314, 0.26429, 0.16137, 0.18767, 0.13632, 0.16655, 0.13198], [1.0, 0.0, 0.9408, 0.11933, 0.85738, 0.01038, 0.85124, 0.01546, 0.76966, -0.00278, 0.84459, 0.10916, 0.83289, 0.03027, 0.8268, 0.03506, 0.74838, 0.01943, 0.80019, 0.02405, 0.80862, 0.04901, 0.80259, 0.05352, 0.77336, 0.0222, 0.79058, 0.06235, 0.85939, 0.09251, 0.77863, 0.0709, 0.77269, 0.07508], [1.0, 0.0, 0.87111, 0.04326, 0.79946, 0.18297, 0.99009, 0.29292, 0.89455, -0.08337, 0.88598, -0.02028, 0.90446, -0.26724, 0.8941, 0.19964, 0.88644, -0.04642, 0.84452, -0.00991, 0.97882, -0.34024, 0.78954, -0.25101, 0.86661, -0.09193, 0.85967, -0.02908, 0.78774, -0.04101, 0.75935, 0.21812, 0.88238, 0.09193], [1.0, 0.0, 0.74916, 0.02549, 0.98994, 0.09792, 0.75855, 0.12877, 0.74313, -0.09188, 0.95842, 0.02482, 0.97921, -0.00469, 0.9611, 0.10195, 0.91482, 0.03756, 0.71026, 0.02683, 0.81221, -0.08048, 1.0, 0.0, 0.71764, -0.01207, 0.82271, 0.02552, 0.72435, -0.01073, 0.90409, 0.11066, 0.72837, 0.0275], [1.0, 0.0, 0.47337, 0.19527, 0.06213, -0.18343, 0.62316, 0.01006, 0.45562, -0.04438, 0.56509, 0.01775, 0.44675, 0.27515, 0.71598, -0.03846, 0.55621, 0.12426, 0.4142, 0.11538, 0.52767, 0.02842, 0.51183, -0.10651, 0.47929, -0.02367, 0.46514, 0.03259, 0.5355, 0.25148, 0.31953, -0.14497, 0.34615, -0.00296], [1.0, 0.0, 0.59887, 0.14689, 0.69868, -0.13936, 0.85122, -0.13936, 0.80979, 0.02448, 0.50471, 0.02825, 0.6742, -0.0452, 0.80791, -0.13748, 0.51412, -0.24482, 0.81544, -0.14313, 0.70245, -0.00377, 0.33333, 0.06215, 0.56121, -0.33145, 0.61444, -0.16837, 0.52731, -0.02072, 0.53861, -0.31262, 0.6742, -0.22034], [1.0, 0.0, 0.84713, -0.03397, 0.86412, -0.08493, 0.81953, 0.0, 0.73673, -0.07643, 0.71975, -0.13588, 0.74947, -0.11677, 0.77495, -0.18684, 0.78132, -0.21231, 0.61996, -0.10191, 0.79193, -0.15711, 0.89384, -0.03397, 0.84926, -0.26115, 0.74115, -0.23312, 0.66242, -0.22293, 0.72611, -0.37792, 0.65817, -0.24841], [1.0, 0.0, 0.87772, -0.08152, 0.83424, 0.07337, 0.84783, 0.04076, 0.77174, -0.02174, 0.77174, -0.05707, 0.82337, -0.10598, 0.67935, -0.00543, 0.88043, -0.20924, 0.83424, 0.03261, 0.86413, -0.05978, 0.97283, -0.27989, 0.85054, -0.1875, 0.83705, -0.10211, 0.8587, -0.03261, 0.78533, -0.1087, 0.79076, -0.00543], [1.0, 0.0, 0.74704, -0.13241, 0.53755, 0.16996, 0.72727, 0.09486, 0.69565, -0.11067, 0.66798, -0.23518, 0.87945, -0.1917, 0.73715, 0.0415, 0.63043, -0.00395, 0.63636, -0.11858, 0.79249, -0.25296, 0.66403, -0.28656, 0.67194, -0.10474, 0.61847, -0.12041, 0.60079, -0.20949, 0.37549, 0.06917, 0.61067, -0.01383], [1.0, 0.0, 0.46785, 0.11308, 0.5898, 0.00665, 0.55432, 0.06874, 0.47894, -0.13969, 0.52993, 0.0133, 0.63858, -0.16186, 0.67849, -0.03326, 0.54545, -0.13525, 0.52993, -0.04656, 0.47894, -0.19512, 0.50776, -0.13525, 0.41463, -0.20177, 0.5393, -0.11455, 0.59867, -0.02882, 0.53659, -0.11752, 0.56319, -0.04435], [1.0, 0.0, 0.88116, 0.27475, 0.72125, 0.42881, 0.61559, 0.63662, 0.38825, 0.90502, 0.09831, 0.96128, -0.20097, 0.892, -0.35737, 0.775, -0.65114, 0.6221, -0.78768, 0.45535, -0.81856, 0.19095, -0.83943, -0.08079, -0.78334, -0.26356, -0.67557, -0.45511, -0.54732, -0.60858, -0.30512, -0.667, -0.19312, -0.75597], [1.0, 0.0, 0.93147, 0.29282, 0.79917, 0.55756, 0.59952, 0.71596, 0.26203, 0.92651, 0.04636, 0.96748, -0.23237, 0.9513, -0.55926, 0.81018, -0.73329, 0.62385, -0.90995, 0.362, -0.92254, 0.0604, -0.93618, -0.19838, -0.83192, -0.46906, -0.65165, -0.69556, -0.41223, -0.85725, -0.1359, -0.93953, 0.10007, -0.94823], [1.0, 0.0, 0.88241, 0.30634, 0.73232, 0.57816, 0.34109, 0.58527, 0.05717, 1.0, -0.09238, 0.92118, -0.62403, 0.71996, -0.69767, 0.32558, -0.81422, 0.41195, -1.0, -0.00775, -0.78973, -0.41085, -0.76901, -0.45478, -0.57242, -0.67605, -0.3161, -0.81876, -0.02979, -0.86841, 0.25392, -0.82127, 0.00194, -0.81686], [1.0, 0.0, 0.83479, 0.28993, 0.69256, 0.47702, 0.49234, 0.68381, 0.21991, 0.86761, -0.08096, 0.85011, -0.35558, 0.77681, -0.52735, 0.58425, -0.7035, 0.31291, -0.75821, 0.03939, -0.71225, -0.15317, -0.58315, -0.39168, -0.37199, -0.52954, -0.1695, -0.60863, 0.08425, -0.61488, 0.25164, -0.48468, 0.40591, -0.35339], [1.0, 0.0, 0.9287, 0.33164, 0.76168, 0.62349, 0.49305, 0.84266, 0.21592, 0.95193, -0.13956, 0.96167, -0.47202, 0.8359, -0.70747, 0.6549, -0.87474, 0.3675, -0.91814, 0.05595, -0.89824, -0.26173, -0.73969, -0.54069, -0.50757, -0.74735, -0.22323, -0.86122, 0.0781, -0.87159, 0.36021, -0.78057, 0.59407, -0.6027], [1.0, 0.0, 0.83367, 0.31456, 0.65541, 0.57671, 0.34962, 0.70677, 0.17293, 0.78947, -0.18976, 0.79886, -0.41729, 0.66541, -0.68421, 0.47744, -0.74725, 0.19492, -0.7218, -0.04887, -0.6203, -0.28195, -0.49165, -0.53463, -0.26577, -0.66014, -0.0153, -0.69706, 0.22708, -0.64428, 0.431, -0.51206, 0.64662, -0.30075], [1.0, 0.0, 0.98455, -0.02736, 0.98058, -0.04104, 1.0, -0.07635, 0.9872, 0.01456, 0.95278, -0.02604, 0.985, -0.07458, 0.99382, -0.07149, 0.97396, -0.09532, 0.97264, -0.12224, 0.99294, -0.05252, 0.95278, -0.08914, 0.97352, -0.08341, 0.96653, -0.12912, 0.93469, -0.14916, 0.97132, -0.15755, 0.96778, -0.188], [1.0, 0.0, 0.94052, -0.01531, 0.9417, 0.01001, 0.94994, -0.01472, 0.95878, -0.0106, 0.94641, -0.0371, 0.97173, -0.01767, 0.97055, -0.03887, 0.95465, -0.04064, 0.9523, -0.04711, 0.94229, -0.02179, 0.92815, -0.04417, 0.92049, -0.04476, 0.92695, -0.05827, 0.90342, -0.07479, 0.91991, -0.07244, 0.92049, -0.0742], [1.0, 0.0, 0.97032, -0.14384, 0.91324, -0.00228, 0.96575, -0.17123, 0.9863, 0.18265, 0.91781, 0.00228, 0.93607, -0.08447, 0.91324, -0.00228, 0.86758, -0.08676, 0.97032, -0.21233, 1.0, 0.10274, 0.92009, -0.05251, 0.92466, 0.06849, 0.94043, -0.09252, 0.97032, -0.20091, 0.85388, -0.08676, 0.96575, -0.21918], [1.0, 0.0, 0.52542, -0.0339, 0.94915, 0.08475, 0.52542, -0.16949, 0.30508, -0.01695, 0.50847, -0.13559, 0.64407, 0.28814, 0.83051, -0.35593, 0.54237, 0.01695, 0.55932, 0.0339, 0.59322, 0.30508, 0.86441, 0.05085, 0.40678, 0.15254, 0.67287, -0.00266, 0.66102, -0.0339, 0.83051, -0.15254, 0.76271, -0.10169], [1.0, 0.0, 0.33333, -0.25, 0.44444, 0.22222, 0.38889, 0.16667, 0.41667, 0.13889, 0.5, -0.11111, 0.54911, -0.08443, 0.58333, 0.33333, 0.55556, 0.02778, 0.25, -0.19444, 0.47222, -0.05556, 0.52778, -0.02778, 0.38889, 0.08333, 0.41543, -0.14256, 0.19444, -0.13889, 0.36924, -0.14809, 0.08333, -0.5], [1.0, 0.0, 0.51207, 1.0, 1.0, 0.5381, 0.71178, 0.80833, 0.45622, 0.46427, 0.33081, 1.0, 0.21249, 1.0, -0.17416, 1.0, -0.33081, 0.98722, -0.61382, 1.0, -0.52674, 0.71699, -0.885, 0.47894, -1.0, 0.35175, -1.0, 0.09569, -1.0, -0.16713, -1.0, -0.42226, -0.91903, -0.65557], [1.0, 0.0, 0.75564, 0.49638, 0.8355, 0.54301, 0.54916, 0.72063, 0.35225, 0.70792, 0.13469, 0.94749, -0.09818, 0.93778, -0.37604, 0.82223, -0.52742, 0.71161, -0.68358, 0.67989, -0.70163, 0.24956, -0.79147, 0.02995, -0.98988, -0.29099, -0.70352, -0.32792, -0.63312, -0.19185, -0.34131, -0.60454, -0.19609, -0.62956], [1.0, 0.0, 0.83789, 0.42904, 0.72113, 0.58385, 0.45625, 0.78115, 0.1647, 0.82732, -0.13012, 0.86947, -0.46177, 0.78497, -0.59435, 0.5207, -0.7847, 0.26529, -0.84014, 0.03928, -0.62041, -0.31351, -0.47412, -0.48905, -0.37298, -0.67796, -0.05054, -0.62691, 0.1469, -0.45911, 0.37093, -0.39167, 0.48319, -0.24313], [1.0, 0.0, 0.93658, 0.35107, 0.75254, 0.6564, 0.45571, 0.88576, 0.15323, 0.95776, -0.21775, 0.96301, -0.56535, 0.83397, -0.78751, 0.58045, -0.93104, 0.2602, -0.93641, -0.06418, -0.87028, -0.40949, -0.65079, -0.67464, -0.36799, -0.84951, -0.04578, -0.91221, 0.2733, -0.85762, 0.54827, -0.69613, 0.74828, -0.44173], [1.0, 0.0, 0.92436, 0.36924, 0.71976, 0.6842, 0.29303, 0.94078, -0.11108, 0.76527, -0.31605, 0.92453, -0.66616, 0.78766, -0.92145, 0.42314, -0.94315, 0.09585, -1.0, 0.03191, -0.66431, -0.66278, -0.4601, -0.78174, -0.13486, -0.88082, 0.19765, -0.85137, 0.48904, -0.70247, 0.69886, -0.46048, 0.76066, -0.13194], [1.0, 0.0, 1.0, 0.16195, 1.0, -0.05558, 1.0, 0.01373, 1.0, -0.12352, 1.0, -0.01511, 1.0, -0.01731, 1.0, -0.06374, 1.0, -0.07157, 1.0, 0.059, 1.0, -0.10108, 1.0, -0.02685, 1.0, -0.22978, 1.0, -0.06823, 1.0, 0.08299, 1.0, -0.14194, 1.0, -0.07439], [1.0, 0.0, 0.95559, -0.00155, 0.86421, -0.13244, 0.94982, -0.00461, 0.82809, -0.51171, 0.92441, 0.10368, 1.0, -0.14247, 0.99264, -0.02542, 0.95853, -0.15518, 0.84013, 0.61739, 1.0, -0.16321, 0.87492, -0.08495, 0.85741, -0.01664, 0.84132, -0.01769, 0.82427, -0.01867, 0.80634, -0.01957, 0.78761, -0.02039], [1.0, 0.0, 0.79378, 0.29492, 0.64064, 0.52312, 0.41319, 0.68158, 0.14177, 0.83548, -0.16831, 0.78772, -0.42911, 0.72328, -0.57165, 0.41471, -0.75436, 0.16755, -0.69977, -0.09856, -0.57695, -0.23503, -0.40637, -0.38287, -0.17437, -0.5254, 0.01523, -0.48707, 0.1903, -0.38059, 0.31008, -0.23199, 0.34572, -0.08036], [1.0, 0.0, 0.88085, 0.35232, 0.68389, 0.65128, 0.34816, 0.79784, 0.05832, 0.90842, -0.29784, 0.8649, -0.62635, 0.6959, -0.77106, 0.39309, -0.85803, 0.08408, -0.81641, -0.24017, -0.64579, -0.50022, -0.39766, -0.68337, -0.11147, -0.75533, 0.17041, -0.71504, 0.40675, -0.57649, 0.56626, -0.36765, 0.62765, -0.13305], [1.0, 0.0, 0.89589, 0.39286, 0.66129, 0.71804, 0.29521, 0.90824, -0.04787, 0.94415, -0.45725, 0.84605, -0.7766, 0.58511, -0.92819, 0.25133, -0.92282, -0.15315, -0.76064, -0.48404, -0.50931, -0.76197, -0.14895, -0.88591, 0.21581, -0.85703, 0.53229, -0.68593, 0.74846, -0.40656, 0.83142, -0.07029, 0.76862, 0.27926], [1.0, 0.0, 1.0, -0.24051, 1.0, -0.20253, 0.87342, -0.10127, 0.88608, 0.01266, 1.0, 0.11392, 0.92405, 0.06329, 0.8481, -0.03797, 0.63291, -0.36709, 0.87342, -0.01266, 0.93671, 0.06329, 1.0, 0.25316, 0.62025, -0.37975, 0.84637, -0.0554, 1.0, -0.06329, 0.53165, 0.02532, 0.83544, -0.02532], [1.0, 0.0, 0.7479, 0.0084, 0.83312, 0.01659, 0.82638, 0.02469, 0.86555, 0.01681, 0.60504, 0.05882, 0.79093, 0.04731, 0.77441, 0.05407, 0.64706, 0.19328, 0.84034, 0.04202, 0.71285, 0.07122, 0.68895, 0.07577, 0.66387, 0.08403, 0.63728, 0.08296, 0.61345, 0.01681, 0.58187, 0.08757, 0.5533, 0.08891], [1.0, 0.0, 0.85013, 0.01809, 0.92211, 0.01456, 0.92046, 0.0218, 0.92765, 0.0801, 0.87597, 0.1137, 0.91161, 0.0432, 0.90738, 0.05018, 0.87339, 0.02842, 0.95866, 0.0, 0.89097, 0.07047, 0.8843, 0.07697, 0.83721, 0.10853, 0.86923, 0.0895, 0.87597, 0.08786, 0.85198, 0.10134, 0.84258, 0.10698], [1.0, 0.0, 1.0, -0.01179, 1.0, -0.00343, 1.0, -0.01565, 1.0, -0.01565, 1.0, -0.02809, 1.0, -0.02187, 0.99828, -0.03087, 0.99528, -0.03238, 0.99314, -0.03452, 1.0, -0.03881, 1.0, -0.05039, 1.0, -0.04931, 0.99842, -0.05527, 0.994, -0.06304, 0.99057, -0.06497, 0.98971, -0.06668], [1.0, 0.0, 0.89505, -0.03168, 0.87525, 0.05545, 0.89505, 0.01386, 0.92871, 0.02772, 0.91287, -0.0099, 0.94059, -0.01584, 0.91881, 0.03366, 0.93663, 0.0, 0.94257, 0.01386, 0.90495, 0.00792, 0.88713, -0.01782, 0.89307, 0.02376, 0.89002, 0.01611, 0.88119, 0.00198, 0.87327, 0.04158, 0.86733, 0.02376], [1.0, 0.0, 0.90071, 0.01773, 1.0, -0.01773, 0.90071, 0.00709, 0.84752, 0.05674, 1.0, 0.03546, 0.97872, 0.01064, 0.97518, 0.03546, 1.0, -0.03191, 0.89716, -0.03191, 0.8617, 0.07801, 1.0, 0.0922, 0.90071, 0.0461, 0.94305, 0.03247, 0.94681, 0.02482, 1.0, 0.01064, 0.93617, 0.02128], [1.0, 0.0, 0.39394, -0.24242, 0.62655, 0.0127, 0.45455, 0.09091, 0.63636, 0.09091, 0.21212, -0.21212, 0.57576, 0.15152, 0.39394, 0.0, 0.56156, 0.04561, 0.51515, 0.0303, 0.78788, 0.18182, 0.30303, -0.15152, 0.48526, 0.05929, 0.46362, 0.06142, 0.33333, -0.0303, 0.41856, 0.0641, 0.39394, 0.24242], [1.0, 0.0, 0.86689, 0.3595, 0.72014, 0.66667, 0.37201, 0.83049, 0.08646, 0.85893, -0.24118, 0.86121, -0.51763, 0.67577, -0.68714, 0.41524, -0.77019, 0.09898, -0.69397, -0.13652, -0.49488, -0.42207, -0.32537, -0.57679, -0.02844, -0.59954, 0.1536, -0.53127, 0.32309, -0.37088, 0.46189, -0.19681, 0.40956, 0.0182], [1.0, 0.0, 0.89563, 0.37917, 0.67311, 0.69438, 0.35916, 0.88696, -0.04193, 0.93345, -0.38875, 0.84414, -0.67274, 0.62078, -0.8268, 0.30356, -0.8615, -0.05365, -0.73564, -0.34275, -0.51778, -0.62443, -0.23428, -0.73855, 0.06911, -0.73856, 0.33531, -0.62296, 0.52414, -0.42086, 0.61217, -0.17343, 0.60073, 0.0866], [1.0, 0.0, 0.90547, 0.41113, 0.65354, 0.74761, 0.29921, 0.95905, -0.13342, 0.9782, -0.52236, 0.83263, -0.79657, 0.55086, -0.96631, 0.15192, -0.93001, -0.25554, -0.71863, -0.59379, -0.41546, -0.85205, -0.0225, -0.93788, 0.36318, -0.85368, 0.67538, -0.61959, 0.85977, -0.28123, 0.88654, 0.098, 0.75495, 0.46301], [1.0, 0.0, 1.0, 1.0, 0.367, 0.06158, 0.12993, 0.92713, -0.27586, 0.93596, -0.31527, 0.37685, -0.87192, 0.36946, -0.92857, -0.08867, -0.38916, -0.34236, -0.46552, -0.82512, -0.05419, -0.93596, 0.25616, -0.20443, 0.73792, -0.4595, 0.85471, -0.06831, 1.0, 1.0, 0.3867, 0.00246, 0.17758, 0.7979], [1.0, 0.0, 1.0, 0.51515, 0.45455, 0.33333, 0.06061, 0.36364, -0.32104, 0.73062, -0.45455, 0.48485, -0.57576, 0.0, -0.57576, -0.12121, -0.33333, -0.48485, -0.09091, -0.84848, 0.48485, -0.57576, 0.57576, -0.42424, 1.0, -0.39394, 0.72961, 0.12331, 0.9697, 0.57576, 0.24242, 0.36364, 0.09091, 0.33333], [1.0, 0.0, 0.8811, 0.0, 0.94817, -0.02744, 0.93598, -0.0122, 0.90244, 0.01829, 0.90244, 0.01829, 0.93902, 0.00915, 0.95732, 0.00305, 1.0, 0.02744, 0.94207, -0.0122, 0.90854, 0.02439, 0.91463, 0.05488, 0.99695, 0.04878, 0.89666, 0.02226, 0.90854, 0.00915, 1.0, 0.05488, 0.97561, -0.0122], [1.0, 0.0, 0.82624, 0.08156, 0.79078, -0.08156, 0.90426, -0.01773, 0.92908, 0.01064, 0.80142, 0.08865, 0.94681, -0.00709, 0.94326, 0.0, 0.93262, 0.20213, 0.95035, -0.00709, 0.91489, 0.00709, 0.80496, 0.07092, 0.91135, 0.15957, 0.89527, 0.08165, 0.7766, 0.06738, 0.92553, 0.18085, 0.92553, 0.0], [1.0, 0.0, 0.74468, 0.10638, 0.88706, 0.00982, 0.88542, 0.01471, 0.87234, -0.01418, 0.7305, 0.10638, 0.87657, 0.02912, 0.87235, 0.03382, 0.95745, 0.07801, 0.95035, 0.04255, 0.85597, 0.04743, 0.84931, 0.05178, 0.87234, 0.11348, 0.83429, 0.06014, 0.74468, -0.03546, 0.8171, 0.068, 0.80774, 0.07173], [1.0, 0.0, 0.87578, 0.03727, 0.89951, 0.00343, 0.8921, 0.0051, 0.86335, 0.0, 0.95031, 0.07453, 0.87021, 0.00994, 0.86303, 0.01151, 0.83851, -0.06211, 0.85714, 0.02484, 0.84182, 0.01603, 0.83486, 0.01749, 0.79503, -0.04348, 0.82111, 0.02033, 0.81988, 0.08696, 0.80757, 0.02308, 0.80088, 0.02441], [1.0, 0.0, 0.97513, 0.0071, 0.98579, 0.01954, 1.0, 0.01954, 0.9929, 0.01599, 0.95737, 0.02309, 0.97158, 0.03552, 1.0, 0.0373, 0.97869, 0.02131, 0.98579, 0.05684, 0.97158, 0.04796, 0.94494, 0.05506, 0.98401, 0.03552, 0.9754, 0.06477, 0.94849, 0.08171, 0.99112, 0.06217, 0.98934, 0.09947], [1.0, 0.0, 1.0, 0.01105, 1.0, 0.01105, 1.0, 0.0232, 0.99448, -0.01436, 0.99448, -0.00221, 0.98343, 0.0232, 1.0, 0.00884, 0.97569, 0.00773, 0.97901, 0.01657, 0.98011, 0.00663, 0.98122, 0.02099, 0.97127, -0.00663, 0.98033, 0.016, 0.97901, 0.01547, 0.98564, 0.02099, 0.98674, 0.02762], [1.0, 0.0, 1.0, -0.01342, 1.0, 0.01566, 1.0, -0.00224, 1.0, 0.06264, 0.97763, 0.04474, 0.95973, 0.02908, 1.0, 0.06488, 0.98881, 0.03356, 1.0, 0.03579, 0.99776, 0.09396, 0.95749, 0.07383, 1.0, 0.10067, 0.99989, 0.08763, 0.99105, 0.08501, 1.0, 0.10067, 1.0, 0.10067], [1.0, 0.0, 0.8842, 0.36724, 0.67123, 0.67382, 0.39613, 0.86399, 0.02424, 0.93182, -0.35148, 0.83713, -0.60316, 0.58842, -0.78658, 0.38778, -0.83285, -0.00642, -0.69318, -0.32963, -0.52504, -0.53924, -0.27377, -0.68126, 0.00806, -0.69774, 0.26028, -0.60678, 0.44569, -0.43383, 0.54209, -0.21542, 0.56286, 0.02823], [1.0, 0.0, 0.90147, 0.41786, 0.64131, 0.75725, 0.3044, 0.95148, -0.20449, 0.96534, -0.55483, 0.81191, -0.81857, 0.50949, -0.96986, 0.10345, -0.91456, -0.31412, -0.70163, -0.65461, -0.32354, -0.88999, 0.05865, -0.94172, 0.44483, -0.82154, 0.74105, -0.55231, 0.89415, -0.18725, 0.87893, 0.20359, 0.70555, 0.54852], [1.0, 0.0, 0.32789, 0.11042, 0.1597, 0.29308, 0.1402, 0.74485, -0.25131, 0.91993, -0.16503, 0.26664, -0.63714, 0.24865, -0.9765, -0.00337, -0.23227, -0.19909, -0.30522, -0.48886, -0.14426, -0.89991, 0.09345, -0.28916, 0.28307, -0.1856, 0.39599, -0.11498, 0.31005, 0.05614, 0.21443, 0.2054, 0.13376, 0.26422], [1.0, 0.0, 0.65845, 0.43617, 0.44681, 0.74804, 0.05319, 0.85106, -0.32027, 0.82139, -0.68253, 0.52408, -0.84211, 0.07111, -0.82811, -0.28723, -0.47032, -0.71725, -0.04759, -0.86002, 0.23292, -0.76316, 0.56663, -0.52128, 0.743, -0.18645, 0.74758, 0.23713, 0.45185, 0.59071, 0.20549, 0.76764, -0.18533, 0.74356], [1.0, 0.0, 0.19466, 0.05725, 0.04198, 0.25191, -0.10557, 0.48866, -0.18321, -0.18321, -0.41985, 0.06107, -0.4542, 0.0916, -0.16412, -0.30534, -0.10305, -0.39695, 0.18702, -0.17557, 0.34012, -0.11953, 0.28626, -0.16031, 0.21645, 0.24692, 0.03913, 0.31092, -0.03817, 0.26336, -0.16794, 0.16794, -0.30153, -0.33588], [1.0, 0.0, 0.98002, 0.00075, 1.0, 0.0, 0.98982, -0.00075, 0.94721, 0.02394, 0.977, 0.0213, 0.97888, 0.03073, 0.9917, 0.02338, 0.93929, 0.05713, 0.93552, 0.05279, 0.97738, 0.05524, 1.0, 0.06241, 0.94155, 0.08107, 0.96709, 0.07255, 0.95701, 0.08088, 0.9819, 0.08126, 0.97247, 0.08616], [1.0, 0.0, 0.82254, -0.07572, 0.80462, 0.00231, 0.87514, -0.01214, 0.86821, -0.07514, 0.72832, -0.11734, 0.84624, 0.05029, 0.83121, -0.07399, 0.74798, 0.06705, 0.78324, 0.06358, 0.86763, -0.0237, 0.78844, -0.06012, 0.74451, -0.0237, 0.76717, -0.02731, 0.74046, -0.0763, 0.70058, -0.0422, 0.78439, 0.01214], [1.0, 0.0, 0.35346, -0.13768, 0.69387, -0.02423, 0.68195, -0.03574, 0.55717, -0.06119, 0.61836, -0.10467, 0.62099, -0.06527, 0.59361, -0.07289, 0.42271, -0.26409, 0.58213, 0.04992, 0.49736, -0.08771, 0.46241, -0.08989, 0.45008, -0.00564, 0.39146, -0.09038, 0.35588, -0.10306, 0.32232, -0.08637, 0.28943, -0.083], [1.0, 0.0, 0.76046, 0.01092, 0.86335, 0.00258, 0.85821, 0.00384, 0.79988, 0.02304, 0.81504, 0.12068, 0.83096, 0.00744, 0.81815, 0.00854, 0.82777, -0.06974, 0.76531, 0.03881, 0.76979, 0.01148, 0.75071, 0.01232, 0.77138, -0.00303, 0.70886, 0.01375, 0.66161, 0.00849, 0.66298, 0.01484, 0.63887, 0.01525], [1.0, 0.0, 0.66667, -0.01366, 0.97404, 0.06831, 0.4959, 0.50137, 0.75683, -0.00273, 0.65164, -0.14071, 0.40164, -0.48907, 0.39208, 0.58743, 0.76776, 0.31831, 0.78552, 0.11339, 0.47541, -0.44945, 1.0, 0.00683, 0.60656, 0.06967, 0.68656, 0.17088, 0.87568, 0.07787, 0.55328, 0.2459, 0.13934, 0.48087], [1.0, 0.0, 0.83508, 0.08298, 0.73739, -0.14706, 0.84349, -0.05567, 0.90441, -0.04622, 0.89391, 0.1313, 0.81197, 0.06723, 0.79307, -0.08929, 1.0, -0.02101, 0.96639, 0.06618, 0.87605, 0.01155, 0.77521, 0.06618, 0.95378, -0.04202, 0.83479, 0.00123, 1.0, 0.12815, 0.8666, -0.10714, 0.90546, -0.04307], [1.0, 0.0, 0.95113, 0.00419, 0.95183, -0.02723, 0.93438, -0.0192, 0.9459, 0.01606, 0.9651, 0.03281, 0.94171, 0.0733, 0.94625, -0.01326, 0.97173, 0.0014, 0.94834, 0.06038, 0.9267, 0.08412, 0.93124, 0.10087, 0.9452, 0.01361, 0.93522, 0.04925, 0.93159, 0.08168, 0.94066, -0.00035, 0.91483, 0.04712], [1.0, 0.0, 0.94701, -0.00034, 0.93207, -0.03227, 0.95177, -0.03431, 0.95584, 0.02446, 0.94124, 0.01766, 0.92595, 0.04688, 0.93954, -0.01461, 0.94837, 0.02004, 0.93784, 0.01393, 0.91406, 0.07677, 0.8947, 0.06148, 0.93988, 0.03193, 0.92489, 0.02542, 0.9212, 0.02242, 0.92459, 0.00442, 0.92697, -0.00577], [1.0, 0.0, 0.90608, -0.01657, 0.98122, -0.01989, 0.95691, -0.03646, 0.85746, 0.0011, 0.89724, -0.03315, 0.89061, -0.01436, 0.90608, -0.0453, 0.91381, -0.00884, 0.80773, -0.12928, 0.88729, 0.01215, 0.92155, -0.0232, 0.9105, -0.02099, 0.89147, -0.0776, 0.82983, -0.17238, 0.96022, -0.03757, 0.87403, -0.16243], [1.0, 0.0, 0.8471, 0.13533, 0.73638, -0.06151, 0.87873, 0.0826, 0.88928, -0.09139, 0.78735, 0.06678, 0.80668, -0.00351, 0.79262, -0.01054, 0.85764, -0.04569, 0.8717, -0.03515, 0.81722, -0.0949, 0.71002, 0.04394, 0.86467, -0.15114, 0.81147, -0.04822, 0.78207, -0.00703, 0.75747, -0.06678, 0.85764, -0.06151]]\n",
      "[1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "filename = 'Dataset/ionosphere.csv'\n",
    "dataset,label=getData(filename)\n",
    "# dataset=pd.DataFrame(dataset) #from dataset_list to dataset_dataframe after suffling\n",
    "print(dataset)\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def split_data(dataset, label):\n",
    "    # train-test split\n",
    "    indices = np.random.permutation(len(dataset))\n",
    "    training_idx, test_idx = indices[:221], indices[221:]\n",
    "    x_train = [dataset[i] for i in training_idx]\n",
    "    x_test = [dataset[i] for i in test_idx]\n",
    "    y_train = [label[i] for i in training_idx]\n",
    "    y_test = [label[i] for i in test_idx]\n",
    "\n",
    "    return x_train, y_train, x_test, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RFE implement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-4 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-4 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-4 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-4 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-4 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-4 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-4 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-4 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-4 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RFE(estimator=SVR(kernel=&#x27;linear&#x27;), n_features_to_select=10)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;RFE<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.feature_selection.RFE.html\">?<span>Documentation for RFE</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>RFE(estimator=SVR(kernel=&#x27;linear&#x27;), n_features_to_select=10)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">estimator: SVR</label><div class=\"sk-toggleable__content fitted\"><pre>SVR(kernel=&#x27;linear&#x27;)</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;SVR<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.svm.SVR.html\">?<span>Documentation for SVR</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>SVR(kernel=&#x27;linear&#x27;)</pre></div> </div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RFE(estimator=SVR(kernel='linear'), n_features_to_select=10)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "\n",
    "estimator = SVR(kernel=\"linear\")\n",
    "model = RFE(estimator, n_features_to_select=10, step=1)\n",
    "model.fit(dataset,label)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "10\n",
      "[[ 1.0000e+00  9.9539e-01 -5.8890e-02 ... -5.1171e-01  4.1078e-01\n",
      "   4.2267e-01]\n",
      " [ 1.0000e+00  1.0000e+00 -1.8829e-01 ... -2.6569e-01 -2.0468e-01\n",
      "  -1.6626e-01]\n",
      " [ 1.0000e+00  1.0000e+00 -3.3650e-02 ... -4.0220e-01  5.8984e-01\n",
      "   6.0436e-01]\n",
      " ...\n",
      " [ 1.0000e+00  9.4701e-01 -3.4000e-04 ...  3.1930e-02  9.2489e-01\n",
      "   9.2459e-01]\n",
      " [ 1.0000e+00  9.0608e-01 -1.6570e-02 ... -2.0990e-02  8.9147e-01\n",
      "   9.6022e-01]\n",
      " [ 1.0000e+00  8.4710e-01  1.3533e-01 ... -1.5114e-01  8.1147e-01\n",
      "   7.5747e-01]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "compressed_dataset_X= model.transform(dataset) # --transform-- the original \"dataset\" Dataframe into a lower-dimensional space based on the model's learned parameters\n",
    "print(type(compressed_dataset_X))\n",
    "print(len(compressed_dataset_X[0]))\n",
    "print(compressed_dataset_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130\n"
     ]
    }
   ],
   "source": [
    "# from NecessaryModules.splitData import split_data\n",
    "X_train, y_train, X_comb, y_comb = split_data(dataset,label)\n",
    "print(len(y_comb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65\n"
     ]
    }
   ],
   "source": [
    "X_valid, X_test, y_valid, y_test = train_test_split(X_comb, y_comb, test_size=0.50, random_state=42)\n",
    "print(len(X_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "221\n",
      "[[ 0.       1.      -1.      ... -1.       1.       1.     ]\n",
      " [ 1.       1.      -1.      ...  0.       1.       1.     ]\n",
      " [ 1.       0.93658  0.35107 ... -0.84951 -0.04578  0.54827]\n",
      " ...\n",
      " [ 1.       1.       1.      ...  0.       1.       1.     ]\n",
      " [ 1.       0.98455 -0.02736 ... -0.08341  0.96653  0.97132]\n",
      " [ 1.       1.       0.23395 ...  0.03591 -0.71731 -0.51251]]\n",
      "<class 'numpy.ndarray'>\n",
      "65\n",
      "[[ 1.0000e+00  1.0135e-01  1.0811e-01  0.0000e+00  0.0000e+00  0.0000e+00\n",
      "   0.0000e+00 -1.0000e+00  1.0000e+00  0.0000e+00]\n",
      " [ 1.0000e+00  1.0000e+00 -1.0000e+00  1.0000e+00  1.0000e+00 -1.0000e+00\n",
      "   1.0000e+00 -1.0000e+00  1.0000e+00 -1.0000e+00]\n",
      " [ 1.0000e+00  9.8002e-01  7.5000e-04  1.0000e+00 -7.5000e-04  9.7738e-01\n",
      "   5.5240e-02  8.1070e-02  9.6709e-01  9.8190e-01]\n",
      " [ 1.0000e+00  3.9286e-01  5.2381e-01 -7.8824e-01 -7.6378e-01 -5.1830e-01\n",
      "   4.4961e-01  7.0238e-01  5.1971e-01 -5.4891e-01]\n",
      " [ 1.0000e+00  8.7578e-01  3.7270e-02  8.9951e-01  5.1000e-03  8.4182e-01\n",
      "   1.6030e-02 -4.3480e-02  8.2111e-01  8.0757e-01]\n",
      " [ 1.0000e+00  8.8420e-01  3.6724e-01  6.7123e-01  8.6399e-01 -5.2504e-01\n",
      "  -5.3924e-01 -6.9774e-01  2.6028e-01  5.4209e-01]\n",
      " [ 1.0000e+00  8.3367e-01  3.1456e-01  6.5541e-01  7.0677e-01 -6.2030e-01\n",
      "  -2.8195e-01 -6.6014e-01 -1.5300e-02  4.3100e-01]\n",
      " [ 1.0000e+00  3.8521e-01  1.5564e-01  4.1245e-01  2.4125e-01  2.4903e-01\n",
      "   9.7280e-02  2.8482e-01 -6.0240e-02 -9.3390e-02]\n",
      " [ 1.0000e+00 -6.7935e-01 -1.0000e+00 -1.0000e+00  6.3317e-01  1.0000e+00\n",
      "  -1.0000e+00  1.0000e+00  1.0000e+00 -1.0000e+00]\n",
      " [ 1.0000e+00  3.6876e-01 -1.0000e+00 -1.0000e+00  1.0000e+00 -1.4343e-01\n",
      "  -2.0188e-01  6.6390e-02  3.4430e-02 -7.6100e-03]\n",
      " [ 1.0000e+00  6.3816e-01  1.0000e+00  2.0833e-01  1.0000e+00  3.2675e-01\n",
      "  -4.3860e-01 -1.0000e+00  1.0000e+00  2.0614e-01]\n",
      " [ 1.0000e+00  1.0000e+00 -5.5290e-02  1.0000e+00 -1.1111e-01  0.0000e+00\n",
      "  -2.5000e-01 -2.7778e-01  1.0000e+00  1.0000e+00]\n",
      " [ 1.0000e+00  1.0000e+00  0.0000e+00  1.0000e+00  5.0000e-01  7.5000e-01\n",
      "   0.0000e+00  5.0000e-01  7.3944e-01  6.9635e-01]\n",
      " [ 1.0000e+00  2.6667e-01 -1.0000e-01  5.3333e-01 -1.3333e-01  3.1667e-01\n",
      "   2.0000e-01  1.3333e-01  4.6214e-01  4.6667e-01]\n",
      " [ 1.0000e+00  1.0000e+00  1.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
      "   0.0000e+00 -1.0000e+00  1.0000e+00  0.0000e+00]\n",
      " [ 1.0000e+00  8.4843e-01  6.7940e-02  8.0562e-01 -3.2990e-02  5.5970e-01\n",
      "  -8.0390e-02 -2.2822e-01  4.8659e-01  4.4277e-01]\n",
      " [ 1.0000e+00  6.6161e-01 -1.0000e+00  1.0000e+00 -6.7321e-01  1.0000e+00\n",
      "   8.5268e-01  8.5357e-01  1.0000e+00  1.0000e+00]\n",
      " [ 1.0000e+00  1.0000e+00  1.6801e-01  9.9352e-01  3.3347e-01  5.6553e-01\n",
      "   5.8071e-01  5.5236e-01  4.3317e-01  3.3921e-01]\n",
      " [ 0.0000e+00  1.0000e+00 -1.0000e+00  1.0000e+00 -1.0000e+00  1.0000e+00\n",
      "   1.0000e+00 -1.0000e+00  1.0000e+00  1.0000e+00]\n",
      " [ 1.0000e+00  5.4600e-02  1.4370e-02 -2.5860e-02  4.5980e-02  2.0110e-02\n",
      "   2.2990e-02 -8.6200e-03  8.6200e-03  2.5860e-02]\n",
      " [ 1.0000e+00  9.4331e-01  1.9959e-01  9.6132e-01  5.6569e-01 -5.0251e-01\n",
      "   6.2563e-01  3.0912e-01 -7.7097e-01 -7.5199e-01]\n",
      " [ 1.0000e+00  7.6627e-01  2.1106e-01  6.3935e-01  5.2500e-01 -3.6591e-01\n",
      "   1.8864e-01 -3.2290e-02 -3.3942e-01 -1.9962e-01]\n",
      " [ 1.0000e+00  6.0678e-01 -2.7120e-02  6.7119e-01 -4.4070e-02  5.3220e-01\n",
      "   6.7800e-03 -3.3900e-02  5.7262e-01  5.8983e-01]\n",
      " [ 0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
      "   0.0000e+00  0.0000e+00  1.0000e+00  0.0000e+00]\n",
      " [ 1.0000e+00  1.0000e+00  1.0000e+00  1.0000e+00 -1.0000e+00  1.0000e+00\n",
      "   1.0000e+00  1.0000e+00  1.0000e+00  1.0000e+00]\n",
      " [ 1.0000e+00  1.0000e+00  2.8046e-01  1.0000e+00  7.7640e-02  1.0000e+00\n",
      "   4.1500e-02 -3.9056e-01  9.6414e-01  9.4578e-01]\n",
      " [ 1.0000e+00  8.6889e-01 -7.1110e-02  1.0000e+00 -6.8890e-02  1.0000e+00\n",
      "  -1.1526e-01  3.5560e-02  1.0000e+00  1.0000e+00]\n",
      " [ 1.0000e+00  1.0000e+00 -3.3650e-02  1.0000e+00 -1.2062e-01  7.0887e-01\n",
      "  -2.7502e-01 -4.0220e-01  5.8984e-01  6.0436e-01]\n",
      " [ 1.0000e+00  1.0000e+00 -5.4210e-01  1.0000e+00 -1.0000e+00  1.0000e+00\n",
      "   1.0000e+00 -4.0888e-01  1.0000e+00  1.0000e+00]\n",
      " [ 1.0000e+00  1.0000e+00 -9.5240e-02 -1.0000e+00 -1.0000e+00  6.8839e-01\n",
      "  -1.0000e+00  3.6508e-01  1.0000e+00 -1.0000e+00]\n",
      " [ 0.0000e+00  1.0000e+00  1.0000e+00  1.0000e+00  1.0000e+00 -1.0000e+00\n",
      "   1.0000e+00 -1.0000e+00  1.0000e+00  1.0000e+00]\n",
      " [ 1.0000e+00  1.0000e+00 -5.7224e-01  9.9150e-01 -9.7450e-01  9.6601e-01\n",
      "  -1.0000e+00 -7.6904e-01  5.3777e-01  1.0000e+00]\n",
      " [ 1.0000e+00  8.5013e-01  1.8090e-02  9.2211e-01  2.1800e-02  8.9097e-01\n",
      "   7.0470e-02  1.0853e-01  8.6923e-01  8.5198e-01]\n",
      " [ 0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  1.0000e+00\n",
      "   1.0000e+00  1.0000e+00  1.0000e+00  1.0000e+00]\n",
      " [ 1.0000e+00  8.7772e-01 -8.1520e-02  8.3424e-01  4.0760e-02  8.6413e-01\n",
      "  -5.9780e-02 -1.8750e-01  8.3705e-01  7.8533e-01]\n",
      " [ 1.0000e+00  0.0000e+00  0.0000e+00  1.0000e+00  0.0000e+00  0.0000e+00\n",
      "   0.0000e+00  4.4828e-01  1.0000e+00  0.0000e+00]\n",
      " [ 1.0000e+00  9.0608e-01 -1.6570e-02  9.8122e-01 -3.6460e-02  8.8729e-01\n",
      "   1.2150e-02 -2.0990e-02  8.9147e-01  9.6022e-01]\n",
      " [ 1.0000e+00  1.8590e-01 -1.6667e-01  0.0000e+00  0.0000e+00  0.0000e+00\n",
      "   0.0000e+00  8.9740e-02  1.7308e-01  2.5640e-02]\n",
      " [ 1.0000e+00  7.5564e-01  4.9638e-01  8.3550e-01  7.2063e-01 -7.0163e-01\n",
      "   2.4956e-01 -2.9099e-01 -7.0352e-01 -3.4131e-01]\n",
      " [ 1.0000e+00 -1.0000e+00  2.8105e-01  2.2222e-01 -7.0984e-01 -4.5750e-02\n",
      "  -8.3007e-01 -4.3137e-01  7.4385e-01  1.8301e-01]\n",
      " [ 1.0000e+00  3.5346e-01 -1.3768e-01  6.9387e-01 -3.5740e-02  4.9736e-01\n",
      "  -8.7710e-02 -5.6400e-03  3.9146e-01  3.2232e-01]\n",
      " [ 1.0000e+00  1.0000e+00  5.8120e-02  9.4525e-01  1.3231e-01  9.9695e-01\n",
      "   1.4258e-01  2.2431e-01  8.8423e-01  7.8324e-01]\n",
      " [ 1.0000e+00  8.4557e-01 -8.5800e-02 -3.1745e-01 -5.6435e-01 -6.9590e-02\n",
      "   5.0810e-01 -3.7180e-02  7.0882e-01 -2.1354e-01]\n",
      " [ 1.0000e+00  1.0000e+00  6.6550e-02  1.0000e+00 -2.7320e-01  7.0645e-01\n",
      "  -7.6320e-01 -8.9128e-01  4.7211e-01  3.0996e-01]\n",
      " [ 1.0000e+00  7.4084e-01  4.9740e-02  7.9074e-01  3.7930e-02  7.0021e-01\n",
      "   1.1355e-01  1.5445e-01  6.4158e-01  5.9759e-01]\n",
      " [ 0.0000e+00  0.0000e+00  0.0000e+00  1.0000e+00  0.0000e+00  0.0000e+00\n",
      "   0.0000e+00  0.0000e+00  1.0000e+00 -1.0000e+00]\n",
      " [ 0.0000e+00  0.0000e+00  0.0000e+00  1.0000e+00  1.0000e+00  0.0000e+00\n",
      "   0.0000e+00  0.0000e+00  1.0000e+00 -1.0000e+00]\n",
      " [ 1.0000e+00  8.7048e-01  3.8027e-01  6.4099e-01  8.6625e-01 -3.8334e-01\n",
      "  -6.2861e-01 -6.6421e-01  3.8544e-01  5.6239e-01]\n",
      " [ 1.0000e+00  8.4783e-01  1.0598e-01  1.0000e+00 -1.0000e+00  1.0000e+00\n",
      "   6.3496e-01 -3.3333e-01  1.0000e+00  1.0000e+00]\n",
      " [ 1.0000e+00  1.0000e+00 -8.7140e-02  1.0000e+00 -8.1779e-01  9.0284e-01\n",
      "   1.1053e-01 -8.2868e-01  4.8136e-01  3.2984e-01]\n",
      " [ 1.0000e+00 -2.0500e-01  2.8750e-01  2.3000e-01  3.1750e-01 -4.8000e-01\n",
      "  -8.0000e-02 -2.4000e-01  3.2190e-01 -2.7104e-01]\n",
      " [ 1.0000e+00  1.0000e+00 -8.6701e-01  1.0000e+00 -3.9896e-01  6.1831e-01\n",
      "   1.5803e-01 -1.7012e-01  1.0000e+00  1.0000e+00]\n",
      " [ 1.0000e+00  7.1253e-01 -2.5950e-02  4.1287e-01 -9.4730e-02 -2.5914e-01\n",
      "   9.2730e-01 -2.0392e-01  9.3124e-01  8.6136e-01]\n",
      " [ 1.0000e+00  1.0000e+00  2.4610e-02  9.9672e-01  7.1430e-02  6.5850e-01\n",
      "   1.6371e-01  1.6390e-01  4.8867e-01  3.8352e-01]\n",
      " [ 1.0000e+00  9.0116e-01  1.6607e-01  7.9299e-01  5.0515e-01 -4.6635e-01\n",
      "   6.5924e-01  3.9951e-01 -7.1844e-01 -7.1475e-01]\n",
      " [ 1.0000e+00  1.0000e+00  9.0910e-02  9.5455e-01  0.0000e+00  8.6364e-01\n",
      "   9.0910e-02  4.5450e-02  9.1541e-01  8.6364e-01]\n",
      " [ 1.0000e+00  9.5882e-01  1.0129e-01  1.0000e+00  2.5550e-02  9.7620e-01\n",
      "  -9.2840e-02 -1.5675e-01  9.5677e-01  1.0000e+00]\n",
      " [ 1.0000e+00  9.2436e-01  3.6924e-01  7.1976e-01  9.4078e-01 -6.6431e-01\n",
      "  -6.6278e-01 -8.8082e-01  1.9765e-01  6.9886e-01]\n",
      " [ 1.0000e+00 -1.0000e+00 -5.9677e-01  0.0000e+00  6.4516e-01 -1.0000e+00\n",
      "  -1.0000e+00  2.3387e-01  1.0000e+00  0.0000e+00]\n",
      " [ 1.0000e+00  7.2727e-01 -5.0000e-02  8.9241e-01  7.2727e-01  1.0000e+00\n",
      "  -3.0000e-01  3.2727e-01  5.6982e-01  4.8927e-01]\n",
      " [ 0.0000e+00  1.0000e+00  1.0000e+00  1.0000e+00  1.0000e+00  1.0000e+00\n",
      "   1.0000e+00 -1.0000e+00  1.0000e+00  1.0000e+00]\n",
      " [ 1.0000e+00  1.0000e+00  1.1385e-01  7.0019e-01  9.6770e-02  7.2676e-01\n",
      "   7.2110e-02  3.7381e-01  4.9090e-01  4.4141e-01]\n",
      " [ 1.0000e+00  8.4710e-01  1.3533e-01  7.3638e-01  8.2600e-02  8.1722e-01\n",
      "  -9.4900e-02 -1.5114e-01  8.1147e-01  7.5747e-01]\n",
      " [ 1.0000e+00  9.1241e-01  4.3470e-02  9.4191e-01  5.3450e-02  8.0983e-01\n",
      "   1.1849e-01  1.1299e-01  7.3550e-01  7.0925e-01]\n",
      " [ 1.0000e+00  7.2414e-01 -1.0840e-02  7.9704e-01  1.9700e-03  7.5961e-01\n",
      "   3.3500e-02 -1.4780e-02  7.8041e-01  8.2956e-01]]\n",
      "<class 'numpy.ndarray'>\n",
      "65\n",
      "[[ 1.0000e+00  3.9394e-01 -2.4242e-01  6.2655e-01  9.0910e-02  7.8788e-01\n",
      "   1.8182e-01  5.9290e-02  4.6362e-01  4.1856e-01]\n",
      " [ 1.0000e+00  1.0000e+00  5.0700e-02  1.0000e+00  1.9498e-01  8.0644e-01\n",
      "   5.9962e-01  6.3942e-01  5.9417e-01  4.7027e-01]\n",
      " [ 1.0000e+00  4.7938e-01 -1.2371e-01  4.2784e-01 -3.9175e-01  5.4639e-01\n",
      "   1.8557e-01  1.9588e-01  5.3396e-01  4.7423e-01]\n",
      " [ 1.0000e+00  8.5736e-01  7.5000e-04  8.1927e-01 -4.1820e-02  8.8125e-01\n",
      "   1.1950e-02 -1.9420e-02  8.2383e-01  7.3936e-01]\n",
      " [ 1.0000e+00  9.7467e-01  1.3082e-01  9.4120e-01  3.2248e-01  4.4245e-01\n",
      "   6.8159e-01  7.6210e-01  1.6813e-01 -2.9620e-02]\n",
      " [ 1.0000e+00  1.0000e+00 -1.0810e-02  1.0000e+00 -6.4860e-02  1.0000e+00\n",
      "   6.4860e-02  9.1890e-02  9.8556e-01  1.0000e+00]\n",
      " [ 1.0000e+00  4.2000e-01 -6.1000e-01  0.0000e+00 -1.0000e+00  0.0000e+00\n",
      "   0.0000e+00  6.8000e-01  1.0000e+00  0.0000e+00]\n",
      " [ 1.0000e+00  5.8459e-01 -3.5526e-01  1.0000e+00 -5.6400e-03  6.6917e-01\n",
      "   2.0489e-01 -4.6990e-02  5.6836e-01  1.5602e-01]\n",
      " [ 1.0000e+00  1.0000e+00  4.5455e-01  1.0000e+00  6.3636e-01  9.0909e-01\n",
      "  -4.5455e-01 -9.0910e-02  1.0000e+00  1.0000e+00]\n",
      " [ 1.0000e+00  2.9202e-01  1.3582e-01  4.5331e-01 -5.0900e-03  3.4975e-01\n",
      "   6.6210e-02 -3.1760e-02  5.0369e-01  7.0798e-01]\n",
      " [ 1.0000e+00  8.1143e-01  3.7140e-02  8.5143e-01  7.1400e-03  7.6857e-01\n",
      "  -8.4290e-02 -6.8570e-02  8.1598e-01  8.1429e-01]\n",
      " [ 1.0000e+00  1.0000e+00  1.0000e+00  0.0000e+00 -1.0000e+00  0.0000e+00\n",
      "   0.0000e+00 -1.0000e+00  1.0000e+00 -1.0000e+00]\n",
      " [ 1.0000e+00  5.9887e-01  1.4689e-01  6.9868e-01 -1.3936e-01  7.0245e-01\n",
      "  -3.7700e-03 -3.3145e-01  6.1444e-01  5.3861e-01]\n",
      " [ 1.0000e+00  2.8409e-01 -3.1818e-01  0.0000e+00 -1.0000e+00  0.0000e+00\n",
      "   0.0000e+00  1.7803e-01  1.0000e+00  1.6288e-01]\n",
      " [ 1.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
      "   0.0000e+00  0.0000e+00  1.0000e+00  0.0000e+00]\n",
      " [ 1.0000e+00  2.9073e-01  1.0025e-01  2.3308e-01  3.4336e-01 -4.1660e-02\n",
      "  -2.8000e-03 -1.5050e-02 -8.8600e-03  9.6000e-04]\n",
      " [ 0.0000e+00  1.0000e+00  1.0000e+00  1.0000e+00  0.0000e+00  0.0000e+00\n",
      "   0.0000e+00 -1.0000e+00  1.0000e+00  0.0000e+00]\n",
      " [ 1.0000e+00  8.8085e-01  3.5232e-01  6.8389e-01  7.9784e-01 -6.4579e-01\n",
      "  -5.0022e-01 -7.5533e-01  1.7041e-01  5.6626e-01]\n",
      " [ 1.0000e+00 -6.5625e-01  1.5625e-01  6.2500e-02  6.2500e-02  0.0000e+00\n",
      "  -9.3750e-02 -4.6875e-01  3.1250e-02 -3.1250e-02]\n",
      " [ 1.0000e+00  1.0000e+00 -1.0000e+00  0.0000e+00 -9.9265e-01  0.0000e+00\n",
      "   0.0000e+00 -1.0000e+00 -1.0000e+00  1.0000e+00]\n",
      " [ 1.0000e+00  4.3750e-01  4.1670e-02  5.8333e-01  0.0000e+00  3.3333e-01\n",
      "   8.3330e-02 -1.8750e-01  4.4012e-01  5.8333e-01]\n",
      " [ 1.0000e+00  7.9157e-01  1.6851e-01  0.0000e+00  6.8740e-02 -1.0200e-01\n",
      "   3.8803e-01  8.0710e-01 -3.4146e-01 -1.0000e+00]\n",
      " [ 1.0000e+00  5.7540e-01 -3.1750e-02  7.5198e-01 -1.1900e-02  4.7817e-01\n",
      "  -2.7780e-02  3.9680e-02  6.1291e-01  6.8849e-01]\n",
      " [ 1.0000e+00  9.9645e-01  6.4680e-02  1.0000e+00  2.4980e-02  8.1633e-01\n",
      "   1.1830e-01  1.3412e-01  7.9476e-01  7.7122e-01]\n",
      " [ 1.0000e+00  9.3147e-01  2.9282e-01  7.9917e-01  7.1596e-01 -9.2254e-01\n",
      "   6.0400e-02 -4.6906e-01 -6.5165e-01 -1.3590e-01]\n",
      " [ 1.0000e+00  4.7337e-01  1.9527e-01  6.2130e-02  1.0060e-02  5.2767e-01\n",
      "   2.8420e-02 -2.3670e-02  4.6514e-01  3.1953e-01]\n",
      " [ 1.0000e+00  1.0000e+00  2.4077e-01  9.9815e-01 -3.0133e-01  6.1041e-01\n",
      "  -3.9328e-01 -5.2142e-01  2.9208e-01  1.5657e-01]\n",
      " [ 1.0000e+00  1.0000e+00  2.3058e-01  1.0000e+00 -1.0401e-01  9.7400e-01\n",
      "   3.7280e-02 -1.2530e-02  9.6238e-01  1.0000e+00]\n",
      " [ 0.0000e+00  1.0000e+00 -1.0000e+00  0.0000e+00  0.0000e+00 -1.0000e+00\n",
      "   1.0000e+00  1.0000e+00  1.0000e+00  1.0000e+00]\n",
      " [ 1.0000e+00  8.2624e-01  8.1560e-02  7.9078e-01 -1.7730e-02  9.1489e-01\n",
      "   7.0900e-03  1.5957e-01  8.9527e-01  9.2553e-01]\n",
      " [ 1.0000e+00  9.5202e-01  2.2540e-02  9.3757e-01  1.2140e-02  9.3584e-01\n",
      "  -4.9710e-02 -4.4510e-02  9.6215e-01  9.5434e-01]\n",
      " [ 1.0000e+00  6.6667e-01 -1.3660e-02  9.7404e-01  5.0137e-01  4.7541e-01\n",
      "  -4.4945e-01  6.9670e-02  6.8656e-01  5.5328e-01]\n",
      " [ 1.0000e+00  9.5113e-01  4.1900e-03  9.5183e-01 -1.9200e-02  9.2670e-01\n",
      "   8.4120e-02  1.3610e-02  9.3522e-01  9.4066e-01]\n",
      " [ 1.0000e+00  6.2121e-01 -6.3636e-01  0.0000e+00  0.0000e+00  1.8940e-02\n",
      "  -5.3409e-01 -2.7273e-01  2.5758e-01  1.8182e-01]\n",
      " [ 1.0000e+00  1.0000e+00  7.3800e-02  1.0000e+00 -5.5630e-02  1.0000e+00\n",
      "   4.4758e-01  2.0033e-01  1.0000e+00  1.0000e+00]\n",
      " [ 1.0000e+00  9.4333e-01  3.8574e-01  4.8263e-01  7.7514e-01  4.9909e-01\n",
      "  -6.3620e-01 -5.4840e-02  6.0098e-01  2.7420e-02]\n",
      " [ 1.0000e+00  9.6355e-01 -7.1980e-02  1.0000e+00 -2.1313e-01  7.5346e-01\n",
      "  -6.0589e-01 -6.5440e-01  5.7577e-01  4.5114e-01]\n",
      " [ 1.0000e+00  4.9870e-01  1.8180e-02  4.3117e-01 -4.1560e-02  4.8571e-01\n",
      "  -3.3770e-02  0.0000e+00  5.3215e-01  5.4545e-01]\n",
      " [ 1.0000e+00  7.9847e-01  3.8265e-01  8.0804e-01 -7.6530e-02  1.0000e+00\n",
      "   1.9100e-03 -1.4541e-01  1.0000e+00  1.0000e+00]\n",
      " [ 0.0000e+00  1.0000e+00 -1.0000e+00  1.0000e+00 -1.0000e+00 -7.5000e-01\n",
      "   1.0000e+00 -1.0000e+00  1.0000e+00  0.0000e+00]\n",
      " [ 1.0000e+00  1.0000e+00  6.7784e-01  8.1309e-01  1.0000e+00 -7.3083e-01\n",
      "  -7.6339e-01 -1.0000e+00  4.1778e-01  9.3570e-01]\n",
      " [ 1.0000e+00  1.6670e-02 -3.5625e-01  0.0000e+00  0.0000e+00  0.0000e+00\n",
      "   0.0000e+00 -1.6667e-01  1.0000e+00  0.0000e+00]\n",
      " [ 1.0000e+00  1.0000e+00  8.0130e-02  9.6775e-01 -7.2200e-03  9.5016e-01\n",
      "  -2.3640e-02  2.0030e-02  9.3772e-01  9.2774e-01]\n",
      " [ 1.0000e+00  4.1932e-01  1.2482e-01  3.5000e-01  2.7955e-01 -2.0028e-01\n",
      "   5.0780e-02 -4.8020e-02 -9.9710e-02 -2.9160e-02]\n",
      " [ 1.0000e+00  2.5000e-01  1.6667e-01  4.6667e-01  2.3966e-01 -2.4740e-02\n",
      "   3.5700e-03 -5.3900e-03 -6.2100e-03 -8.9000e-04]\n",
      " [ 1.0000e+00  8.8804e-01  3.8138e-01  6.5926e-01  8.7892e-01 -4.6637e-01\n",
      "  -5.5605e-01 -6.1055e-01  3.0406e-01  4.7029e-01]\n",
      " [ 1.0000e+00  8.6689e-01  3.5950e-01  7.2014e-01  8.3049e-01 -4.9488e-01\n",
      "  -4.2207e-01 -5.9954e-01  1.5360e-01  4.6189e-01]\n",
      " [ 1.0000e+00 -1.0000e+00  1.0000e+00 -1.0000e+00  1.0000e+00 -3.1402e-01\n",
      "  -1.0000e+00 -1.0000e+00 -1.0000e+00 -1.0000e+00]\n",
      " [ 1.0000e+00  6.2745e-01 -7.8430e-02  7.2549e-01 -7.8430e-02  5.8824e-01\n",
      "  -1.9608e-01 -2.5490e-01  5.2409e-01  4.3137e-01]\n",
      " [ 1.0000e+00  8.3789e-01  4.2904e-01  7.2113e-01  7.8115e-01 -6.2041e-01\n",
      "  -3.1351e-01 -6.7796e-01 -5.0540e-02  3.7093e-01]\n",
      " [ 1.0000e+00 -6.4100e-03 -5.0000e-01  0.0000e+00  1.0000e+00 -3.5256e-01\n",
      "   7.4359e-01  0.0000e+00 -6.1538e-01  0.0000e+00]\n",
      " [ 1.0000e+00  0.0000e+00  0.0000e+00 -1.0000e+00  1.0000e+00 -1.0000e+00\n",
      "  -1.0000e+00  4.3750e-01  1.0000e+00 -1.0000e+00]\n",
      " [ 1.0000e+00  9.7032e-01 -1.4384e-01  9.1324e-01 -1.7123e-01  1.0000e+00\n",
      "   1.0274e-01  6.8490e-02  9.4043e-01  8.5388e-01]\n",
      " [ 1.0000e+00  9.9539e-01 -5.8890e-02  8.5243e-01 -3.7708e-01  5.6971e-01\n",
      "  -2.9674e-01 -5.1171e-01  4.1078e-01  4.2267e-01]\n",
      " [ 1.0000e+00  8.9410e-01  1.3425e-01  8.7001e-01  4.3388e-01 -2.0201e-01\n",
      "   6.6926e-01  5.0489e-01 -4.6215e-01 -5.2823e-01]\n",
      " [ 1.0000e+00  9.4080e-01  1.1933e-01  8.5738e-01  1.5460e-02  8.0862e-01\n",
      "   4.9010e-02  2.2200e-02  7.9058e-01  7.7863e-01]\n",
      " [ 1.0000e+00  5.1207e-01  1.0000e+00  1.0000e+00  8.0833e-01 -5.2674e-01\n",
      "   7.1699e-01  3.5175e-01 -1.0000e+00 -1.0000e+00]\n",
      " [ 1.0000e+00  8.8110e-01  0.0000e+00  9.4817e-01 -1.2200e-02  9.0854e-01\n",
      "   2.4390e-02  4.8780e-02  8.9666e-01  1.0000e+00]\n",
      " [ 1.0000e+00  5.8660e-02 -8.3800e-03  6.7040e-02 -1.1170e-02 -4.7490e-02\n",
      "   2.5140e-02  5.5900e-03  1.0335e-01  4.4690e-02]\n",
      " [ 1.0000e+00  8.2254e-01 -7.5720e-02  8.0462e-01 -1.2140e-02  8.6763e-01\n",
      "  -2.3700e-02 -2.3700e-02  7.6717e-01  7.0058e-01]\n",
      " [ 1.0000e+00  2.5316e-01  3.5949e-01  0.0000e+00 -1.0000e+00  7.5900e-03\n",
      "   6.8101e-01  3.5696e-01  5.5700e-02  6.3290e-02]\n",
      " [ 1.0000e+00  1.0000e+00  5.4902e-01  6.2745e-01  1.0000e+00  3.5294e-01\n",
      "  -1.0000e+00 -2.1569e-01  9.2874e-01  2.3529e-01]\n",
      " [ 1.0000e+00  9.0374e-01 -1.6040e-02  1.0000e+00  1.6040e-02  9.6791e-01\n",
      "   2.1390e-02  5.3480e-02  9.6974e-01  1.0000e+00]\n",
      " [ 0.0000e+00  1.0000e+00 -1.0000e+00  1.0000e+00  1.0000e+00  1.0000e+00\n",
      "   1.0000e+00 -1.0000e+00  1.0000e+00  1.0000e+00]\n",
      " [ 1.0000e+00  9.4649e-01  8.9200e-03  9.7287e-01  3.7200e-03  9.7770e-01\n",
      "   4.9800e-02  8.1010e-02  9.5243e-01  9.7845e-01]]\n"
     ]
    }
   ],
   "source": [
    "compressed_dataset_X_train= model.transform(X_train) # --transform-- the original \"dataset\" Dataframe into a lower-dimensional space based on the model's learned parameters\n",
    "print(type(compressed_dataset_X_train))\n",
    "print(len(compressed_dataset_X_train))\n",
    "print(compressed_dataset_X_train)\n",
    "\n",
    "compressed_dataset_X_valid= model.transform(X_valid) # --transform-- the original \"dataset\" Dataframe into a lower-dimensional space based on the model's learned parameters\n",
    "print(type(compressed_dataset_X_valid))\n",
    "print(len(compressed_dataset_X_valid))\n",
    "print(compressed_dataset_X_valid)\n",
    "\n",
    "compressed_dataset_X_test= model.transform(X_test) # --transform-- the original \"dataset\" Dataframe into a lower-dimensional space based on the model's learned parameters\n",
    "print(type(compressed_dataset_X_test))\n",
    "print(len(compressed_dataset_X_test))\n",
    "print(compressed_dataset_X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# reshape the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(65, 10)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compressed_dataset_X_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(221, 10, 1)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_arr=compressed_dataset_X_train.reshape(compressed_dataset_X_train.shape[0],compressed_dataset_X_train.shape[1],1)\n",
    "X_train_arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(65, 10, 1)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X_valid_arr=compressed_dataset_X_valid.to_numpy()\n",
    "X_valid_arr=compressed_dataset_X_valid.reshape(compressed_dataset_X_valid.shape[0],compressed_dataset_X_valid.shape[1],1)\n",
    "X_valid_arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(65, 10, 1)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_arr=compressed_dataset_X_test.reshape(compressed_dataset_X_test.shape[0],compressed_dataset_X_test.shape[1],1)\n",
    "X_test_arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for \"y\"\n",
    "\n",
    "y_train_arr=np.array(y_train)\n",
    "y_train_arr=y_train_arr.reshape(y_train_arr.shape[0],1)\n",
    "\n",
    "y_valid_arr=np.array(y_valid)\n",
    "y_valid_arr=y_valid_arr.reshape(y_valid_arr.shape[0],1)\n",
    "\n",
    "y_test_arr=np.array(y_test)\n",
    "y_test_arr=y_test_arr.reshape(y_test_arr.shape[0],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(65, 1)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_arr.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# one hot encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "# one hot encoding\n",
    "y_train_arr = to_categorical(y_train, 7)\n",
    "y_valid_arr = to_categorical(y_valid, 7)\n",
    "y_test_arr = to_categorical(y_test, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(65, 7)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_arr.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# cnn model\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from numpy import dstack\n",
    "from pandas import read_csv\n",
    "from matplotlib import pyplot\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Conv1D\n",
    "from keras.layers import MaxPooling1D,LSTM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "callback=tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    min_delta=0,\n",
    "    patience=7,\n",
    "    verbose=0,\n",
    "    mode='auto',\n",
    "    baseline=None,\n",
    "    restore_best_weights=True,\n",
    "    start_from_epoch=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global value\n",
    "verbose, epochs, batch_size = 1, 100, 20\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize scores\n",
    "def summarize_results(scores):\n",
    " print(scores)\n",
    " m, s = mean(scores), std(scores)\n",
    " print('Test Accuracy: %.3f%% (+/-%.3f)' % (m, s))\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy measure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**tunned model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit and evaluate a model\n",
    "import optuna\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def optimize_model2(trainX, trainy,validX,validy):\n",
    "    n_timesteps, n_features, n_outputs = trainX.shape[1], trainX.shape[2], 7\n",
    "    def objective_model2(trial):\n",
    "    # Define hyperparameters to be tuned\n",
    "     \n",
    "     filters = trial.suggest_int('filters', 32, 128)\n",
    "     kernel_size = trial.suggest_int('kernel_size', 2, 5)\n",
    "     dropout_rate = trial.suggest_float('dropout_rate', 0.1, 0.5)\n",
    "    #  dense_units = trial.suggest_int('dense_units', 50, 200)\n",
    "     pool_size=trial.suggest_int('pool_size',2,4)\n",
    "     \n",
    "     \n",
    "     # Build the CNN model\n",
    "     model = Sequential()\n",
    "     model.add(Conv1D(filters=filters, kernel_size=kernel_size, activation='relu', input_shape=(n_timesteps, n_features)))\n",
    "     model.add(MaxPooling1D(pool_size=pool_size))\n",
    "     model.add(LSTM(units=filters)) # remember the important features\n",
    "     model.add(Dense(100, activation='relu'))\n",
    "     model.add(Dense(filters, activation='relu')) \n",
    "     model.add(Dropout(dropout_rate))#for regularization\n",
    "     model.add(Dense(n_outputs, activation='softmax'))\n",
    " \n",
    "     # Compile the model\n",
    "     model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    " \n",
    "     # Fit the model\n",
    "     history = model.fit(trainX, trainy, validation_data=(validX, validy), epochs=epochs,callbacks=[callback],batch_size=batch_size, verbose=verbose)\n",
    "    \n",
    "    # Return the validation accuracy as the objective value\n",
    "     return history.history['val_accuracy'][-1]\n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    study.optimize(objective_model2, n_trials= 10, \n",
    "                   #timeout=600\n",
    "                   )#The maximum time (in seconds) allowed for the optimization process to run.\n",
    "    # Get the best hyperparameters\n",
    "    best_params = study.best_params\n",
    "    print(\"Best Hyperparameters:\", best_params)\n",
    "    fig_study = optuna.visualization.plot_parallel_coordinate(study, params=[\"filters\", \"kernel_size\",\"dropout_rate\",\"pool_size\"])\n",
    "    fig_study.show()\n",
    "\n",
    "    return best_params\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-11 01:02:29,831] A new study created in memory with name: no-name-53b0f7c1-5df9-4a8c-98f7-215fc9d166b8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "12/12 [==============================] - 4s 144ms/step - loss: 1.9081 - accuracy: 0.5747 - val_loss: 1.8581 - val_accuracy: 0.5077\n",
      "Epoch 2/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 1.7739 - accuracy: 0.6652 - val_loss: 1.6884 - val_accuracy: 0.5077\n",
      "Epoch 3/100\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 1.4729 - accuracy: 0.6652 - val_loss: 1.3328 - val_accuracy: 0.5077\n",
      "Epoch 4/100\n",
      "12/12 [==============================] - 0s 23ms/step - loss: 1.0436 - accuracy: 0.6561 - val_loss: 0.9620 - val_accuracy: 0.5077\n",
      "Epoch 5/100\n",
      "12/12 [==============================] - 0s 21ms/step - loss: 0.7370 - accuracy: 0.6878 - val_loss: 0.6883 - val_accuracy: 0.5846\n",
      "Epoch 6/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.5946 - accuracy: 0.7014 - val_loss: 0.6889 - val_accuracy: 0.6000\n",
      "Epoch 7/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.5621 - accuracy: 0.7557 - val_loss: 0.5946 - val_accuracy: 0.6769\n",
      "Epoch 8/100\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.4943 - accuracy: 0.8100 - val_loss: 0.5670 - val_accuracy: 0.7231\n",
      "Epoch 9/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.4690 - accuracy: 0.8371 - val_loss: 0.5478 - val_accuracy: 0.7538\n",
      "Epoch 10/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.4133 - accuracy: 0.8371 - val_loss: 0.5605 - val_accuracy: 0.7692\n",
      "Epoch 11/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.3657 - accuracy: 0.8778 - val_loss: 0.6054 - val_accuracy: 0.7231\n",
      "Epoch 12/100\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.3789 - accuracy: 0.8733 - val_loss: 0.4827 - val_accuracy: 0.8308\n",
      "Epoch 13/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.3301 - accuracy: 0.8914 - val_loss: 0.5012 - val_accuracy: 0.8308\n",
      "Epoch 14/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.3493 - accuracy: 0.8914 - val_loss: 0.5178 - val_accuracy: 0.8308\n",
      "Epoch 15/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.3184 - accuracy: 0.9050 - val_loss: 0.5729 - val_accuracy: 0.7846\n",
      "Epoch 16/100\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.3026 - accuracy: 0.8959 - val_loss: 0.4022 - val_accuracy: 0.8462\n",
      "Epoch 17/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.4061 - accuracy: 0.8100 - val_loss: 0.4582 - val_accuracy: 0.8308\n",
      "Epoch 18/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.2975 - accuracy: 0.9050 - val_loss: 0.6033 - val_accuracy: 0.7692\n",
      "Epoch 19/100\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.2998 - accuracy: 0.9095 - val_loss: 0.4789 - val_accuracy: 0.8154\n",
      "Epoch 20/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.2872 - accuracy: 0.9186 - val_loss: 0.4924 - val_accuracy: 0.8154\n",
      "Epoch 21/100\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.3265 - accuracy: 0.8778 - val_loss: 0.6003 - val_accuracy: 0.7692\n",
      "Epoch 22/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.2762 - accuracy: 0.8959 - val_loss: 0.4241 - val_accuracy: 0.8462\n",
      "Epoch 23/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.2833 - accuracy: 0.9186 - val_loss: 0.4227 - val_accuracy: 0.8462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-11 01:02:36,895] Trial 0 finished with value: 0.8461538553237915 and parameters: {'filters': 32, 'kernel_size': 4, 'dropout_rate': 0.25577374917753853, 'pool_size': 3}. Best is trial 0 with value: 0.8461538553237915.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "12/12 [==============================] - 3s 52ms/step - loss: 1.8706 - accuracy: 0.6471 - val_loss: 1.7449 - val_accuracy: 0.5846\n",
      "Epoch 2/100\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 1.5565 - accuracy: 0.7104 - val_loss: 1.2776 - val_accuracy: 0.5538\n",
      "Epoch 3/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.9758 - accuracy: 0.6833 - val_loss: 0.7963 - val_accuracy: 0.5538\n",
      "Epoch 4/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6931 - accuracy: 0.6787 - val_loss: 0.6987 - val_accuracy: 0.6000\n",
      "Epoch 5/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.5307 - accuracy: 0.7873 - val_loss: 0.5779 - val_accuracy: 0.6923\n",
      "Epoch 6/100\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.4255 - accuracy: 0.8371 - val_loss: 0.5531 - val_accuracy: 0.7385\n",
      "Epoch 7/100\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.3822 - accuracy: 0.8552 - val_loss: 0.5775 - val_accuracy: 0.7692\n",
      "Epoch 8/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.3455 - accuracy: 0.8778 - val_loss: 0.5759 - val_accuracy: 0.7692\n",
      "Epoch 9/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.3248 - accuracy: 0.8914 - val_loss: 0.4562 - val_accuracy: 0.8462\n",
      "Epoch 10/100\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.3489 - accuracy: 0.8733 - val_loss: 0.5428 - val_accuracy: 0.8000\n",
      "Epoch 11/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.3058 - accuracy: 0.8959 - val_loss: 0.5437 - val_accuracy: 0.8154\n",
      "Epoch 12/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.2761 - accuracy: 0.9186 - val_loss: 0.5503 - val_accuracy: 0.8154\n",
      "Epoch 13/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.2910 - accuracy: 0.9050 - val_loss: 0.4698 - val_accuracy: 0.8154\n",
      "Epoch 14/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.2684 - accuracy: 0.9186 - val_loss: 0.4600 - val_accuracy: 0.8308\n",
      "Epoch 15/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.2580 - accuracy: 0.9231 - val_loss: 0.4984 - val_accuracy: 0.8308\n",
      "Epoch 16/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.2359 - accuracy: 0.9231 - val_loss: 0.5502 - val_accuracy: 0.8308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-11 01:02:41,756] Trial 1 finished with value: 0.8307692408561707 and parameters: {'filters': 60, 'kernel_size': 4, 'dropout_rate': 0.43398262049841263, 'pool_size': 4}. Best is trial 0 with value: 0.8461538553237915.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "12/12 [==============================] - 3s 55ms/step - loss: 1.8758 - accuracy: 0.5249 - val_loss: 1.7331 - val_accuracy: 0.6462\n",
      "Epoch 2/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 1.5432 - accuracy: 0.5566 - val_loss: 1.1846 - val_accuracy: 0.4923\n",
      "Epoch 3/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.9808 - accuracy: 0.5023 - val_loss: 0.7517 - val_accuracy: 0.5077\n",
      "Epoch 4/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.7202 - accuracy: 0.6425 - val_loss: 0.8189 - val_accuracy: 0.5077\n",
      "Epoch 5/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6609 - accuracy: 0.6516 - val_loss: 0.6828 - val_accuracy: 0.5077\n",
      "Epoch 6/100\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6663 - accuracy: 0.6199 - val_loss: 0.7432 - val_accuracy: 0.5077\n",
      "Epoch 7/100\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6687 - accuracy: 0.6516 - val_loss: 0.6941 - val_accuracy: 0.5077\n",
      "Epoch 8/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.6190 - accuracy: 0.6968 - val_loss: 0.6510 - val_accuracy: 0.6154\n",
      "Epoch 9/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.5713 - accuracy: 0.7059 - val_loss: 0.6441 - val_accuracy: 0.6154\n",
      "Epoch 10/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.5267 - accuracy: 0.7828 - val_loss: 0.5923 - val_accuracy: 0.6769\n",
      "Epoch 11/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.4916 - accuracy: 0.8190 - val_loss: 0.5919 - val_accuracy: 0.6923\n",
      "Epoch 12/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.4282 - accuracy: 0.8100 - val_loss: 0.5912 - val_accuracy: 0.7077\n",
      "Epoch 13/100\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.3880 - accuracy: 0.8462 - val_loss: 0.5847 - val_accuracy: 0.7231\n",
      "Epoch 14/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.3949 - accuracy: 0.8507 - val_loss: 0.5473 - val_accuracy: 0.7231\n",
      "Epoch 15/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.3803 - accuracy: 0.8281 - val_loss: 0.6814 - val_accuracy: 0.6769\n",
      "Epoch 16/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.3574 - accuracy: 0.8643 - val_loss: 0.4914 - val_accuracy: 0.8154\n",
      "Epoch 17/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.3076 - accuracy: 0.8869 - val_loss: 0.6022 - val_accuracy: 0.7538\n",
      "Epoch 18/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.3236 - accuracy: 0.8778 - val_loss: 0.4533 - val_accuracy: 0.8154\n",
      "Epoch 19/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.3002 - accuracy: 0.9050 - val_loss: 0.5136 - val_accuracy: 0.8000\n",
      "Epoch 20/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.2920 - accuracy: 0.8959 - val_loss: 0.4052 - val_accuracy: 0.8769\n",
      "Epoch 21/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.2721 - accuracy: 0.9231 - val_loss: 0.4473 - val_accuracy: 0.8308\n",
      "Epoch 22/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.2488 - accuracy: 0.9186 - val_loss: 0.4352 - val_accuracy: 0.8308\n",
      "Epoch 23/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.2605 - accuracy: 0.9140 - val_loss: 0.4144 - val_accuracy: 0.8615\n",
      "Epoch 24/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.2390 - accuracy: 0.9231 - val_loss: 0.4044 - val_accuracy: 0.8769\n",
      "Epoch 25/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.2286 - accuracy: 0.9186 - val_loss: 0.4220 - val_accuracy: 0.8308\n",
      "Epoch 26/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.2268 - accuracy: 0.9231 - val_loss: 0.4305 - val_accuracy: 0.8308\n",
      "Epoch 27/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.2263 - accuracy: 0.9276 - val_loss: 0.3502 - val_accuracy: 0.8923\n",
      "Epoch 28/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.2280 - accuracy: 0.9276 - val_loss: 0.3652 - val_accuracy: 0.8923\n",
      "Epoch 29/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.2057 - accuracy: 0.9186 - val_loss: 0.3236 - val_accuracy: 0.8923\n",
      "Epoch 30/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.2279 - accuracy: 0.9231 - val_loss: 0.4656 - val_accuracy: 0.8000\n",
      "Epoch 31/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.2275 - accuracy: 0.9186 - val_loss: 0.3184 - val_accuracy: 0.8923\n",
      "Epoch 32/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.1914 - accuracy: 0.9412 - val_loss: 0.3147 - val_accuracy: 0.8923\n",
      "Epoch 33/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.1928 - accuracy: 0.9321 - val_loss: 0.3292 - val_accuracy: 0.8769\n",
      "Epoch 34/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.1843 - accuracy: 0.9276 - val_loss: 0.3149 - val_accuracy: 0.8769\n",
      "Epoch 35/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.1991 - accuracy: 0.9276 - val_loss: 0.3049 - val_accuracy: 0.8923\n",
      "Epoch 36/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.2141 - accuracy: 0.9231 - val_loss: 0.4570 - val_accuracy: 0.8462\n",
      "Epoch 37/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.1839 - accuracy: 0.9367 - val_loss: 0.3173 - val_accuracy: 0.8923\n",
      "Epoch 38/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.3462 - accuracy: 0.8914 - val_loss: 0.5415 - val_accuracy: 0.7846\n",
      "Epoch 39/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.2321 - accuracy: 0.9276 - val_loss: 0.3125 - val_accuracy: 0.8615\n",
      "Epoch 40/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.1826 - accuracy: 0.9367 - val_loss: 0.4231 - val_accuracy: 0.8308\n",
      "Epoch 41/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.1735 - accuracy: 0.9412 - val_loss: 0.3255 - val_accuracy: 0.8769\n",
      "Epoch 42/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.1679 - accuracy: 0.9502 - val_loss: 0.3412 - val_accuracy: 0.8769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-11 01:02:49,017] Trial 2 finished with value: 0.8769230842590332 and parameters: {'filters': 51, 'kernel_size': 3, 'dropout_rate': 0.11298823417623911, 'pool_size': 4}. Best is trial 2 with value: 0.8769230842590332.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "12/12 [==============================] - 3s 52ms/step - loss: 1.8231 - accuracy: 0.7104 - val_loss: 1.5634 - val_accuracy: 0.5846\n",
      "Epoch 2/100\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 1.1456 - accuracy: 0.7104 - val_loss: 0.7838 - val_accuracy: 0.5538\n",
      "Epoch 3/100\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.5887 - accuracy: 0.7421 - val_loss: 0.7260 - val_accuracy: 0.6000\n",
      "Epoch 4/100\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.4775 - accuracy: 0.7738 - val_loss: 0.6708 - val_accuracy: 0.6308\n",
      "Epoch 5/100\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.4108 - accuracy: 0.8235 - val_loss: 0.5389 - val_accuracy: 0.7692\n",
      "Epoch 6/100\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.4051 - accuracy: 0.8688 - val_loss: 0.4548 - val_accuracy: 0.8308\n",
      "Epoch 7/100\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.3010 - accuracy: 0.8824 - val_loss: 0.4770 - val_accuracy: 0.8154\n",
      "Epoch 8/100\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.2628 - accuracy: 0.8959 - val_loss: 0.4770 - val_accuracy: 0.8154\n",
      "Epoch 9/100\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.2340 - accuracy: 0.9321 - val_loss: 0.4301 - val_accuracy: 0.8615\n",
      "Epoch 10/100\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.2416 - accuracy: 0.9140 - val_loss: 0.4524 - val_accuracy: 0.8462\n",
      "Epoch 11/100\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.2143 - accuracy: 0.9548 - val_loss: 0.4133 - val_accuracy: 0.8615\n",
      "Epoch 12/100\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.2778 - accuracy: 0.9095 - val_loss: 0.5025 - val_accuracy: 0.8462\n",
      "Epoch 13/100\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.2229 - accuracy: 0.9457 - val_loss: 0.3797 - val_accuracy: 0.8615\n",
      "Epoch 14/100\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.2166 - accuracy: 0.9231 - val_loss: 0.4379 - val_accuracy: 0.8615\n",
      "Epoch 15/100\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.1778 - accuracy: 0.9457 - val_loss: 0.3700 - val_accuracy: 0.8615\n",
      "Epoch 16/100\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.1881 - accuracy: 0.9276 - val_loss: 0.4163 - val_accuracy: 0.8769\n",
      "Epoch 17/100\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.1798 - accuracy: 0.9457 - val_loss: 0.3878 - val_accuracy: 0.8923\n",
      "Epoch 18/100\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.1726 - accuracy: 0.9548 - val_loss: 0.3859 - val_accuracy: 0.8923\n",
      "Epoch 19/100\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.1899 - accuracy: 0.9367 - val_loss: 0.3033 - val_accuracy: 0.8923\n",
      "Epoch 20/100\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.1929 - accuracy: 0.9412 - val_loss: 0.3966 - val_accuracy: 0.8923\n",
      "Epoch 21/100\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.2641 - accuracy: 0.9095 - val_loss: 0.3904 - val_accuracy: 0.8923\n",
      "Epoch 22/100\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.1621 - accuracy: 0.9502 - val_loss: 0.3161 - val_accuracy: 0.8769\n",
      "Epoch 23/100\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.1511 - accuracy: 0.9683 - val_loss: 0.4146 - val_accuracy: 0.8923\n",
      "Epoch 24/100\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.1504 - accuracy: 0.9638 - val_loss: 0.3878 - val_accuracy: 0.8923\n",
      "Epoch 25/100\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.1429 - accuracy: 0.9593 - val_loss: 0.3429 - val_accuracy: 0.8769\n",
      "Epoch 26/100\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.1207 - accuracy: 0.9638 - val_loss: 0.3631 - val_accuracy: 0.8923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-11 01:02:54,999] Trial 3 finished with value: 0.892307698726654 and parameters: {'filters': 124, 'kernel_size': 5, 'dropout_rate': 0.18945305567616413, 'pool_size': 4}. Best is trial 3 with value: 0.892307698726654.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "12/12 [==============================] - 3s 52ms/step - loss: 1.8516 - accuracy: 0.6018 - val_loss: 1.6755 - val_accuracy: 0.5077\n",
      "Epoch 2/100\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 1.3877 - accuracy: 0.6697 - val_loss: 1.0543 - val_accuracy: 0.5077\n",
      "Epoch 3/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.8039 - accuracy: 0.6787 - val_loss: 0.6754 - val_accuracy: 0.5846\n",
      "Epoch 4/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6457 - accuracy: 0.6652 - val_loss: 0.6216 - val_accuracy: 0.6308\n",
      "Epoch 5/100\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.4694 - accuracy: 0.8190 - val_loss: 0.5641 - val_accuracy: 0.6615\n",
      "Epoch 6/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.4073 - accuracy: 0.8326 - val_loss: 0.5295 - val_accuracy: 0.7385\n",
      "Epoch 7/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.3281 - accuracy: 0.8778 - val_loss: 0.5490 - val_accuracy: 0.7846\n",
      "Epoch 8/100\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.3087 - accuracy: 0.9050 - val_loss: 0.4535 - val_accuracy: 0.8462\n",
      "Epoch 9/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.2696 - accuracy: 0.9095 - val_loss: 0.5068 - val_accuracy: 0.8308\n",
      "Epoch 10/100\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.2468 - accuracy: 0.9321 - val_loss: 0.4203 - val_accuracy: 0.8308\n",
      "Epoch 11/100\n",
      "12/12 [==============================] - 0s 21ms/step - loss: 0.2408 - accuracy: 0.9095 - val_loss: 0.5251 - val_accuracy: 0.8462\n",
      "Epoch 12/100\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 0.2409 - accuracy: 0.9276 - val_loss: 0.4659 - val_accuracy: 0.8615\n",
      "Epoch 13/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.2400 - accuracy: 0.9186 - val_loss: 0.4169 - val_accuracy: 0.8615\n",
      "Epoch 14/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.1916 - accuracy: 0.9548 - val_loss: 0.3939 - val_accuracy: 0.8615\n",
      "Epoch 15/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.2019 - accuracy: 0.9412 - val_loss: 0.4198 - val_accuracy: 0.8615\n",
      "Epoch 16/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.2024 - accuracy: 0.9457 - val_loss: 0.3656 - val_accuracy: 0.8462\n",
      "Epoch 17/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.1971 - accuracy: 0.9367 - val_loss: 0.3663 - val_accuracy: 0.8923\n",
      "Epoch 18/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.1962 - accuracy: 0.9321 - val_loss: 0.4036 - val_accuracy: 0.8923\n",
      "Epoch 19/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.1693 - accuracy: 0.9502 - val_loss: 0.4013 - val_accuracy: 0.8923\n",
      "Epoch 20/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.1531 - accuracy: 0.9548 - val_loss: 0.3668 - val_accuracy: 0.8923\n",
      "Epoch 21/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.1599 - accuracy: 0.9593 - val_loss: 0.3795 - val_accuracy: 0.8923\n",
      "Epoch 22/100\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.1374 - accuracy: 0.9638 - val_loss: 0.3349 - val_accuracy: 0.9077\n",
      "Epoch 23/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.1227 - accuracy: 0.9593 - val_loss: 0.3413 - val_accuracy: 0.9077\n",
      "Epoch 24/100\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.1281 - accuracy: 0.9638 - val_loss: 0.3457 - val_accuracy: 0.9077\n",
      "Epoch 25/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.1134 - accuracy: 0.9729 - val_loss: 0.3484 - val_accuracy: 0.9231\n",
      "Epoch 26/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.1105 - accuracy: 0.9683 - val_loss: 0.3744 - val_accuracy: 0.9077\n",
      "Epoch 27/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0978 - accuracy: 0.9774 - val_loss: 0.4285 - val_accuracy: 0.9077\n",
      "Epoch 28/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.1003 - accuracy: 0.9729 - val_loss: 0.3954 - val_accuracy: 0.9077\n",
      "Epoch 29/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0874 - accuracy: 0.9819 - val_loss: 0.3618 - val_accuracy: 0.9077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-11 01:03:01,092] Trial 4 finished with value: 0.9076923131942749 and parameters: {'filters': 88, 'kernel_size': 5, 'dropout_rate': 0.3472139860540476, 'pool_size': 4}. Best is trial 4 with value: 0.9076923131942749.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "12/12 [==============================] - 3s 47ms/step - loss: 1.8839 - accuracy: 0.5339 - val_loss: 1.7781 - val_accuracy: 0.5077\n",
      "Epoch 2/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 1.6370 - accuracy: 0.6335 - val_loss: 1.4176 - val_accuracy: 0.5077\n",
      "Epoch 3/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 1.1604 - accuracy: 0.6516 - val_loss: 0.9368 - val_accuracy: 0.5077\n",
      "Epoch 4/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.7576 - accuracy: 0.6652 - val_loss: 0.6977 - val_accuracy: 0.5538\n",
      "Epoch 5/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.6677 - accuracy: 0.6425 - val_loss: 0.6304 - val_accuracy: 0.6462\n",
      "Epoch 6/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.6246 - accuracy: 0.6561 - val_loss: 0.6822 - val_accuracy: 0.6154\n",
      "Epoch 7/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.5403 - accuracy: 0.7376 - val_loss: 0.6479 - val_accuracy: 0.6462\n",
      "Epoch 8/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.4425 - accuracy: 0.7964 - val_loss: 0.6354 - val_accuracy: 0.6923\n",
      "Epoch 9/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.4595 - accuracy: 0.7873 - val_loss: 0.6109 - val_accuracy: 0.6923\n",
      "Epoch 10/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.4443 - accuracy: 0.8371 - val_loss: 0.7139 - val_accuracy: 0.7077\n",
      "Epoch 11/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.4553 - accuracy: 0.8326 - val_loss: 0.5917 - val_accuracy: 0.7538\n",
      "Epoch 12/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.3892 - accuracy: 0.8688 - val_loss: 0.6611 - val_accuracy: 0.7385\n",
      "Epoch 13/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.4045 - accuracy: 0.8597 - val_loss: 0.6411 - val_accuracy: 0.7538\n",
      "Epoch 14/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.4038 - accuracy: 0.8462 - val_loss: 0.6108 - val_accuracy: 0.7538\n",
      "Epoch 15/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.3900 - accuracy: 0.8552 - val_loss: 0.5964 - val_accuracy: 0.7538\n",
      "Epoch 16/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.3477 - accuracy: 0.8869 - val_loss: 0.6786 - val_accuracy: 0.7385\n",
      "Epoch 17/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.3311 - accuracy: 0.8869 - val_loss: 0.6271 - val_accuracy: 0.7692\n",
      "Epoch 18/100\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.3786 - accuracy: 0.8778 - val_loss: 0.6336 - val_accuracy: 0.7538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-11 01:03:05,851] Trial 5 finished with value: 0.7538461685180664 and parameters: {'filters': 41, 'kernel_size': 2, 'dropout_rate': 0.34493265196568357, 'pool_size': 4}. Best is trial 4 with value: 0.9076923131942749.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "12/12 [==============================] - 3s 47ms/step - loss: 1.8681 - accuracy: 0.6425 - val_loss: 1.8071 - val_accuracy: 0.5077\n",
      "Epoch 2/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 1.6507 - accuracy: 0.6652 - val_loss: 1.5592 - val_accuracy: 0.5077\n",
      "Epoch 3/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 1.2377 - accuracy: 0.6652 - val_loss: 1.2730 - val_accuracy: 0.5077\n",
      "Epoch 4/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.8897 - accuracy: 0.6561 - val_loss: 0.8707 - val_accuracy: 0.5077\n",
      "Epoch 5/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6813 - accuracy: 0.6742 - val_loss: 0.7719 - val_accuracy: 0.5385\n",
      "Epoch 6/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.6078 - accuracy: 0.6878 - val_loss: 0.6650 - val_accuracy: 0.6000\n",
      "Epoch 7/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.4947 - accuracy: 0.7873 - val_loss: 0.6133 - val_accuracy: 0.6615\n",
      "Epoch 8/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.5069 - accuracy: 0.7738 - val_loss: 0.6258 - val_accuracy: 0.6462\n",
      "Epoch 9/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.4788 - accuracy: 0.8100 - val_loss: 0.6033 - val_accuracy: 0.6923\n",
      "Epoch 10/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.4643 - accuracy: 0.8100 - val_loss: 0.5910 - val_accuracy: 0.7231\n",
      "Epoch 11/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.3767 - accuracy: 0.8643 - val_loss: 0.5914 - val_accuracy: 0.7231\n",
      "Epoch 12/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.3741 - accuracy: 0.8869 - val_loss: 0.5652 - val_accuracy: 0.7538\n",
      "Epoch 13/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.3579 - accuracy: 0.8869 - val_loss: 0.4944 - val_accuracy: 0.8154\n",
      "Epoch 14/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.3155 - accuracy: 0.8824 - val_loss: 0.5224 - val_accuracy: 0.8000\n",
      "Epoch 15/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.3039 - accuracy: 0.9050 - val_loss: 0.4568 - val_accuracy: 0.8308\n",
      "Epoch 16/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.2876 - accuracy: 0.9050 - val_loss: 0.4229 - val_accuracy: 0.8462\n",
      "Epoch 17/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.2933 - accuracy: 0.9050 - val_loss: 0.7288 - val_accuracy: 0.7538\n",
      "Epoch 18/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.3189 - accuracy: 0.9140 - val_loss: 0.4093 - val_accuracy: 0.8462\n",
      "Epoch 19/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.2737 - accuracy: 0.9140 - val_loss: 0.4558 - val_accuracy: 0.8615\n",
      "Epoch 20/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.2582 - accuracy: 0.9231 - val_loss: 0.3887 - val_accuracy: 0.8462\n",
      "Epoch 21/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.2453 - accuracy: 0.9140 - val_loss: 0.4127 - val_accuracy: 0.8769\n",
      "Epoch 22/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.2378 - accuracy: 0.9186 - val_loss: 0.4738 - val_accuracy: 0.8615\n",
      "Epoch 23/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.2216 - accuracy: 0.9276 - val_loss: 0.5221 - val_accuracy: 0.8462\n",
      "Epoch 24/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.3452 - accuracy: 0.8959 - val_loss: 0.7776 - val_accuracy: 0.7538\n",
      "Epoch 25/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.2417 - accuracy: 0.9140 - val_loss: 0.2889 - val_accuracy: 0.8769\n",
      "Epoch 26/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.2197 - accuracy: 0.9231 - val_loss: 0.5325 - val_accuracy: 0.8154\n",
      "Epoch 27/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.2434 - accuracy: 0.9186 - val_loss: 0.3701 - val_accuracy: 0.8462\n",
      "Epoch 28/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.2478 - accuracy: 0.9231 - val_loss: 0.5273 - val_accuracy: 0.7846\n",
      "Epoch 29/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.2278 - accuracy: 0.9095 - val_loss: 0.3408 - val_accuracy: 0.8615\n",
      "Epoch 30/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.2069 - accuracy: 0.9231 - val_loss: 0.3069 - val_accuracy: 0.8769\n",
      "Epoch 31/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.3569 - accuracy: 0.8326 - val_loss: 0.4875 - val_accuracy: 0.8462\n",
      "Epoch 32/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.2591 - accuracy: 0.9140 - val_loss: 0.5365 - val_accuracy: 0.8154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-11 01:03:11,338] Trial 6 finished with value: 0.8153846263885498 and parameters: {'filters': 34, 'kernel_size': 4, 'dropout_rate': 0.10539966478346474, 'pool_size': 3}. Best is trial 4 with value: 0.9076923131942749.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "12/12 [==============================] - 3s 51ms/step - loss: 1.7864 - accuracy: 0.6109 - val_loss: 1.4651 - val_accuracy: 0.5077\n",
      "Epoch 2/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 1.0852 - accuracy: 0.6244 - val_loss: 0.8823 - val_accuracy: 0.5077\n",
      "Epoch 3/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.7208 - accuracy: 0.6606 - val_loss: 0.6833 - val_accuracy: 0.5385\n",
      "Epoch 4/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6302 - accuracy: 0.6697 - val_loss: 0.7922 - val_accuracy: 0.5385\n",
      "Epoch 5/100\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.5740 - accuracy: 0.7330 - val_loss: 0.5883 - val_accuracy: 0.6923\n",
      "Epoch 6/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.4733 - accuracy: 0.8054 - val_loss: 0.6349 - val_accuracy: 0.7077\n",
      "Epoch 7/100\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.3960 - accuracy: 0.8462 - val_loss: 0.6733 - val_accuracy: 0.7077\n",
      "Epoch 8/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.3762 - accuracy: 0.8597 - val_loss: 0.6170 - val_accuracy: 0.7385\n",
      "Epoch 9/100\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.3931 - accuracy: 0.8597 - val_loss: 0.6096 - val_accuracy: 0.7231\n",
      "Epoch 10/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.3458 - accuracy: 0.8643 - val_loss: 0.6038 - val_accuracy: 0.7231\n",
      "Epoch 11/100\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.3323 - accuracy: 0.8778 - val_loss: 0.5367 - val_accuracy: 0.8154\n",
      "Epoch 12/100\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.3280 - accuracy: 0.8914 - val_loss: 0.5746 - val_accuracy: 0.7846\n",
      "Epoch 13/100\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.3066 - accuracy: 0.8959 - val_loss: 0.6120 - val_accuracy: 0.7846\n",
      "Epoch 14/100\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.2802 - accuracy: 0.9140 - val_loss: 0.5380 - val_accuracy: 0.8154\n",
      "Epoch 15/100\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.2919 - accuracy: 0.9231 - val_loss: 0.4830 - val_accuracy: 0.8154\n",
      "Epoch 16/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.3752 - accuracy: 0.8552 - val_loss: 0.4893 - val_accuracy: 0.7692\n",
      "Epoch 17/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.3456 - accuracy: 0.8778 - val_loss: 0.5503 - val_accuracy: 0.7385\n",
      "Epoch 18/100\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.3140 - accuracy: 0.9005 - val_loss: 0.4340 - val_accuracy: 0.8154\n",
      "Epoch 19/100\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.2847 - accuracy: 0.9231 - val_loss: 0.5619 - val_accuracy: 0.7692\n",
      "Epoch 20/100\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.2461 - accuracy: 0.9186 - val_loss: 0.5016 - val_accuracy: 0.8308\n",
      "Epoch 21/100\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.2376 - accuracy: 0.9140 - val_loss: 0.5719 - val_accuracy: 0.8000\n",
      "Epoch 22/100\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.2642 - accuracy: 0.9276 - val_loss: 0.4989 - val_accuracy: 0.8462\n",
      "Epoch 23/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.2403 - accuracy: 0.9231 - val_loss: 0.5668 - val_accuracy: 0.8000\n",
      "Epoch 24/100\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.2375 - accuracy: 0.9367 - val_loss: 0.5202 - val_accuracy: 0.8462\n",
      "Epoch 25/100\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.2342 - accuracy: 0.9321 - val_loss: 0.5733 - val_accuracy: 0.7692\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-11 01:03:16,940] Trial 7 finished with value: 0.7692307829856873 and parameters: {'filters': 120, 'kernel_size': 2, 'dropout_rate': 0.4408837715917965, 'pool_size': 4}. Best is trial 4 with value: 0.9076923131942749.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "12/12 [==============================] - 3s 50ms/step - loss: 1.7127 - accuracy: 0.6335 - val_loss: 1.2793 - val_accuracy: 0.5077\n",
      "Epoch 2/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.9028 - accuracy: 0.6652 - val_loss: 0.7350 - val_accuracy: 0.5077\n",
      "Epoch 3/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6955 - accuracy: 0.5792 - val_loss: 0.8559 - val_accuracy: 0.5077\n",
      "Epoch 4/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6957 - accuracy: 0.6471 - val_loss: 0.6353 - val_accuracy: 0.6308\n",
      "Epoch 5/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.5447 - accuracy: 0.7376 - val_loss: 0.6895 - val_accuracy: 0.6154\n",
      "Epoch 6/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.4717 - accuracy: 0.7873 - val_loss: 0.6627 - val_accuracy: 0.6462\n",
      "Epoch 7/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.4258 - accuracy: 0.8371 - val_loss: 0.5657 - val_accuracy: 0.7077\n",
      "Epoch 8/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.3963 - accuracy: 0.8326 - val_loss: 0.6946 - val_accuracy: 0.7077\n",
      "Epoch 9/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.3587 - accuracy: 0.8462 - val_loss: 0.6538 - val_accuracy: 0.7231\n",
      "Epoch 10/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.3477 - accuracy: 0.8688 - val_loss: 0.5998 - val_accuracy: 0.7692\n",
      "Epoch 11/100\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.3322 - accuracy: 0.8778 - val_loss: 0.8168 - val_accuracy: 0.7077\n",
      "Epoch 12/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.5306 - accuracy: 0.8100 - val_loss: 0.8007 - val_accuracy: 0.6154\n",
      "Epoch 13/100\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.4324 - accuracy: 0.8416 - val_loss: 0.5396 - val_accuracy: 0.7385\n",
      "Epoch 14/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.3343 - accuracy: 0.9140 - val_loss: 0.6325 - val_accuracy: 0.7385\n",
      "Epoch 15/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.2965 - accuracy: 0.8914 - val_loss: 0.5964 - val_accuracy: 0.7846\n",
      "Epoch 16/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.3091 - accuracy: 0.8869 - val_loss: 0.6892 - val_accuracy: 0.7538\n",
      "Epoch 17/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.2961 - accuracy: 0.9095 - val_loss: 0.5953 - val_accuracy: 0.7692\n",
      "Epoch 18/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.2858 - accuracy: 0.8914 - val_loss: 0.5668 - val_accuracy: 0.7692\n",
      "Epoch 19/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.2799 - accuracy: 0.9140 - val_loss: 0.5926 - val_accuracy: 0.7692\n",
      "Epoch 20/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.2641 - accuracy: 0.8959 - val_loss: 0.5946 - val_accuracy: 0.7692\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-11 01:03:21,873] Trial 8 finished with value: 0.7692307829856873 and parameters: {'filters': 108, 'kernel_size': 2, 'dropout_rate': 0.13817970452614026, 'pool_size': 4}. Best is trial 4 with value: 0.9076923131942749.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "12/12 [==============================] - 3s 47ms/step - loss: 1.8492 - accuracy: 0.5701 - val_loss: 1.6829 - val_accuracy: 0.5077\n",
      "Epoch 2/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 1.4180 - accuracy: 0.6697 - val_loss: 1.1385 - val_accuracy: 0.5077\n",
      "Epoch 3/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.8882 - accuracy: 0.6652 - val_loss: 0.8327 - val_accuracy: 0.5077\n",
      "Epoch 4/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.6757 - accuracy: 0.6606 - val_loss: 0.7260 - val_accuracy: 0.5077\n",
      "Epoch 5/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.6549 - accuracy: 0.6606 - val_loss: 0.6859 - val_accuracy: 0.5846\n",
      "Epoch 6/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.5969 - accuracy: 0.7104 - val_loss: 0.6145 - val_accuracy: 0.6462\n",
      "Epoch 7/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.4957 - accuracy: 0.7828 - val_loss: 0.7721 - val_accuracy: 0.6000\n",
      "Epoch 8/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.4696 - accuracy: 0.7964 - val_loss: 0.6069 - val_accuracy: 0.7077\n",
      "Epoch 9/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.4222 - accuracy: 0.8190 - val_loss: 0.6039 - val_accuracy: 0.7385\n",
      "Epoch 10/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.3901 - accuracy: 0.8507 - val_loss: 0.6662 - val_accuracy: 0.7231\n",
      "Epoch 11/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.3414 - accuracy: 0.8778 - val_loss: 0.5027 - val_accuracy: 0.7692\n",
      "Epoch 12/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.3546 - accuracy: 0.9050 - val_loss: 0.5950 - val_accuracy: 0.7538\n",
      "Epoch 13/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.3261 - accuracy: 0.9005 - val_loss: 0.5474 - val_accuracy: 0.8000\n",
      "Epoch 14/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.2845 - accuracy: 0.8869 - val_loss: 0.5891 - val_accuracy: 0.7846\n",
      "Epoch 15/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.2903 - accuracy: 0.9186 - val_loss: 0.5562 - val_accuracy: 0.8154\n",
      "Epoch 16/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.2985 - accuracy: 0.9005 - val_loss: 0.5403 - val_accuracy: 0.8308\n",
      "Epoch 17/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.3228 - accuracy: 0.8824 - val_loss: 0.5440 - val_accuracy: 0.7692\n",
      "Epoch 18/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.2802 - accuracy: 0.9186 - val_loss: 0.4779 - val_accuracy: 0.8308\n",
      "Epoch 19/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.2740 - accuracy: 0.9276 - val_loss: 0.5322 - val_accuracy: 0.8308\n",
      "Epoch 20/100\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.2564 - accuracy: 0.9231 - val_loss: 0.5014 - val_accuracy: 0.8308\n",
      "Epoch 21/100\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.3341 - accuracy: 0.8959 - val_loss: 0.4947 - val_accuracy: 0.8462\n",
      "Epoch 22/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.2678 - accuracy: 0.9231 - val_loss: 0.5337 - val_accuracy: 0.8154\n",
      "Epoch 23/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.2381 - accuracy: 0.9457 - val_loss: 0.4640 - val_accuracy: 0.8462\n",
      "Epoch 24/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.2443 - accuracy: 0.9321 - val_loss: 0.5245 - val_accuracy: 0.8462\n",
      "Epoch 25/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.2285 - accuracy: 0.9321 - val_loss: 0.4948 - val_accuracy: 0.8462\n",
      "Epoch 26/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.2252 - accuracy: 0.9457 - val_loss: 0.4978 - val_accuracy: 0.8462\n",
      "Epoch 27/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.2406 - accuracy: 0.9412 - val_loss: 0.4808 - val_accuracy: 0.8462\n",
      "Epoch 28/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.2334 - accuracy: 0.9367 - val_loss: 0.4846 - val_accuracy: 0.8462\n",
      "Epoch 29/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.2108 - accuracy: 0.9457 - val_loss: 0.4562 - val_accuracy: 0.8462\n",
      "Epoch 30/100\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.2291 - accuracy: 0.9276 - val_loss: 0.4705 - val_accuracy: 0.8154\n",
      "Epoch 31/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.2110 - accuracy: 0.9367 - val_loss: 0.4597 - val_accuracy: 0.8462\n",
      "Epoch 32/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.2048 - accuracy: 0.9457 - val_loss: 0.4846 - val_accuracy: 0.8308\n",
      "Epoch 33/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.2141 - accuracy: 0.9321 - val_loss: 0.4704 - val_accuracy: 0.8462\n",
      "Epoch 34/100\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 0.1860 - accuracy: 0.9548 - val_loss: 0.5256 - val_accuracy: 0.8154\n",
      "Epoch 35/100\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 0.2402 - accuracy: 0.9140 - val_loss: 0.4829 - val_accuracy: 0.8308\n",
      "Epoch 36/100\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.2426 - accuracy: 0.9231 - val_loss: 0.5261 - val_accuracy: 0.8000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-11 01:03:28,838] Trial 9 finished with value: 0.800000011920929 and parameters: {'filters': 61, 'kernel_size': 2, 'dropout_rate': 0.217410822325768, 'pool_size': 4}. Best is trial 4 with value: 0.9076923131942749.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'filters': 88, 'kernel_size': 5, 'dropout_rate': 0.3472139860540476, 'pool_size': 4}\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "dimensions": [
          {
           "label": "Objective Value",
           "range": [
            0.7538461685180664,
            0.9076923131942749
           ],
           "values": [
            0.8461538553237915,
            0.8307692408561707,
            0.8769230842590332,
            0.892307698726654,
            0.9076923131942749,
            0.7538461685180664,
            0.8153846263885498,
            0.7692307829856873,
            0.7692307829856873,
            0.800000011920929
           ]
          },
          {
           "label": "dropout_rate",
           "range": [
            0.10539966478346474,
            0.4408837715917965
           ],
           "values": [
            0.25577374917753853,
            0.43398262049841263,
            0.11298823417623911,
            0.18945305567616413,
            0.3472139860540476,
            0.34493265196568357,
            0.10539966478346474,
            0.4408837715917965,
            0.13817970452614026,
            0.217410822325768
           ]
          },
          {
           "label": "filters",
           "range": [
            32,
            124
           ],
           "values": [
            32,
            60,
            51,
            124,
            88,
            41,
            34,
            120,
            108,
            61
           ]
          },
          {
           "label": "kernel_size",
           "range": [
            2,
            5
           ],
           "values": [
            4,
            4,
            3,
            5,
            5,
            2,
            4,
            2,
            2,
            2
           ]
          },
          {
           "label": "pool_size",
           "range": [
            3,
            4
           ],
           "values": [
            3,
            4,
            4,
            4,
            4,
            4,
            3,
            4,
            4,
            4
           ]
          }
         ],
         "labelangle": 30,
         "labelside": "bottom",
         "line": {
          "color": [
           0.8461538553237915,
           0.8307692408561707,
           0.8769230842590332,
           0.892307698726654,
           0.9076923131942749,
           0.7538461685180664,
           0.8153846263885498,
           0.7692307829856873,
           0.7692307829856873,
           0.800000011920929
          ],
          "colorbar": {
           "title": {
            "text": "Objective Value"
           }
          },
          "colorscale": [
           [
            0,
            "rgb(247,251,255)"
           ],
           [
            0.125,
            "rgb(222,235,247)"
           ],
           [
            0.25,
            "rgb(198,219,239)"
           ],
           [
            0.375,
            "rgb(158,202,225)"
           ],
           [
            0.5,
            "rgb(107,174,214)"
           ],
           [
            0.625,
            "rgb(66,146,198)"
           ],
           [
            0.75,
            "rgb(33,113,181)"
           ],
           [
            0.875,
            "rgb(8,81,156)"
           ],
           [
            1,
            "rgb(8,48,107)"
           ]
          ],
          "reversescale": false,
          "showscale": true
         },
         "type": "parcoords"
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Parallel Coordinate Plot"
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "best_params=optimize_model2(X_train_arr, y_train_arr, X_valid_arr, y_valid_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'filters': 88,\n",
       " 'kernel_size': 5,\n",
       " 'dropout_rate': 0.3472139860540476,\n",
       " 'pool_size': 4}"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit and evaluate a model\n",
    "def evaluate_model_1(trainX, trainy,validX,validy, testX, testy):\n",
    "#  verbose, epochs, batch_size = 1, 1500, 100\n",
    " n_timesteps, n_features, n_outputs = trainX.shape[1], trainX.shape[2], 7\n",
    " model = Sequential()\n",
    " model.add(Conv1D(filters=best_params['filters'], kernel_size=best_params['kernel_size'], activation='relu', input_shape=(n_timesteps,n_features)))\n",
    " model.add(MaxPooling1D(pool_size=best_params['pool_size']))\n",
    " model.add(LSTM(units=best_params['filters']))\n",
    " model.add(Dense(100, activation='relu'))\n",
    " model.add(Dense(best_params['filters'], activation='relu'))\n",
    " model.add(Dropout(best_params['dropout_rate']))\n",
    " model.add(Dense(n_outputs, activation='softmax')) # \"softmax\" for multi-class\n",
    " model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    " # fit network\n",
    " history=model.fit(trainX, trainy, validation_data=(validX, validy), epochs=epochs, batch_size=batch_size,callbacks=[callback], verbose=verbose) \n",
    " # evaluate model\n",
    " _, accuracy = model.evaluate(testX, testy, batch_size=batch_size, verbose=0)\n",
    " # '_,'-->a variable is being used for a specific purpose, but its value is not of interest or not used in the subsequent code.\n",
    " return accuracy,history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "12/12 [==============================] - 3s 50ms/step - loss: 1.8552 - accuracy: 0.6787 - val_loss: 1.6898 - val_accuracy: 0.5846\n",
      "Epoch 2/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 1.3993 - accuracy: 0.6878 - val_loss: 1.0545 - val_accuracy: 0.5077\n",
      "Epoch 3/100\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.7729 - accuracy: 0.6878 - val_loss: 0.6514 - val_accuracy: 0.6154\n",
      "Epoch 4/100\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6337 - accuracy: 0.6968 - val_loss: 0.6840 - val_accuracy: 0.6308\n",
      "Epoch 5/100\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.4800 - accuracy: 0.7919 - val_loss: 0.5800 - val_accuracy: 0.7077\n",
      "Epoch 6/100\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.3985 - accuracy: 0.8959 - val_loss: 0.5375 - val_accuracy: 0.8000\n",
      "Epoch 7/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.3196 - accuracy: 0.9005 - val_loss: 0.5798 - val_accuracy: 0.8000\n",
      "Epoch 8/100\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.2937 - accuracy: 0.9231 - val_loss: 0.4798 - val_accuracy: 0.8308\n",
      "Epoch 9/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.2556 - accuracy: 0.9186 - val_loss: 0.5245 - val_accuracy: 0.8154\n",
      "Epoch 10/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.2520 - accuracy: 0.9367 - val_loss: 0.4558 - val_accuracy: 0.8615\n",
      "Epoch 11/100\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.2202 - accuracy: 0.9186 - val_loss: 0.4541 - val_accuracy: 0.8462\n",
      "Epoch 12/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.2296 - accuracy: 0.9457 - val_loss: 0.4115 - val_accuracy: 0.8462\n",
      "Epoch 13/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.2091 - accuracy: 0.9321 - val_loss: 0.4527 - val_accuracy: 0.8615\n",
      "Epoch 14/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.2198 - accuracy: 0.9412 - val_loss: 0.4119 - val_accuracy: 0.8615\n",
      "Epoch 15/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.2092 - accuracy: 0.9412 - val_loss: 0.4153 - val_accuracy: 0.8769\n",
      "Epoch 16/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.1962 - accuracy: 0.9321 - val_loss: 0.4419 - val_accuracy: 0.8769\n",
      "Epoch 17/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.1824 - accuracy: 0.9502 - val_loss: 0.4063 - val_accuracy: 0.8462\n",
      "Epoch 18/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.1655 - accuracy: 0.9457 - val_loss: 0.4073 - val_accuracy: 0.8923\n",
      "Epoch 19/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.1590 - accuracy: 0.9502 - val_loss: 0.4235 - val_accuracy: 0.8923\n",
      "Epoch 20/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.1658 - accuracy: 0.9593 - val_loss: 0.3819 - val_accuracy: 0.8462\n",
      "Epoch 21/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.1673 - accuracy: 0.9367 - val_loss: 0.4636 - val_accuracy: 0.8923\n",
      "Epoch 22/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.1656 - accuracy: 0.9502 - val_loss: 0.3567 - val_accuracy: 0.8462\n",
      "Epoch 23/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.1528 - accuracy: 0.9548 - val_loss: 0.4338 - val_accuracy: 0.8923\n",
      "Epoch 24/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.1596 - accuracy: 0.9548 - val_loss: 0.3663 - val_accuracy: 0.8923\n",
      "Epoch 25/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.1362 - accuracy: 0.9548 - val_loss: 0.3831 - val_accuracy: 0.8923\n",
      "Epoch 26/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.1446 - accuracy: 0.9638 - val_loss: 0.3204 - val_accuracy: 0.8769\n",
      "Epoch 27/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.2003 - accuracy: 0.9321 - val_loss: 0.4970 - val_accuracy: 0.8462\n",
      "Epoch 28/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.1502 - accuracy: 0.9548 - val_loss: 0.3060 - val_accuracy: 0.9077\n",
      "Epoch 29/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.1253 - accuracy: 0.9638 - val_loss: 0.3825 - val_accuracy: 0.8923\n",
      "Epoch 30/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.1183 - accuracy: 0.9638 - val_loss: 0.3274 - val_accuracy: 0.9077\n",
      "Epoch 31/100\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.1043 - accuracy: 0.9638 - val_loss: 0.3864 - val_accuracy: 0.9077\n",
      "Epoch 32/100\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.1104 - accuracy: 0.9638 - val_loss: 0.3291 - val_accuracy: 0.9231\n",
      "Epoch 33/100\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.0889 - accuracy: 0.9774 - val_loss: 0.4169 - val_accuracy: 0.9077\n",
      "Epoch 34/100\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0958 - accuracy: 0.9819 - val_loss: 0.3560 - val_accuracy: 0.9231\n",
      "Epoch 35/100\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0867 - accuracy: 0.9864 - val_loss: 0.3761 - val_accuracy: 0.9231\n",
      "95.38461565971375\n",
      "Test Accuracy: 95.385% (+/-0.000)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "score_1,history_1= evaluate_model_1(X_train_arr, y_train_arr, X_valid_arr, y_valid_arr, X_test_arr, y_test_arr)\n",
    "score_1 = score_1 * 100.0\n",
    "summarize_results(score_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**defined-model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "\n",
    "# # fit and evaluate a model\n",
    "# def evaluate_model_2(trainX, trainy,validX,validy, testX, testy):\n",
    "# #  verbose, epochs, batch_size = 1, 1500, 100\n",
    "#  n_timesteps, n_features, n_outputs = trainX.shape[1], trainX.shape[2], 7\n",
    "\n",
    "#  model = Sequential()\n",
    "#  model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(n_timesteps, n_features)))\n",
    "#  model.add(MaxPooling1D(pool_size=2))\n",
    "#  model.add(LSTM(units=64)) # remember the important features\n",
    "#  model.add(Dense(100, activation='relu'))\n",
    "#  model.add(Dense(64, activation='relu')) \n",
    "#  model.add(Dropout(0.5))#for regularization\n",
    "#  model.add(Dense(n_outputs, activation='softmax'))\n",
    "#  model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "#  # fit network\n",
    "#  history=model.fit(trainX, trainy, validation_data=(validX, validy), epochs=epochs, batch_size=batch_size,callbacks=[callback], verbose=verbose)\n",
    "#  #summarize_mode\n",
    "#  print(model.summary())\n",
    "\n",
    "#  #load-model\n",
    "#  pickle.dump(model, open(\"../all_pkl_file/all_tuned_model/PCA_model2_fitted_2.pkl\", \"wb\"))\n",
    " \n",
    "#  # evaluate model\n",
    "#  _, accuracy = model.evaluate(testX, testy, batch_size=batch_size, verbose=0)\n",
    "#  # '_,'-->a variable is being used for a specific purpose, but its value is not of interest or not used in the subsequent code.\n",
    "#  return accuracy,history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# score_2,history_2= evaluate_model_2(X_train_arr, y_train_arr, X_valid_arr, y_valid_arr, X_test_arr, y_test_arr)\n",
    "# score_2 = score_2 * 100.0\n",
    "# summarize_results(score_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # plot loss-curve_2\n",
    "# pyplot.plot(history_2.history['loss'], label='training')\n",
    "# pyplot.plot(history_2.history['val_loss'], label='validation')\n",
    "# plt.xlabel('epoch')\n",
    "# plt.ylabel('loss')\n",
    "# plt.title('Loss-curve')\n",
    "# pyplot.legend()\n",
    "# pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion-matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load the encoder model from the saved file\n",
    "# with open(\"../all_pkl_file/all_tuned_model/PCA_model2_fitted_2.pkl\", \"rb\") as file: #\"rb\"= read mode\n",
    "#     model = pickle.load(file)\n",
    "\n",
    "# model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**confusionmatrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  #confusion_matrix\n",
    "\n",
    "# from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix\n",
    "\n",
    "\n",
    "# predictions=model.predict(X_test_arr)\n",
    "# print(y_test_arr)\n",
    "# print(len(y_test_arr),',',len(y_test_arr[0]))\n",
    "# print(predictions)\n",
    "# print(len(predictions),',',len(predictions[0]))\n",
    "\n",
    "# for i in range(len(predictions)):\n",
    "#     for j in range(len(predictions[0])):\n",
    "#         if predictions[i][j]==max(predictions[i]):\n",
    "#             predictions[i][j]=1\n",
    "#         else: predictions[i][j]=0\n",
    "\n",
    "# # reverse one-hot encoding for fit into confusion matrix\n",
    "# y_test_cm=y_test_arr.argmax(axis=1)\n",
    "# print(y_test_cm)\n",
    "# predictions_cm=predictions.argmax(axis=1)\n",
    "# print(predictions_cm)\n",
    "\n",
    "# cm = confusion_matrix(y_test_cm, predictions_cm, labels=[0,1,2,3,4,5,6])\n",
    "# disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
    "#                             display_labels=[0,1,2,3,4,5,6])\n",
    "# disp.plot()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # plot loss-curve\n",
    "# pyplot.plot(history_1.history['loss'], label='training')\n",
    "# pyplot.plot(history_1.history['val_loss'], label='validation')\n",
    "# plt.xlabel('epoch')\n",
    "# plt.ylabel('loss')\n",
    "# plt.title('Loss-curve')\n",
    "# pyplot.legend()\n",
    "# pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # plot training history\n",
    "# pyplot.plot(history.history['accuracy'], label='train')\n",
    "# pyplot.plot(history.history['val_accuracy'], label='test')\n",
    "# plt.xlabel('epoch')\n",
    "# plt.ylabel('accuracy')\n",
    "# plt.title('Accuracy-curve')\n",
    "# pyplot.legend()\n",
    "# pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ROC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load the encoder model from the saved file\n",
    "# with open(\"../all_pkl_file/all_tuned_model/PCA_model2_fitted_2.pkl\", \"rb\") as file: #\"rb\"= read mode\n",
    "#     model = pickle.load(file)\n",
    "\n",
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# from sklearn.metrics import roc_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions=model.predict(X_test_arr)\n",
    "# for i in range(len(predictions)):\n",
    "#     for j in range(len(predictions[0])):\n",
    "#         if predictions[i][j]==max(predictions[i]):\n",
    "#             predictions[i][j]=1\n",
    "#         else: predictions[i][j]=0\n",
    "# # Compute ROC curve and ROC area for each class\n",
    "# fpr = dict()\n",
    "# tpr = dict()\n",
    "# roc_auc = dict()\n",
    "\n",
    "# for i in range(7):\n",
    "#     fpr[i], tpr[i], _ = roc_curve(y_test_arr[:, i], predictions[:, i])\n",
    "#     roc_auc[i] = auc(fpr[i], tpr[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plot ROC curve for each class\n",
    "# plt.figure()\n",
    "# for i in range(7):\n",
    "#     plt.plot(fpr[i], tpr[i], label=f'class {i}(area = {roc_auc[i]:0.2f})')\n",
    "# plt.plot([0, 1], [0, 1], 'k--')\n",
    "# plt.xlabel('False Positive Rate')\n",
    "# plt.ylabel('True Positive Rate')\n",
    "# plt.title('ROC Curve')\n",
    "# plt.legend(loc='lower right')\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
