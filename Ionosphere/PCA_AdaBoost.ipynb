{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import optuna\n",
    "# import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "#plt.style.use('fivethirtyeight')\n",
    "import xgboost as xgb\n",
    "import sklearn\n",
    "import random\n",
    "from NecessaryModules.getData import getData\n",
    "from NecessaryModules.splitData import split_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.0, 0.0, 0.99539, -0.05889, 0.85243, 0.02306, 0.83398, -0.37708, 1.0, 0.0376, 0.85243, -0.17755, 0.59755, -0.44945, 0.60536, -0.38223, 0.84356, -0.38542, 0.58212, -0.32192, 0.56971, -0.29674, 0.36946, -0.47357, 0.56811, -0.51171, 0.41078, -0.46168, 0.21266, -0.3409, 0.42267, -0.54487, 0.18641, -0.453], [1.0, 0.0, 1.0, -0.18829, 0.93035, -0.36156, -0.10868, -0.93597, 1.0, -0.04549, 0.50874, -0.67743, 0.34432, -0.69707, -0.51685, -0.97515, 0.05499, -0.62237, 0.33109, -1.0, -0.13151, -0.453, -0.18056, -0.35734, -0.20332, -0.26569, -0.20468, -0.18401, -0.1904, -0.11593, -0.16626, -0.06288, -0.13738, -0.02447], [1.0, 0.0, 1.0, -0.03365, 1.0, 0.00485, 1.0, -0.12062, 0.88965, 0.01198, 0.73082, 0.05346, 0.85443, 0.00827, 0.54591, 0.00299, 0.83775, -0.13644, 0.75535, -0.0854, 0.70887, -0.27502, 0.43385, -0.12062, 0.57528, -0.4022, 0.58984, -0.22145, 0.431, -0.17365, 0.60436, -0.2418, 0.56045, -0.38238], [1.0, 0.0, 1.0, -0.45161, 1.0, 1.0, 0.71216, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.14516, 0.54094, -0.3933, -1.0, -0.54467, -0.69975, 1.0, 0.0, 0.0, 1.0, 0.90695, 0.51613, 1.0, 1.0, -0.20099, 0.25682, 1.0, -0.32382, 1.0], [1.0, 0.0, 1.0, -0.02401, 0.9414, 0.06531, 0.92106, -0.23255, 0.77152, -0.16399, 0.52798, -0.20275, 0.56409, -0.00712, 0.34395, -0.27457, 0.5294, -0.2178, 0.45107, -0.17813, 0.05982, -0.35575, 0.02309, -0.52879, 0.03286, -0.65158, 0.1329, -0.53206, 0.02431, -0.62197, -0.05707, -0.59573, -0.04608, -0.65697], [1.0, 0.0, 0.02337, -0.00592, -0.09924, -0.11949, -0.00763, -0.11824, 0.14706, 0.06637, 0.03786, -0.06302, 0.0, 0.0, -0.04572, -0.1554, -0.00343, -0.10196, -0.11575, -0.05414, 0.01838, 0.03669, 0.01519, 0.00888, 0.03513, -0.01535, -0.0324, 0.09223, -0.07859, 0.00732, 0.0, 0.0, -0.00039, 0.12011], [1.0, 0.0, 0.97588, -0.10602, 0.94601, -0.208, 0.92806, -0.2835, 0.85996, -0.27342, 0.79766, -0.47929, 0.78225, -0.50764, 0.74628, -0.61436, 0.57945, -0.68086, 0.37852, -0.73641, 0.36324, -0.76562, 0.31898, -0.79753, 0.22792, -0.81634, 0.13659, -0.8251, 0.04606, -0.82395, -0.04262, -0.81318, -0.13832, -0.80975], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, -1.0, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.96355, -0.07198, 1.0, -0.14333, 1.0, -0.21313, 1.0, -0.36174, 0.9257, -0.43569, 0.9451, -0.40668, 0.90392, -0.46381, 0.98305, -0.35257, 0.84537, -0.6602, 0.75346, -0.60589, 0.69637, -0.64225, 0.85106, -0.6544, 0.57577, -0.69712, 0.25435, -0.63919, 0.45114, -0.72779, 0.38895, -0.7342], [1.0, 0.0, -0.01864, -0.08459, 0.0, 0.0, 0.0, 0.0, 0.1147, -0.2681, -0.45663, -0.38172, 0.0, 0.0, -0.33656, 0.38602, -0.37133, 0.15018, 0.63728, 0.22115, 0.0, 0.0, 0.0, 0.0, -0.14803, -0.01326, 0.20645, -0.02294, 0.0, 0.0, 0.16595, 0.24086, -0.08208, 0.38065], [1.0, 0.0, 1.0, 0.06655, 1.0, -0.18388, 1.0, -0.2732, 1.0, -0.43107, 1.0, -0.41349, 0.96232, -0.51874, 0.90711, -0.59017, 0.8923, -0.66474, 0.69876, -0.70997, 0.70645, -0.7632, 0.63081, -0.80544, 0.55867, -0.89128, 0.47211, -0.865, 0.40303, -0.83675, 0.30996, -0.89093, 0.22995, -0.89158], [1.0, 0.0, 1.0, -0.5421, 1.0, -1.0, 1.0, -1.0, 1.0, 0.36217, 1.0, -0.41119, 1.0, 1.0, 1.0, -1.0, 1.0, -0.29354, 1.0, -0.93599, 1.0, 1.0, 1.0, 1.0, 1.0, -0.40888, 1.0, -0.62745, 1.0, -1.0, 1.0, -1.0, 1.0, -1.0], [1.0, 0.0, 1.0, -0.16316, 1.0, -0.10169, 0.99999, -0.15197, 1.0, -0.19277, 0.94055, -0.35151, 0.95735, -0.29785, 0.93719, -0.34412, 0.94486, -0.28106, 0.90137, -0.43383, 0.86043, -0.47308, 0.82987, -0.5122, 0.8408, -0.47137, 0.76224, -0.5837, 0.65723, -0.68794, 0.68714, -0.64537, 0.64727, -0.67226], [1.0, 0.0, 1.0, -0.86701, 1.0, 0.2228, 0.85492, -0.39896, 1.0, -0.1209, 1.0, 0.35147, 1.0, 0.07772, 1.0, -0.14767, 1.0, -1.0, 1.0, -1.0, 0.61831, 0.15803, 1.0, 0.62349, 1.0, -0.17012, 1.0, 0.35924, 1.0, -0.66494, 1.0, 0.88428, 1.0, -0.18826], [1.0, 0.0, 1.0, 0.0738, 1.0, 0.0342, 1.0, -0.05563, 1.0, 0.08764, 1.0, 0.19651, 1.0, 0.20328, 1.0, 0.12785, 1.0, 0.10561, 1.0, 0.27087, 1.0, 0.44758, 1.0, 0.4175, 1.0, 0.20033, 1.0, 0.36743, 0.95603, 0.48641, 1.0, 0.32492, 1.0, 0.46712], [1.0, 0.0, 0.50932, -0.93996, 1.0, 0.26708, -0.0352, -1.0, 1.0, -1.0, 0.43685, -1.0, 0.0, 0.0, -1.0, -0.34265, -0.37681, 0.03623, 1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -0.16253, 0.92236, 0.39752, 0.26501, 0.0, 0.0, 1.0, 0.23188, 0.0, 0.0], [1.0, 0.0, 0.99645, 0.06468, 1.0, -0.01236, 0.97811, 0.02498, 0.96112, 0.02312, 0.99274, 0.07808, 0.89323, 0.10346, 0.94212, 0.05269, 0.88809, 0.1112, 0.86104, 0.08631, 0.81633, 0.1183, 0.83668, 0.14442, 0.81329, 0.13412, 0.79476, 0.13638, 0.7911, 0.15379, 0.77122, 0.1593, 0.70941, 0.12015], [0.0, 0.0, 0.0, 0.0, -1.0, -1.0, 1.0, 1.0, -1.0, 1.0, -1.0, 1.0, 1.0, -1.0, 1.0, 1.0, -1.0, -1.0, -1.0, 1.0, 1.0, -1.0, -1.0, 1.0, -1.0, 1.0, 1.0, -1.0, -1.0, 1.0, -1.0, -1.0, 1.0, -1.0], [1.0, 0.0, 0.67065, 0.02528, 0.66626, 0.05031, 0.57197, 0.18761, 0.08776, 0.34081, 0.63621, 0.12131, 0.62099, 0.14285, 0.78637, 0.10976, 0.58373, 0.18151, 0.14395, 0.41224, 0.53888, 0.21326, 0.5142, 0.22625, 0.48838, 0.23724, 0.46167, 0.24618, 0.43433, 0.25306, 0.40663, 0.25792, 1.0, 0.33036], [0.0, 0.0, 1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, -1.0, -0.71875, 1.0, 0.0, 0.0, -1.0, 1.0, 1.0, 1.0, -1.0, 1.0, 1.0, 0.5625, -1.0, 1.0, 1.0, 1.0, 1.0, -1.0, 1.0, 1.0, 1.0, 1.0], [1.0, 0.0, 1.0, -0.00612, 1.0, -0.09834, 1.0, -0.07649, 1.0, -0.10605, 1.0, -0.11073, 1.0, -0.39489, 1.0, -0.15616, 0.92124, -0.31884, 0.86473, -0.34534, 0.91693, -0.44072, 0.9606, -0.46866, 0.81874, -0.40372, 0.82681, -0.42231, 0.75784, -0.38231, 0.80448, -0.40575, 0.74354, -0.45039], [0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, 1.0, -1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, -1.0, -1.0, 1.0, -1.0, 1.0, -1.0, 1.0], [1.0, 0.0, 0.96071, 0.07088, 1.0, 0.04296, 1.0, 0.09313, 0.90169, -0.05144, 0.89263, 0.0258, 0.8325, -0.06142, 0.87534, 0.09831, 0.76544, 0.0028, 0.75206, -0.05295, 0.65961, -0.07905, 0.64158, -0.05929, 0.55677, -0.07705, 0.58051, -0.02205, 0.49664, -0.01251, 0.5131, -0.00015, 0.52099, -0.00182], [0.0, 0.0, -1.0, 1.0, 0.0, 0.0, 0.0, 0.0, -1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, -1.0, -1.0, 1.0, 1.0, 1.0, 0.0, 0.0, -1.0, -1.0, 1.0, -1.0, 1.0, 1.0, -1.0, 1.0, 0.0, 0.0], [1.0, 0.0, 1.0, -0.06182, 1.0, 0.02942, 1.0, -0.05131, 1.0, -0.01707, 1.0, -0.11726, 0.84493, -0.05202, 0.93392, -0.06598, 0.6917, -0.07379, 0.65731, -0.20367, 0.9491, -0.31558, 0.80852, -0.31654, 0.84932, -0.34838, 0.72529, -0.29174, 0.73094, -0.38576, 0.54356, -0.26284, 0.64207, -0.39487], [1.0, 0.0, 1.0, 0.5782, 1.0, -1.0, 1.0, -1.0, 1.0, -1.0, 1.0, -1.0, 1.0, -1.0, 1.0, -1.0, 1.0, -1.0, 1.0, -1.0, 1.0, -0.62796, 1.0, -1.0, 1.0, -1.0, 1.0, -1.0, 1.0, -1.0, 1.0, -1.0, 1.0, -1.0], [1.0, 0.0, 1.0, -0.08714, 1.0, -0.17263, 0.86635, -0.81779, 0.94817, 0.61053, 0.95473, -0.41382, 0.88486, -0.31736, 0.87937, -0.23433, 0.81051, -0.6218, 0.12245, -1.0, 0.90284, 0.11053, 0.62357, -0.78547, 0.55389, -0.82868, 0.48136, -0.86583, 0.4065, -0.89674, 0.32984, -0.92128, -0.13341, -1.0], [0.0, 0.0, -1.0, -1.0, 0.0, 0.0, -1.0, 1.0, 1.0, -0.375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, -1.0, -1.0, -1.0, 1.0, -1.0, 0.0, 0.0, 1.0, -1.0, -1.0, 1.0, -1.0, -1.0, 0.0, 0.0, -1.0, 1.0], [1.0, 0.0, 1.0, 0.0838, 1.0, 0.17387, 1.0, -0.13308, 0.98172, 0.6452, 1.0, 0.47904, 1.0, 0.59113, 1.0, 0.70758, 1.0, 0.82777, 1.0, 0.95099, 1.0, 1.0, 0.98042, 1.0, 0.91624, 1.0, 0.83899, 1.0, 0.74822, 1.0, 0.64358, 1.0, 0.52479, 1.0], [0.0, 0.0, -1.0, -1.0, 1.0, 1.0, 1.0, -1.0, -1.0, 1.0, 1.0, -1.0, -1.0, -1.0, 0.0, 0.0, 1.0, 1.0, -1.0, -1.0, 1.0, -1.0, 1.0, -1.0, 1.0, 1.0, 1.0, -1.0, 1.0, -1.0, -1.0, 1.0, 1.0, -1.0], [1.0, 0.0, 1.0, -0.14236, 1.0, -0.16256, 1.0, -0.23656, 1.0, -0.07514, 1.0, -0.2501, 1.0, -0.26161, 1.0, -0.21975, 1.0, -0.38606, 1.0, -0.46162, 1.0, -0.35519, 1.0, -0.59661, 1.0, -0.47643, 0.9882, -0.49687, 1.0, -0.7582, 1.0, -0.75761, 1.0, -0.84437], [1.0, 0.0, 1.0, -1.0, 1.0, 1.0, 1.0, -1.0, 1.0, -1.0, 1.0, -1.0, 1.0, -0.0184, 1.0, -1.0, 1.0, 1.0, 1.0, -0.85583, 1.0, 1.0, 1.0, -1.0, 0.0, 0.0, 1.0, 1.0, 1.0, -0.79141, 1.0, 1.0, 1.0, 1.0], [1.0, 0.0, 0.88208, -0.14639, 0.93408, -0.11057, 0.921, -0.1645, 0.88307, -0.17036, 0.88462, -0.31809, 0.85269, -0.31463, 0.82116, -0.35924, 0.80681, -0.33632, 0.75243, -0.47022, 0.70555, -0.47153, 0.6615, -0.50085, 0.61297, -0.48086, 0.56804, -0.54629, 0.50179, -0.59854, 0.47075, -0.57377, 0.42189, -0.58086], [1.0, 0.0, 0.71253, -0.02595, 0.41287, -0.23067, 0.98019, -0.09473, 0.99709, -0.10236, 1.0, -0.10951, 0.58965, 1.0, 0.83726, -1.0, 0.8227, -0.17863, 0.8076, -0.28257, -0.25914, 0.9273, 0.51933, 0.05456, 0.65493, -0.20392, 0.93124, -0.41307, 0.63811, -0.21901, 0.86136, -0.87354, -0.23186, -1.0], [1.0, 0.0, 1.0, -0.15899, 0.72314, 0.27686, 0.83443, -0.58388, 1.0, -0.28207, 1.0, -0.49863, 0.79962, -0.12527, 0.76837, 0.14638, 1.0, 0.39337, 1.0, 0.2659, 0.96354, -0.01891, 0.92599, -0.91338, 1.0, 0.14803, 1.0, -0.11582, 1.0, -0.11129, 1.0, 0.53372, 1.0, -0.57758], [1.0, 0.0, 0.66161, -1.0, 1.0, 1.0, 1.0, -0.67321, 0.80893, -0.40446, 1.0, -1.0, 1.0, -0.89375, 1.0, 0.73393, 0.17589, 0.70982, 1.0, 0.78036, 1.0, 0.85268, 1.0, -1.0, 1.0, 0.85357, 1.0, -0.08571, 0.95982, -0.3625, 1.0, 0.65268, 1.0, 0.34732], [1.0, 0.0, 1.0, 0.00433, 1.0, -0.01209, 1.0, -0.0296, 1.0, -0.07014, 0.97839, -0.06256, 1.0, -0.06544, 0.97261, -0.07917, 0.92561, -0.13665, 0.94184, -0.14327, 0.99589, -0.14248, 0.94815, -0.13565, 0.89469, -0.20851, 0.89067, -0.17909, 0.85644, -0.18552, 0.83777, -0.20101, 0.83867, -0.20766], [0.0, 0.0, 1.0, 1.0, 1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, 1.0, 1.0, 1.0, -1.0, 1.0, -1.0, 1.0, 1.0, -1.0, 1.0, 1.0, -1.0, 1.0, 1.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.91241, 0.04347, 0.94191, 0.0228, 0.94705, 0.05345, 0.93582, 0.01321, 0.91911, 0.06348, 0.92766, 0.12067, 0.92048, 0.06211, 0.88899, 0.12722, 0.83744, 0.14439, 0.80983, 0.11849, 0.77041, 0.14222, 0.75755, 0.11299, 0.7355, 0.13282, 0.66387, 0.153, 0.70925, 0.10754, 0.65258, 0.11447], [1.0, 0.0, 1.0, 0.02461, 0.99672, 0.04861, 0.97545, 0.07143, 0.61745, -1.0, 0.91036, 0.11147, 0.88462, 0.5364, 0.82077, 0.14137, 0.76929, 0.15189, 1.0, 0.41003, 0.6585, 0.16371, 0.60138, 0.16516, 0.54446, 0.1639, 0.48867, 0.16019, 0.43481, 0.15436, 0.38352, 0.14677, 1.0, 1.0], [1.0, 0.0, 1.0, 0.06538, 1.0, 0.20746, 1.0, 0.26281, 0.93051, 0.32213, 0.86773, 0.39039, 0.75474, 0.50082, 0.79555, 0.52321, 0.65954, 0.60756, 0.57619, 0.62999, 0.47807, 0.67135, 0.40553, 0.6884, 0.34384, 0.72082, 0.27712, 0.72386, 0.19296, 0.70682, 0.11372, 0.72688, 0.0699, 0.71444], [1.0, 0.0, -1.0, -1.0, 1.0, 1.0, 1.0, -0.14375, 0.0, 0.0, -1.0, 1.0, 1.0, 1.0, 0.17917, -1.0, -1.0, -1.0, 0.0875, -1.0, 1.0, -1.0, -1.0, 1.0, -1.0, -1.0, 1.0, -1.0, -1.0, -1.0, 1.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.90932, 0.08791, 0.86528, 0.16888, 1.0, 0.16598, 0.55187, 0.68154, 0.70207, 0.36719, 0.16286, 0.42739, 0.5762, 0.46086, 0.51067, 0.49618, 0.31639, 0.12967, 0.37824, 0.54462, 0.31274, 0.55826, 0.24856, 0.56527, 0.18626, 0.56605, 0.12635, 0.56101, 0.06927, 0.55061, 0.12137, 0.67739], [1.0, 0.0, -0.64286, -1.0, 1.0, 0.82857, 1.0, -1.0, 1.0, -0.23393, 1.0, 0.96161, 1.0, -0.37679, 1.0, -1.0, 1.0, 0.13839, 1.0, -1.0, 1.0, -0.03393, -0.84286, 1.0, 0.5375, 0.85714, 1.0, 1.0, 1.0, -1.0, 1.0, -1.0, 1.0, -1.0], [1.0, 0.0, 0.99025, -0.05785, 0.99793, -0.13009, 0.98663, -0.1943, 0.99374, -0.25843, 0.92738, -0.3013, 0.92651, -0.37965, 0.89812, -0.43796, 0.84922, -0.52064, 0.87433, -0.57075, 0.79016, -0.59839, 0.74725, -0.64615, 0.68282, -0.68479, 0.65247, -0.73174, 0.6101, -0.75353, 0.54752, -0.80278, 0.49195, -0.83245], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, -0.375, -1.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, 1.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 1.0, -0.0373, 1.0, -0.07383, 0.99601, -0.11039, 0.99838, -0.09931, 0.98941, -0.13814, 0.96674, -0.21695, 0.95288, -0.25099, 0.91236, -0.344, 0.90581, -0.32152, 0.89991, -0.34691, 0.87874, -0.37643, 0.86213, -0.4299, 0.83172, -0.43122, 0.81433, -0.42593, 0.77919, -0.47977, 0.75115, -0.50152], [1.0, 0.0, 0.94598, -0.02685, -1.0, 0.26131, -0.36393, 0.35639, 0.69258, -0.63427, 1.0, -0.03353, -0.2902, -0.0055, -0.54852, 0.15452, 0.91921, -0.4627, 1.0, -0.50424, -0.29735, -0.31454, -0.73864, 0.37361, 0.83872, -0.46734, 0.52208, -0.5813, 1.0, -0.61393, -0.09634, 0.20477, -0.06117, 0.41913], [1.0, 0.0, 0.98166, 0.00874, 0.98103, -0.03818, 0.97565, -0.05699, 0.95947, -0.06971, 0.99004, -0.04507, 0.94713, -0.11102, 0.93369, -0.1279, 0.94217, -0.11583, 0.79682, -0.192, 0.88274, -0.17387, 0.86257, -0.18739, 0.88487, -0.19689, 0.81813, -0.21136, 0.78546, -0.23864, 0.76911, -0.23095, 0.74323, -0.23902], [1.0, 0.0, 0.0, 0.0, 1.0, 0.51724, 0.0, 0.0, 0.10991, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, -0.22414, -0.55711, -0.83297, 0.7694, 0.63147, 0.0, 0.0, 0.53448, 0.35668, -0.90302, 0.44828, 1.0, -1.0, -1.0, 0.81573, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.84134, -0.18362, 0.43644, 0.02919, 0.93421, -0.00267, 0.87947, 0.13795, 0.81121, -0.01789, 0.88559, 0.54991, 0.91714, -0.57486, 0.75, -0.2952, 0.86676, -0.20104, 1.0, 1.0, 0.4661, -0.1629, 0.90066, -0.02778, 0.93358, -0.01158, 0.61582, -0.32298, 0.84463, -0.25706, 0.93323, -0.01425], [0.0, 0.0, 1.0, 1.0, 1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, -1.0, -1.0, 1.0, -1.0, -1.0, 1.0, 0.0, 0.0, 1.0, -1.0, 1.0, -1.0, 1.0, 1.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.9101, 1.0, -0.2697, 1.0, -0.83152, 1.0, -1.0, 1.0, -1.0, 0.72526, -1.0, -0.57779, -1.0, -0.42052, -1.0, -1.0, -0.52838, -1.0, 0.90014, -1.0, 1.0, -1.0, 1.0, -1.0, 1.0, -0.34686, 1.0, 0.34845], [1.0, 0.0, -0.67935, -1.0, -1.0, 1.0, 1.0, 0.63317, 0.03515, -1.0, -1.0, -1.0, 1.0, 1.0, 0.88683, -1.0, -1.0, 1.0, 0.8384, 1.0, 1.0, -1.0, -1.0, -1.0, -0.18856, 1.0, 1.0, -1.0, -1.0, -1.0, -1.0, 1.0, 1.0, 0.33611], [1.0, 0.0, 0.95659, 0.08143, 0.97487, -0.05667, 0.97165, -0.08484, 0.96097, -0.06561, 0.94717, 0.01279, 0.95436, -0.16795, 0.94612, -0.19497, 0.9963, -0.32268, 0.90343, -0.35902, 0.91428, -0.27316, 0.9014, -0.29807, 0.99899, -0.40747, 0.87244, -0.34586, 0.92059, -0.30619, 0.83951, -0.39061, 0.82166, -0.41173], [1.0, 0.0, 0.08333, -0.20685, -1.0, 1.0, -1.0, 1.0, 0.71875, 0.47173, -0.82143, -0.62723, -1.0, -1.0, -1.0, 1.0, -0.02753, 0.59152, -0.42113, -0.42113, -0.74628, -1.0, -1.0, -0.46801, -1.0, 0.2381, 1.0, -1.0, -1.0, -0.38914, -1.0, -1.0, -1.0, 0.61458], [1.0, 0.0, 1.0, -0.02259, 1.0, -0.04494, 1.0, -0.06682, 1.0, -0.08799, 1.0, 0.56173, 1.0, -0.12738, 1.0, -0.14522, 1.0, 0.32407, 1.0, -0.17639, 0.99484, -0.18949, 0.95601, -0.20081, 1.0, -0.92284, 0.8728, -0.21793, 0.8292, -0.2237, 0.78479, -0.22765, 0.73992, -0.22981], [0.0, 0.0, -1.0, 1.0, 1.0, -1.0, -1.0, 1.0, 0.0, 0.0, 1.0, 1.0, -1.0, -0.1875, 1.0, 1.0, -1.0, -1.0, 1.0, -1.0, -1.0, -1.0, 1.0, 1.0, 1.0, -1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, -1.0, -1.0], [1.0, 0.0, 1.0, 0.05812, 0.94525, 0.07418, 0.99952, 0.13231, 1.0, -0.01911, 0.94846, 0.07033, 0.95713, 0.14644, 0.94862, 0.11224, 0.90896, 0.20119, 0.96741, 0.16265, 0.99695, 0.14258, 0.90784, 0.1641, 0.91667, 0.22431, 0.88423, 0.23571, 0.88568, 0.22511, 0.78324, 0.29576, 0.83574, 0.31166], [1.0, 0.0, 0.17188, -1.0, -1.0, 1.0, 0.0, 0.0, 0.0, 0.0, -1.0, 1.0, 0.0, 0.0, -0.61354, -0.67708, 0.80521, 0.36146, 0.51979, 0.14375, 0.0, 0.0, -1.0, -0.27083, -0.84792, 0.9625, 1.0, 1.0, -1.0, 0.67708, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 1.0, 0.09771, 1.0, 0.12197, 1.0, 0.22574, 0.98602, 0.09237, 0.9493, 0.19211, 0.92992, 0.24288, 0.89241, 0.28343, 0.85529, 0.26721, 0.83656, 0.33129, 0.83393, 0.31698, 0.74829, 0.39597, 0.76193, 0.34658, 0.68452, 0.42746, 0.62764, 0.46031, 0.56791, 0.47033, 0.54252, 0.50903], [1.0, 0.0, 0.01667, -0.35625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12292, -0.55, 0.22813, 0.82813, 1.0, -0.42292, 0.0, 0.0, 0.08333, -1.0, -0.10625, -0.16667, 1.0, -0.76667, -1.0, 0.18854, 0.0, 0.0, 1.0, -0.27292], [1.0, 0.0, 1.0, 0.16801, 0.99352, 0.16334, 0.94616, 0.33347, 0.91759, 0.2261, 0.91408, 0.37107, 0.8425, 0.46899, 0.81011, 0.49225, 0.78473, 0.48311, 0.65091, 0.56977, 0.56553, 0.58071, 0.55586, 0.6472, 0.48311, 0.55236, 0.43317, 0.69129, 0.35684, 0.76147, 0.33921, 0.66844, 0.22101, 0.78685], [1.0, 0.0, 0.63816, 1.0, 0.20833, -1.0, 1.0, 1.0, 0.87719, 0.30921, -0.66886, 1.0, -0.05921, 0.58772, 0.01754, 0.05044, -0.51535, -1.0, 0.14254, -0.03289, 0.32675, -0.4386, -1.0, 1.0, 0.80921, -1.0, 1.0, -0.0614, 1.0, 1.0, 0.20614, -1.0, 1.0, 1.0], [1.0, 0.0, 1.0, -0.41457, 1.0, 0.76131, 0.8706, 0.18593, 1.0, -0.09925, 0.93844, 0.4799, 0.65452, -0.1608, 1.0, 0.00879, 0.97613, -0.50126, 0.80025, -0.24497, 0.88065, -0.19095, 1.0, -0.12312, 0.93593, 0.10678, 0.9289, -0.07249, 1.0, -0.27387, 0.4397, 0.19849, 0.51382, -0.05402], [1.0, 0.0, 0.84783, 0.10598, 1.0, 0.3913, 1.0, -1.0, 0.66938, 0.08424, 1.0, 0.27038, 1.0, 0.60598, 1.0, 0.35507, 1.0, 0.02672, 0.58424, -0.43025, 1.0, 0.63496, 0.8913, 0.26585, 0.91033, -0.33333, 1.0, 0.15942, 0.37681, -0.01947, 1.0, 0.22464, 1.0, 0.37409], [1.0, 0.0, 1.0, 0.28046, 1.0, 0.02477, 1.0, 0.07764, 1.0, 0.04317, 0.98762, 0.33266, 1.0, 0.05489, 1.0, 0.04384, 0.9575, -0.24598, 0.84371, -0.08668, 1.0, 0.0415, 0.99933, 0.27376, 1.0, -0.39056, 0.96414, -0.02174, 0.86747, 0.2336, 0.94578, -0.22021, 0.80355, -0.07329], [0.0, 0.0, 1.0, -1.0, 1.0, -1.0, 1.0, -1.0, 1.0, -1.0, 1.0, 1.0, 1.0, 1.0, 1.0, -1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, -1.0, 1.0, -1.0, 1.0, -1.0, 1.0, 0.65625, 0.0, 0.0, 1.0, -1.0], [1.0, 0.0, 1.0, 0.67784, 0.81309, 0.82021, 0.43019, 1.0, 0.20619, 0.80541, -0.43872, 1.0, -0.79135, 0.77092, -1.0, 0.40268, -0.39046, -0.58634, -0.97907, -0.42822, -0.73083, -0.76339, -0.37671, -0.97491, 0.41366, -1.0, 0.41778, -0.93296, 0.25773, -1.0, 0.9357, -0.35222, 0.98816, 0.03446], [1.0, 0.0, 1.0, 1.0, 1.0, -1.0, 1.0, -1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, -1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.0, 0.0, 1.0, -1.0, 1.0, -1.0], [1.0, 0.0, 1.0, 0.03529, 1.0, 0.18281, 1.0, 0.26968, 1.0, 0.25068, 1.0, 0.28778, 1.0, 0.38643, 1.0, 0.31674, 1.0, 0.65701, 1.0, 0.53846, 1.0, 0.61267, 1.0, 0.59457, 0.89593, 0.68326, 0.89502, 0.71374, 0.85611, 0.67149, 0.74389, 0.85611, 0.71493, 0.75837], [0.0, 0.0, 1.0, -1.0, 1.0, 1.0, -1.0, -1.0, 1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, 1.0, 1.0, -1.0, 1.0, -1.0, -0.75, 1.0, 1.0, -1.0, 1.0, -1.0, 1.0, -1.0, -1.0, -1.0, 0.0, 0.0, 1.0, -1.0], [1.0, 0.0, 0.96087, 0.0862, 0.9676, 0.19279, 0.96026, 0.27451, 0.98044, 0.35052, 0.92867, 0.46281, 0.86265, 0.52517, 0.8282, 0.58794, 0.73242, 0.69065, 0.69003, 0.7314, 0.54473, 0.6882, 0.48339, 0.76197, 0.40615, 0.74689, 0.33401, 0.83796, 0.24944, 0.86061, 0.13756, 0.86835, 0.09048, 0.86285], [1.0, 0.0, 0.69444, 0.38889, 0.0, 0.0, -0.32937, 0.69841, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.20635, -0.24206, 0.21032, 0.19444, 0.46429, 0.78175, 0.0, 0.0, 0.0, 0.0, 0.73413, 0.27381, 0.7619, 0.63492, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 1.0, 0.0507, 1.0, 0.10827, 1.0, 0.19498, 1.0, 0.28453, 1.0, 0.34826, 1.0, 0.38261, 0.94575, 0.42881, 0.89126, 0.50391, 0.75906, 0.58801, 0.80644, 0.59962, 0.79578, 0.62758, 0.66643, 0.63942, 0.59417, 0.69435, 0.49538, 0.72684, 0.47027, 0.71689, 0.33381, 0.75243], [0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, -1.0, 1.0, -1.0, 1.0, 1.0, 1.0, 1.0, 1.0, -1.0, 1.0, 1.0, 1.0, 1.0, 1.0, -1.0, -1.0, -1.0, 1.0, -1.0, 1.0, -1.0, 1.0, 1.0, 0.0, 0.0, 1.0, -1.0], [1.0, 0.0, 1.0, 0.04078, 1.0, 0.11982, 1.0, 0.16159, 1.0, 0.27921, 0.98703, 0.30889, 0.92745, 0.37639, 0.91118, 0.39749, 0.81939, 0.46059, 0.78619, 0.46994, 0.794, 0.56282, 0.70331, 0.58129, 0.67077, 0.59723, 0.58903, 0.6099, 0.53952, 0.60932, 0.45312, 0.63636, 0.40442, 0.62658], [0.0, 0.0, 1.0, 1.0, 1.0, -1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, -1.0, -1.0, 1.0, -1.0, 1.0, -1.0, 1.0, 1.0, -1.0, 1.0, 1.0, -1.0, 1.0, -1.0, -1.0, -1.0, 1.0], [1.0, 0.0, 1.0, 0.24168, 1.0, 0.4859, 1.0, 0.72973, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.77128, 1.0, 1.0, 1.0, 1.0, 0.74468, 1.0, 0.89647, 1.0, 0.64628, 1.0, 0.38255, 1.0, 0.10819, 1.0, -0.1737, 1.0, -0.81383, 1.0], [0.0, 0.0, 1.0, 1.0, 1.0, -1.0, 1.0, 1.0, -1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, -1.0, 1.0, -1.0, 1.0, 1.0, 1.0, 1.0, -1.0, 1.0, 1.0, 1.0, 1.0, 1.0, -1.0, -1.0, 1.0], [1.0, 0.0, 1.0, -0.06604, 1.0, 0.62937, 1.0, 0.09557, 1.0, 0.2028, 1.0, -1.0, 1.0, -0.40559, 1.0, -0.15851, 1.0, 0.04895, 1.0, -0.61538, 1.0, -0.26573, 1.0, -1.0, 1.0, -0.58042, 1.0, -0.81372, 1.0, -1.0, 1.0, -0.78555, 1.0, -0.48252], [0.0, 0.0, 1.0, -1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, -1.0, 1.0, -1.0, 1.0, 1.0, 1.0, -1.0, 1.0, 1.0, 1.0, 1.0, 1.0, -1.0, 1.0, 1.0, 1.0, -1.0, 1.0, 1.0, 1.0, -1.0], [1.0, 0.0, 0.92277, 0.07804, 0.92679, 0.16251, 0.89702, 0.24618, 0.84111, 0.35197, 0.78801, 0.42196, 0.70716, 0.46983, 0.70796, 0.56476, 0.60459, 0.642, 0.51247, 0.64924, 0.39903, 0.66975, 0.34232, 0.68343, 0.23693, 0.76146, 0.18765, 0.73885, 0.09694, 0.71038, 0.02735, 0.77072, -0.04023, 0.69509], [1.0, 0.0, 0.68198, -0.17314, 0.82332, 0.21908, 0.46643, 0.32862, 0.25795, 0.58304, 1.0, -0.15194, 0.0106, 0.44523, 0.0106, 0.38869, 0.18681, 0.41168, 0.10567, 0.36353, 0.04325, 0.30745, -0.00083, 0.24936, -0.02862, 0.19405, -0.04314, 0.14481, -0.04779, 0.10349, -0.04585, 0.07064, -0.04013, 0.04586], [1.0, 0.0, 0.74852, -0.02811, 0.6568, -0.05178, 0.80621, 0.02811, 0.85947, 0.02515, 0.63462, 0.08728, 0.71598, 0.0784, 0.73077, 0.05178, 0.7855, -0.27811, 0.65976, -0.01479, 0.78698, 0.06953, 0.34615, -0.18639, 0.65385, 0.02811, 0.61009, -0.06637, 0.5355, -0.21154, 0.59024, -0.14053, 0.56361, 0.02959], [1.0, 0.0, 0.39179, -0.06343, 0.97464, 0.04328, 1.0, 1.0, 0.35821, 0.15299, 0.54478, 0.1306, 0.61567, -0.8209, 0.57836, 0.6791, 0.66791, -0.10448, 0.46642, -0.11567, 0.65574, 0.14792, 0.83209, 0.45522, 0.47015, 0.16418, 0.49309, 0.1463, 0.32463, -0.02612, 0.39118, 0.13521, 0.34411, 0.12755], [1.0, 0.0, 0.67547, 0.04528, 0.76981, -0.10566, 0.77358, 0.03774, 0.66038, -0.04528, 0.64528, 0.01132, 0.66792, -0.13962, 0.72075, -0.02264, 0.76981, 0.08679, 0.61887, -0.07925, 0.75849, -0.23774, 0.73962, -0.14717, 0.84906, -0.15094, 0.73886, -0.05801, 0.66792, 0.02264, 0.86415, 0.03774, 0.73208, 0.00755], [1.0, 0.0, 0.72727, -0.05, 0.89241, 0.03462, 1.0, 0.72727, 0.66364, -0.05909, 0.48182, -0.16818, 0.81809, 0.09559, 0.56818, 1.0, 0.50455, 0.21818, 0.66818, 0.1, 1.0, -0.3, 0.98636, -1.0, 0.57273, 0.32727, 0.56982, 0.14673, 0.42273, 0.08182, 0.48927, 0.14643, 1.0, 1.0], [1.0, 0.0, 0.57647, -0.01569, 0.40392, 0.0, 0.38431, 0.12941, 0.4, -0.05882, 0.56471, 0.14118, 0.46667, 0.08235, 0.52549, -0.0549, 0.58039, 0.01569, 0.50196, 0.0, 0.45882, 0.06667, 0.58039, 0.08235, 0.49804, 0.00392, 0.48601, 0.10039, 0.46275, 0.08235, 0.45098, 0.23529, 0.43137, 0.17255], [1.0, 0.0, 0.41932, 0.12482, 0.35, 0.125, 0.23182, 0.27955, -0.03636, 0.44318, 0.04517, 0.36194, -0.19091, 0.33636, -0.1335, 0.27322, 0.02727, 0.40455, -0.34773, 0.12727, -0.20028, 0.05078, -0.18636, 0.36364, -0.14003, -0.04802, -0.09971, -0.07114, -1.0, -1.0, -0.02916, -0.07464, -0.00526, -0.06314], [1.0, 0.0, 0.88305, -0.21996, 1.0, 0.36373, 0.82403, 0.19206, 0.85086, 0.05901, 0.90558, -0.04292, 0.85193, 0.25, 0.77897, 0.25322, 0.69206, 0.5794, 0.7103, 0.39056, 0.73176, 0.27575, 1.0, 0.34871, 0.5676, 0.52039, 0.69811, 0.53235, 0.80901, 0.58584, 0.43026, 0.70923, 0.52361, 0.54185], [1.0, 0.0, 0.84557, -0.0858, -0.31745, -0.80553, -0.08961, -0.56435, 0.80648, 0.04576, 0.89514, -0.00763, -0.18494, 0.63966, -0.20019, -0.68065, 0.85701, -0.11344, 0.77979, -0.15729, -0.06959, 0.5081, -0.34128, 0.80934, 0.78932, -0.03718, 0.70882, -0.25288, 0.77884, -0.14109, -0.21354, -0.7817, -0.18494, -0.59867], [1.0, 0.0, 0.7087, -0.24783, 0.64348, 0.04348, 0.45217, 0.38261, 0.65217, 0.18261, 0.5, 0.26957, 0.57826, -0.23043, 0.50435, 0.37826, 0.38696, -0.42609, 0.36087, -0.26087, 0.26957, 0.11739, 0.53246, -0.03845, 0.31304, -0.12174, 0.4993, -0.04264, 0.48348, -0.04448, 0.64348, -0.25217, 0.50435, 0.14783], [1.0, 0.0, -0.5418, 0.14861, -0.33746, 0.73375, 0.52012, -0.13932, 0.31889, -0.06811, 0.20743, -0.1517, 0.47368, 0.08978, 0.56347, -0.1548, 0.16409, 0.45201, 0.33746, 0.03406, 0.50464, 0.07121, -0.63777, -0.6161, 1.0, 0.65635, 0.41348, -0.40116, -0.1517, 0.11146, 0.02399, 0.5582, 0.52632, -0.08978], [1.0, 0.0, 0.29202, 0.13582, 0.45331, 0.16808, 0.51783, -0.00509, 0.52632, 0.20883, 0.52462, -0.16638, 0.47368, -0.04754, 0.55518, 0.03905, 0.81664, -0.22411, 0.42445, -0.04244, 0.34975, 0.06621, 0.28183, -0.20883, 0.51731, -0.03176, 0.50369, -0.03351, 0.34635, 0.09847, 0.70798, -0.01868, 0.39559, -0.03226], [1.0, 0.0, 0.79157, 0.16851, 0.0, 0.0, 0.56541, 0.06874, 0.39468, 1.0, 0.38359, 0.99557, -0.02439, 0.53215, 0.23725, 0.1286, -0.02661, 0.95122, -0.50998, 0.84922, -0.102, 0.38803, -0.42572, 0.23725, -0.91574, 0.8071, -0.34146, 0.88248, -1.0, 0.69401, -1.0, 0.1286, 0.0, 0.0], [1.0, 0.0, 0.90116, 0.16607, 0.79299, 0.37379, 0.7299, 0.50515, 0.59784, 0.72997, 0.44303, 0.81152, 0.24412, 0.87493, 0.06438, 0.85038, -0.12611, 0.87396, -0.28739, 0.79617, -0.46635, 0.65924, -0.57135, 0.53805, -0.68159, 0.39951, -0.71844, 0.25835, -0.72369, 0.11218, -0.71475, -0.05525, -0.67699, -0.19904], [1.0, 0.0, 0.97714, 0.19049, 0.82683, 0.46259, 0.71771, 0.58732, 0.47968, 0.84278, 0.31409, 0.92643, 0.10289, 0.93945, -0.13254, 0.8429, -0.3202, 0.91624, -0.52145, 0.79525, -0.68274, 0.49508, -0.77408, 0.33537, -0.85376, 0.17849, -0.83314, -0.01358, -0.82366, -0.19321, -0.67289, -0.33662, -0.59943, -0.497], [1.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.50814, -0.78502, 0.60586, 0.32899, -1.0, -0.41368, 0.0, 0.0, 0.0, 0.0, 1.0, -0.2671, 0.36482, -0.63518, 0.97068, -1.0, -1.0, -1.0, 1.0, -0.59609, -1.0, -1.0, -1.0, -1.0, 1.0, -1.0, 0.0, 0.0], [1.0, 0.0, 0.74084, 0.04974, 0.79074, 0.02543, 0.78575, 0.03793, 0.6623, 0.09948, 0.67801, 0.31152, 0.75934, 0.07348, 0.74695, 0.08442, 0.70681, -0.07853, 0.63613, 0.0, 0.70021, 0.11355, 0.68183, 0.12185, 0.67016, 0.15445, 0.64158, 0.13608, 0.65707, 0.17539, 0.59759, 0.14697, 0.57455, 0.15114], [1.0, 0.0, 1.0, -1.0, 0.0, 0.0, 0.77941, -0.99265, 0.80882, 0.55147, -0.41912, -0.94853, 0.0, 0.0, 0.0, 0.0, 0.72059, -0.77206, 0.73529, -0.60294, 0.0, 0.0, 0.18382, -1.0, -1.0, -1.0, -1.0, -1.0, 1.0, -1.0, 1.0, -1.0, 0.0, 0.0], [1.0, 0.0, 1.0, 0.01709, 0.96215, -0.03142, 1.0, -0.03436, 1.0, -0.05071, 0.99026, -0.07092, 0.99173, -0.09002, 1.0, -0.15727, 1.0, -0.14257, 0.9831, -0.11813, 1.0, -0.18519, 1.0, -0.19272, 0.98971, -0.22083, 0.9649, -0.20243, 0.94599, -0.17123, 0.96436, -0.22561, 0.87011, -0.23296], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.95704, -0.12095, 0.63318, -0.1269, 0.96365, -0.18242, 0.97026, 0.0846, 0.92003, -0.01124, 0.83543, -0.24719, 1.0, -0.31395, 0.99273, -0.21216, 0.98678, -0.21018, 1.0, -0.27165, 0.93126, -0.39458, 1.0, -0.19233, 0.88793, -0.31565, 0.81428, -0.23728, 0.89095, -0.31857, 0.69531, -0.41573], [1.0, 0.0, 0.28409, -0.31818, 0.0, 0.0, 0.68182, -1.0, 0.30682, 0.95833, 0.64394, 0.06439, 0.34848, -0.84848, 0.0, 0.0, 0.59091, -0.35985, 0.45076, -0.80682, 0.0, 0.0, 0.0, 0.0, 0.24242, 0.17803, 1.0, -0.23864, 0.06061, -0.48485, 0.16288, -0.70076, 0.0, 0.0], [1.0, 0.0, 0.9449, -0.49311, 1.0, -0.03692, 0.98898, -0.87052, 0.90083, 0.66942, 1.0, -0.10104, 1.0, -0.12493, 1.0, -0.15017, 1.0, -0.17681, 1.0, -0.20491, 1.0, -0.23452, 1.0, -0.26571, 1.0, -0.29852, 1.0, -0.33304, 1.0, -0.36931, 1.0, -0.4074, 1.0, -0.44739], [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.62195, 1.0, 0.0, 0.0, 0.0, 0.0, 0.36585, -0.71951, 0.56098, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.10976, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.99449, 0.00526, 0.84082, -0.11313, 0.88237, -0.16431, 0.99061, -0.06257, 0.96484, -0.07496, 0.85221, 0.02966, 0.87161, -0.20848, 0.93881, -0.12977, 0.98298, -0.08935, 0.89876, 0.00075, 0.87836, -0.05882, 0.93368, -0.19872, 0.87579, -0.17806, 0.94294, -0.16581, 0.80253, -0.25741, 0.76586, -0.27794], [1.0, 0.0, 0.10135, 0.10811, 0.0, 0.0, 0.0, 0.0, 0.5473, 0.82432, 0.31081, 1.0, 0.0, 0.0, 0.0, 0.0, 0.37162, -1.0, 0.33108, -1.0, 0.0, 0.0, 0.0, 0.0, -0.42568, -1.0, 1.0, -1.0, 0.55405, -0.23649, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 1.0, -0.57224, 0.9915, -0.73371, 0.89518, -0.9745, 1.0, -0.35818, 1.0, -0.23229, 0.6289, -0.86402, 1.0, -0.57535, 1.0, -0.79603, 0.76771, -0.88952, 0.96601, -1.0, 0.7012, -0.74896, 0.61946, -0.76904, 0.53777, -0.77986, 0.8102, -1.0, 1.0, -1.0, 0.30445, -0.76112], [1.0, 0.0, 0.65909, -0.62879, 0.0, 0.0, 0.0, 0.0, 0.77273, 1.0, 1.0, -0.2803, 0.0, 0.0, 0.0, 0.0, 0.62121, -0.22727, 0.84091, -1.0, 1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 1.0, -0.93939, -0.12879, -0.93182, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.86284, 0.1931, 0.8092, 0.41149, 0.67203, 0.55785, 0.54559, 0.69962, 0.36705, 0.81533, 0.19617, 0.85671, -0.04061, 0.86284, -0.17241, 0.75785, -0.341, 0.65747, -0.48199, 0.56092, -0.6023, 0.40996, -0.59234, 0.25747, -0.63038, 0.08818, -0.57241, -0.07816, -0.54866, -0.19923, -0.42912, -0.31954], [1.0, 0.0, 0.42, -0.61, 0.0, 0.0, 1.0, -1.0, 0.9, 1.0, 0.43, 0.64, 0.0, 0.0, 0.0, 0.0, 0.67, -0.29, 0.84, -1.0, 0.0, 0.0, 0.0, 0.0, 0.21, 0.68, 1.0, 0.22, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 1.0, 0.23395, 0.91404, 0.52013, 0.7802, 0.72144, 0.4766, 0.84222, 0.27639, 0.9173, 0.09467, 0.88248, -0.2198, 0.91404, -0.34168, 0.75517, -0.5136, 0.64527, -0.64527, 0.44614, -0.74102, 0.29162, -0.70838, 0.03591, -0.71731, -0.11943, -0.64962, -0.28183, -0.51251, -0.44505, -0.37432, -0.53319], [1.0, 0.0, 0.91353, 0.81586, -0.72973, 1.0, -0.39466, 0.55735, 0.05405, 0.2973, -0.18599, -0.10241, -0.03158, -0.0897, 0.01401, -0.03403, 0.01108, -0.00537, 0.00342, 0.00097, 0.00048, 0.00075, -3e-05, 0.00019, -3e-05, 2e-05, -1e-05, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.21429, -0.09524, 0.33333, 0.07143, 0.19048, 0.19048, 0.2381, 0.09524, 0.40476, 0.02381, 0.30952, -0.04762, 0.30952, -0.04762, 0.28571, -0.11905, 0.33333, 0.04762, 0.30952, 0.0, 0.21429, -0.11905, 0.35714, -0.04762, 0.22109, -0.0229, 0.19048, 0.0, 0.16997, -0.02034, 0.14694, -0.01877], [1.0, 0.0, 1.0, -0.14754, 1.0, 0.04918, 0.57377, -0.01639, 0.65574, 0.01639, 0.85246, -0.03279, 0.72131, 0.0, 0.68852, -0.16393, 0.19672, -0.14754, 0.65558, -0.17176, 0.67213, 0.03279, 1.0, -0.29508, 0.31148, -0.34426, 0.52385, -0.20325, 0.32787, -0.03279, 0.27869, -0.44262, 0.4918, -0.06557], [1.0, 0.0, 0.98182, 0.0, 0.88627, 0.03131, 0.86249, 0.04572, 0.8, 0.0, 0.69091, 0.04545, 0.79343, 0.08436, 0.77118, 0.09579, 0.62727, 0.25455, 0.68182, 0.12727, 0.70674, 0.12608, 0.68604, 0.13493, 0.74545, 0.22727, 0.64581, 0.15088, 0.67273, 0.02727, 0.60715, 0.16465, 0.5884, 0.17077], [1.0, 0.0, 0.39286, 0.52381, -0.78824, 0.11342, -0.16628, -0.76378, 0.66667, 0.0119, 0.82143, 0.40476, -0.6723, 0.30729, -0.34797, -0.63668, 0.46429, 0.15476, 0.54762, 0.05952, -0.5183, 0.44961, -0.47651, -0.47594, 0.32143, 0.70238, 0.51971, 0.38848, 0.57143, 0.39286, -0.54891, -0.29915, 0.25441, -0.55837], [1.0, 0.0, 0.86889, -0.07111, 1.0, -0.02494, 1.0, -0.06889, 0.87778, 0.00222, 0.83556, -0.06444, 1.0, -0.07287, 1.0, -0.2, 0.86889, 0.05333, 0.88, -0.03778, 1.0, -0.11526, 1.0, -0.18667, 0.84444, 0.03556, 1.0, -0.14162, 0.82222, -0.14667, 1.0, -0.15609, 1.0, -0.44222], [1.0, 0.0, 0.43636, -0.12727, 0.58182, -0.14545, 0.18182, -0.67273, 0.34545, -0.03636, 0.29091, -0.05455, 0.29091, 0.29091, 0.36364, -0.41818, 0.2, -0.01818, 0.36364, 0.05455, 0.12727, 0.49091, 0.61818, 0.16364, 0.32727, 0.16364, 0.41098, -0.07027, 0.34545, -0.05455, 0.12727, -0.36364, 0.29091, -0.29091], [1.0, 0.0, 1.0, -0.92453, 1.0, 0.75472, 0.49057, -0.0566, 0.62264, 0.0, 1.0, -0.00054, 0.45283, 0.07547, 0.62264, -0.0566, 0.98878, -0.00085, 0.5283, 0.0, 0.5283, 0.07547, 0.9519, -0.00112, 1.0, 0.79245, 0.92192, -0.00128, 0.9434, -1.0, 1.0, 0.43396, 0.43396, -0.11321], [1.0, 0.0, 0.7381, 0.83333, -0.7619, -0.2381, 0.33333, -0.14286, 0.45238, -0.14286, -0.67285, 0.12808, 0.33333, 0.0, 0.28571, -0.07143, -0.38214, 0.51163, 0.2381, 0.02381, 0.45238, 0.04762, 0.16667, -0.2619, -0.57255, -0.10234, 0.24889, -0.51079, 1.0, 0.0, -0.66667, -0.04762, 0.2619, 0.02381], [1.0, 0.0, 0.4375, 0.04167, 0.58333, -0.10417, 0.39583, 0.0, 0.33333, -0.0625, 0.47917, 0.0, 0.29167, 0.10417, 0.54167, 0.02083, 0.4375, -0.22917, 0.35417, -0.22917, 0.33333, 0.08333, 0.25, 0.1875, 0.39583, -0.1875, 0.44012, -0.10064, 0.41667, -0.08333, 0.58333, -0.3125, 0.33333, -0.0625], [1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.47744, -0.89098, -0.51504, 0.45489, -0.95489, 0.28571, 0.64662, 1.0, 0.0, 0.0, 0.0, 0.0, 0.6203, 0.20301, -1.0, -1.0, 1.0, -1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.95217, 0.06595, 0.93614, 0.1303, 0.90996, 0.19152, 0.84881, -0.49962, 0.90023, 0.6132, 0.77937, 0.34328, 0.72254, 0.37988, 0.66145, 0.40844, 0.95472, 0.59862, 0.53258, 0.44088, 0.46773, 0.44511, 0.4044, 0.44199, 0.34374, 0.43221, 0.9033, 1.0, 0.23405, 0.3962, 0.18632, 0.37191], [1.0, 0.0, 0.5984, 0.40332, 0.82809, 0.80521, 0.76001, 0.70709, 0.8401, -0.10984, 0.97311, 0.07981, 0.95824, -0.85727, 0.91962, 0.88444, 0.95452, -0.05206, 0.88673, 0.18135, 0.98484, -0.69594, 0.8667, -0.85755, 0.28604, -0.30063, 1.0, 0.17076, 0.62958, 0.42677, 0.87757, 0.81007, 0.81979, 0.68822], [1.0, 0.0, 0.95882, 0.10129, 1.0, -0.01918, 0.98313, 0.02555, 0.96974, -0.09316, 0.98955, -0.02716, 0.9798, -0.03096, 1.0, -0.05343, 1.0, -0.05179, 0.9384, 0.01557, 0.9762, -0.09284, 0.97889, -0.05318, 0.91567, -0.15675, 0.95677, -0.06995, 0.90978, 0.01307, 1.0, -0.10797, 0.93144, -0.06888], [1.0, 0.0, 0.0, 0.0, -0.33672, 0.85388, 0.0, 0.0, 0.68869, -1.0, 0.97078, 0.31385, -0.26048, -0.59212, -0.30241, 0.65565, 0.94155, 0.16391, 0.0, 0.0, 0.0, 0.0, -0.18043, -1.0, 0.0, 0.0, 1.0, -1.0, 0.0, 0.0, 0.04447, 0.61881, 0.0, 0.0], [1.0, 0.0, 0.96933, 0.00876, 1.0, 0.00843, 0.98658, -0.00763, 0.97868, -0.02844, 0.9982, -0.0351, 1.0, -0.01271, 1.0, -0.02581, 1.0, -0.01175, 0.98485, 0.00025, 1.0, -0.02612, 1.0, -0.04744, 0.96019, -0.04527, 0.99188, -0.03473, 0.9702, -0.02478, 1.0, -0.03855, 0.9842, -0.04112], [1.0, 0.0, 0.0, 0.0, 0.98919, -0.22703, 0.18919, -0.05405, 0.0, 0.0, 0.93243, 0.07297, 1.0, -0.2, 1.0, 0.07027, 1.0, -0.11351, 0.0, 0.0, 1.0, -0.21081, 1.0, -0.41622, 0.0, 0.0, 1.0, -0.17568, 0.0, 0.0, 1.0, -0.25946, 0.28919, -0.15676], [1.0, 0.0, 0.64122, 0.01403, 0.34146, -0.02439, 0.52751, 0.03466, 0.19512, 0.12195, 0.43313, 0.04755, 0.21951, 0.04878, 0.29268, 0.0, 0.36585, 0.0, 0.31707, 0.07317, 0.26829, 0.12195, 0.23698, 0.05813, 0.21951, 0.09756, 0.19304, 0.05641, 0.1741, 0.05504, 0.19512, 0.0, 0.17073, 0.07317], [1.0, 0.0, 1.0, 1.0, 1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, -1.0, 1.0, 1.0, 1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 1.0, -0.27778, 0.0, 0.0, 1.0, -1.0, 1.0, 1.0, 1.0, -1.0, 0.0, 0.0], [1.0, 0.0, 0.34694, 0.20408, 0.46939, 0.2449, 0.40816, 0.20408, 0.46939, 0.44898, 0.30612, 0.59184, 0.12245, 0.55102, 0.0, 0.5102, -0.06122, 0.55102, -0.20408, 0.55102, -0.28571, 0.44898, -0.28571, 0.32653, -0.61224, 0.22449, -0.46579, 0.14895, -0.59184, 0.18367, -0.34694, 0.0, -0.26531, -0.2449], [1.0, 0.0, 0.0, 0.0, 1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, -0.25342, 1.0, 0.23288, 1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, -1.0, 0.0, 0.0, 1.0, -1.0, 0.0, 0.0], [1.0, 0.0, 0.89706, 0.38235, 0.91176, 0.375, 0.74265, 0.67647, 0.45588, 0.77941, 0.19118, 0.88971, -0.02206, 0.86029, -0.20588, 0.82353, -0.375, 0.67647, -0.5, 0.47794, -0.73529, 0.38235, -0.86029, 0.08824, -0.74265, -0.125, -0.67925, -0.24131, -0.55147, -0.42647, -0.44118, -0.50735, -0.28676, -0.56618], [1.0, 0.0, -1.0, 0.28105, 0.22222, 0.15033, -0.75693, -0.70984, -0.30719, 0.71242, -1.0, 1.0, -0.81699, 0.33987, -0.79085, -0.02614, -0.98039, -0.83007, -0.60131, -0.54248, -0.04575, -0.83007, 0.94118, -0.94118, -1.0, -0.43137, 0.74385, 0.09176, -1.0, 0.05229, 0.18301, 0.02614, -0.40201, -0.48241], [1.0, 0.0, 0.26667, -0.1, 0.53333, 0.0, 0.33333, -0.13333, 0.36667, 0.11667, 0.56667, 0.01667, 0.71667, 0.08333, 0.7, -0.06667, 0.53333, 0.2, 0.41667, -0.01667, 0.31667, 0.2, 0.7, 0.0, 0.25, 0.13333, 0.46214, 0.05439, 0.4, 0.03333, 0.46667, 0.03333, 0.41667, -0.05], [1.0, 0.0, -0.26667, 0.4, -0.27303, 0.12159, -0.17778, -0.04444, 0.06192, -0.06879, 0.04461, 0.02575, -0.00885, 0.02726, -0.01586, -0.00166, -0.00093, -0.00883, 0.0047, -0.00153, 0.00138, 0.00238, -0.00114, 0.00102, -0.00069, -0.0005, 0.00019, -0.00043, 0.00026, 5e-05, 0.0, 0.00015, -8e-05, 2e-05], [1.0, 0.0, 1.0, -0.37838, 0.64865, 0.2973, 0.64865, -0.24324, 0.86486, 0.18919, 1.0, -0.27027, 0.51351, 0.0, 0.62162, -0.05405, 0.32432, -0.21622, 0.71833, -0.17666, 0.62162, 0.05405, 0.75676, 0.13514, 0.35135, -0.2973, 0.61031, -0.22163, 0.58478, -0.23027, 0.72973, -0.59459, 0.51351, -0.24324], [1.0, 0.0, 0.94531, -0.03516, -1.0, -0.33203, -1.0, -0.01563, 0.97266, 0.01172, 0.93359, -0.01953, -1.0, 0.16406, -1.0, -0.00391, 0.95313, -0.03516, 0.92188, -0.02734, -0.99219, 0.11719, -0.93359, 0.34766, 0.95703, -0.00391, 0.82041, 0.13758, 0.90234, -0.06641, -1.0, -0.1875, -1.0, -0.34375], [1.0, 0.0, 0.95202, 0.02254, 0.93757, -0.01272, 0.93526, 0.01214, 0.96705, -0.01734, 0.96936, 0.0052, 0.95665, -0.03064, 0.9526, -0.00405, 0.9948, -0.02659, 0.99769, 0.01792, 0.93584, -0.04971, 0.93815, -0.0237, 0.97052, -0.04451, 0.96215, -0.01647, 0.97399, 0.01908, 0.95434, -0.0341, 0.95838, 0.00809], [1.0, 0.0, 1.0, -0.05529, 1.0, -1.0, 0.5, -0.11111, 0.36111, -0.22222, 1.0, -0.25712, 0.16667, -0.11111, 1.0, -0.3466, 1.0, -0.38853, 1.0, -0.42862, 0.0, -0.25, 1.0, -0.50333, 1.0, -0.27778, 1.0, -0.57092, 1.0, -0.27778, 1.0, -0.63156, 1.0, -0.65935], [1.0, 0.0, 0.31034, -0.10345, 0.24138, -0.10345, 0.2069, -0.06897, 0.07405, -0.05431, 0.03649, -0.03689, 0.01707, -0.02383, 0.00741, -0.01482, 0.00281, -0.00893, 0.00078, -0.00523, -3e-05, -0.00299, -0.00028, -0.00166, -0.00031, -0.0009, -0.00025, -0.00048, -0.00018, -0.00024, -0.00012, -0.00012, -8e-05, -6e-05], [1.0, 0.0, 0.62745, -0.07843, 0.72549, 0.0, 0.60784, -0.07843, 0.62745, -0.11765, 0.68627, -0.11765, 0.66667, -0.13725, 0.64706, -0.09804, 0.54902, -0.11765, 0.54902, -0.21569, 0.58824, -0.19608, 0.66667, -0.23529, 0.45098, -0.2549, 0.52409, -0.24668, 0.56863, -0.31373, 0.43137, -0.21569, 0.47059, -0.27451], [1.0, 0.0, 0.25, 0.16667, 0.46667, 0.26667, 0.19036, 0.23966, 0.07766, 0.19939, 0.0107, 0.14922, -0.02367, 0.10188, -0.03685, 0.06317, -0.03766, 0.03458, -0.0323, 0.01532, -0.02474, 0.00357, -0.01726, -0.00273, -0.01097, -0.00539, -0.00621, -0.00586, -0.00294, -0.0052, -0.00089, -0.00408, 0.00025, -0.00291], [1.0, 0.0, -0.65625, 0.15625, 0.0625, 0.0, 0.0, 0.0625, 0.625, 0.0625, 0.1875, 0.0, -0.03125, 0.09375, 0.0625, 0.0, 0.15625, -0.15625, 0.4375, -0.375, 0.0, -0.09375, 0.0, 0.0, 0.03125, -0.46875, 0.03125, 0.0, -0.71875, 0.03125, -0.03125, 0.0, 0.0, 0.09375], [1.0, 0.0, 1.0, -0.01081, 1.0, -0.02703, 1.0, -0.06486, 0.95135, -0.01622, 0.98919, -0.03243, 0.98919, 0.08649, 1.0, -0.06486, 0.95135, 0.09189, 0.97838, -0.00541, 1.0, 0.06486, 1.0, 0.04324, 0.97838, 0.09189, 0.98556, 0.01251, 1.0, -0.03243, 1.0, 0.02703, 1.0, -0.07027], [1.0, 0.0, 0.85271, 0.05426, 1.0, 0.08069, 1.0, 1.0, 0.91473, -0.00775, 0.83721, 0.03876, 1.0, 0.27153, 1.0, 1.0, 0.81395, 0.04651, 0.90698, 0.11628, 1.0, 0.5067, 1.0, -1.0, 0.8062, 0.03876, 1.0, 0.71613, 0.84496, 0.06977, 1.0, 0.87317, 1.0, 1.0], [1.0, 0.0, 0.90374, -0.01604, 1.0, 0.08021, 1.0, 0.01604, 0.93048, 0.00535, 0.93583, -0.01604, 1.0, 0.0, 1.0, 0.06417, 1.0, 0.04813, 0.91444, 0.04278, 0.96791, 0.02139, 0.9893, -0.01604, 0.96257, 0.05348, 0.96974, 0.04452, 0.87701, 0.0107, 1.0, 0.09091, 0.97861, 0.06417], [1.0, 0.0, -0.205, 0.2875, 0.23, 0.1, 0.2825, 0.3175, 0.3225, 0.35, 0.36285, -0.34617, 0.0925, 0.275, -0.095, 0.21, -0.0875, 0.235, -0.34187, 0.31408, -0.48, -0.08, 0.29908, 0.33176, -0.58, -0.24, 0.3219, -0.28475, -0.47, 0.185, -0.27104, -0.31228, 0.40445, 0.0305], [1.0, 0.0, 0.6, 0.03333, 0.63333, 0.06667, 0.7, 0.06667, 0.7, 0.0, 0.63333, 0.0, 0.8, 0.0, 0.73333, 0.0, 0.7, 0.1, 0.66667, 0.1, 0.73333, -0.03333, 0.76667, 0.0, 0.63333, 0.13333, 0.65932, 0.10168, 0.6, 0.13333, 0.6, 0.16667, 0.63333, 0.16667], [1.0, 0.0, 0.05866, -0.00838, 0.06704, 0.00838, 0.0, -0.01117, 0.00559, -0.03911, 0.01676, -0.07542, -0.00559, 0.05307, 0.06425, -0.03352, 0.0, 0.09497, -0.06425, 0.07542, -0.04749, 0.02514, 0.02793, -0.00559, 0.00838, 0.00559, 0.10335, -0.00838, 0.03073, -0.00279, 0.04469, 0.0, 0.04749, -0.03352], [1.0, 0.0, 0.94653, 0.28713, 0.72554, 0.67248, 0.47564, 0.82455, 0.01267, 0.89109, -0.24871, 0.84475, -0.47644, 0.56079, -0.75881, 0.41743, -0.66455, 0.07208, -0.65426, -0.19525, -0.52475, -0.44, -0.30851, -0.55089, -0.04119, -0.64792, 0.16085, -0.5642, 0.36752, -0.41901, 0.46059, -0.22535, 0.50376, -0.0598], [1.0, 0.0, 0.0546, 0.01437, -0.02586, 0.04598, 0.01437, 0.04598, -0.07759, 0.00862, 0.01724, -0.06609, -0.03736, 0.0431, -0.08333, -0.04598, -0.09483, 0.08046, -0.04023, 0.05172, 0.02011, 0.02299, -0.03736, -0.01149, 0.03161, -0.00862, 0.00862, 0.01724, 0.02586, 0.01149, 0.02586, 0.01149, -0.04598, -0.00575], [1.0, 0.0, 0.72414, -0.01084, 0.79704, 0.01084, 0.8, 0.00197, 0.79015, 0.01084, 0.78424, -0.00985, 0.8335, 0.03251, 0.85123, 0.01675, 0.80099, -0.00788, 0.79113, -0.02956, 0.75961, 0.0335, 0.74778, 0.05517, 0.72611, -0.01478, 0.78041, 0.00612, 0.74089, -0.05025, 0.82956, 0.02956, 0.79015, 0.00788], [1.0, 0.0, 0.03852, 0.02568, 0.00428, 0.0, 0.01997, -0.01997, 0.0214, -0.04993, -0.0485, -0.01284, 0.01427, -0.02282, 0.0, -0.03281, -0.04708, -0.02853, -0.01712, 0.03566, 0.0214, 0.00428, 0.05136, -0.02282, 0.05136, 0.01854, 0.03994, 0.01569, 0.01997, 0.00713, -0.02568, -0.01854, -0.01427, 0.01997], [1.0, 0.0, 0.4709, 0.22751, 0.42328, 0.33598, 0.25661, 0.47619, 0.01852, 0.49471, -0.02116, 0.53968, -0.34127, 0.31217, -0.4127, 0.3254, -0.51587, 0.06878, -0.5, -0.1164, -0.14815, -0.1455, -0.14815, -0.38095, -0.2328, 0.00265, 0.03574, -0.31739, 0.15873, -0.21693, 0.24868, -0.24339, 0.2672, 0.04233], [1.0, 0.0, 0.08696, 0.00686, 0.13959, -0.04119, 0.10526, -0.08238, 0.12586, -0.06178, 0.23341, -0.01144, 0.12357, 0.0778, 0.14645, -0.13501, 0.29062, -0.04805, 0.18993, 0.07323, 0.1167, 0.0, 0.11213, -0.00229, 0.15103, -0.10297, 0.08467, 0.01373, 0.11213, -0.06636, 0.09611, -0.07323, 0.1167, -0.06865], [1.0, 0.0, 0.94333, 0.38574, 0.48263, 0.64534, 0.21572, 0.77514, -0.55941, 0.64899, -0.73675, 0.42048, -0.76051, 0.0, -0.62706, -0.31079, -0.38391, -0.62157, -0.12797, -0.69287, 0.49909, -0.6362, 0.71481, -0.3766, 0.73857, -0.05484, 0.60098, 0.30384, 0.45521, 0.60512, 0.02742, 0.54479, -0.21572, 0.50457], [1.0, 0.0, 0.01975, 0.00705, 0.0409, -0.00846, 0.02116, 0.01128, 0.01128, 0.04372, 0.00282, 0.00141, 0.01975, -0.03103, -0.01975, 0.06065, -0.0409, 0.0268, -0.02398, -0.00423, 0.04372, -0.02539, 0.01834, 0.0, 0.0, -0.01269, 0.01834, -0.01128, 0.00564, -0.01551, -0.01693, -0.02398, 0.00705, 0.0], [1.0, 0.0, 0.85736, 0.00075, 0.81927, -0.05676, 0.77521, -0.04182, 0.84317, 0.09037, 0.86258, 0.11949, 0.88051, -0.06124, 0.78342, 0.0351, 0.83719, -0.06796, 0.8357, -0.1419, 0.88125, 0.01195, 0.90515, 0.0224, 0.79686, -0.01942, 0.82383, -0.03678, 0.88125, -0.06423, 0.73936, -0.01942, 0.79089, -0.09186], [1.0, 0.0, 1.0, -1.0, 1.0, 1.0, -1.0, 1.0, 1.0, -1.0, 1.0, -1.0, -1.0, -1.0, -1.0, 1.0, 1.0, 1.0, 1.0, 1.0, -1.0, 1.0, 1.0, -1.0, 1.0, -1.0, 1.0, 1.0, 1.0, 1.0, -1.0, 1.0, -1.0, 1.0], [1.0, 0.0, 0.85209, 0.39252, 0.38887, 0.76432, 0.08858, 0.98903, -0.42625, 0.88744, -0.76229, 0.4998, -0.93092, 0.10768, -0.859, -0.31044, -0.6603, -0.55262, -0.1926, -0.86063, 0.28444, -0.80496, 0.64649, -0.3523, 0.77814, -0.23324, 0.71698, 0.21343, 0.3783, 0.5831, 0.19667, 0.66315, -0.11215, 0.64933], [1.0, 0.0, 1.0, 1.0, 1.0, 0.5125, 0.625, -1.0, 1.0, 1.0, 0.025, 0.03125, 1.0, 1.0, 0.0, 0.0, 1.0, -1.0, 1.0, 1.0, 1.0, 1.0, 0.3125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, -0.94375, 1.0, 0.0, 0.0], [1.0, 0.0, 1.0, 0.54902, 0.62745, 1.0, 0.01961, 1.0, -0.4902, 0.92157, -0.82353, 0.58824, -1.0, 0.11765, -0.96078, -0.33333, -0.64706, -0.68627, -0.23529, -0.86275, 0.35294, -1.0, 0.7451, -0.72549, 0.92157, -0.21569, 0.92874, 0.21876, 0.72549, 0.56863, 0.23529, 0.90196, -0.11765, 0.90196], [1.0, 0.0, 0.0, 0.0, -1.0, -1.0, -1.0, 1.0, 0.0, 0.0, -1.0, 1.0, 1.0, 1.0, 1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -1.0, 1.0, 1.0, 0.4375, 1.0, -1.0, 0.0, 0.0, -1.0, -1.0, -1.0, 1.0], [1.0, 0.0, 0.44444, 0.44444, 0.53695, 0.90763, -0.22222, 1.0, -0.33333, 0.88889, -1.0, 0.33333, -1.0, -0.11111, -1.0, -0.22222, -0.66667, -0.77778, 0.55556, -1.0, -0.22222, -0.77778, 0.77778, -0.22222, 0.33333, 0.0, 0.9212, 0.45019, 0.57454, 0.84353, 0.22222, 1.0, -0.55556, 1.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.5, 0.5, 0.75, 0.0, 0.91201, 0.12094, 0.89067, 0.1421, 0.86922, 0.16228, 0.75, 0.25, 0.75, 0.5, 0.75, 0.0, 1.0, -0.25, 0.5, 0.5, 0.73944, 0.26388, 0.75, 0.25, 0.69635, 0.29074, 0.67493, 0.30293], [0.0, 0.0, -1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, -1.0, 1.0, -1.0, 1.0, -1.0, -1.0, -1.0, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, 1.0, -1.0, 1.0, 1.0, -1.0, -1.0, 0.0, 0.0], [1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.66667, 0.11111, 1.0, -0.11111, 0.88889, -0.11111, 1.0, -0.22222, 0.77778, 0.0, 0.77778, 0.0, 1.0, -0.11111, 0.77778, -0.11111, 0.66667, -0.11111, 0.66667, 0.0, 0.90347, -0.05352, 1.0, 0.11111, 0.88889, -0.11111, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, 1.0, 0.75, 0.0, 0.0, 0.0, 0.0, -1.0, 1.0, 0.0, 0.0, 1.0, -1.0, -1.0, -1.0, 1.0, 1.0, 0.0, 0.0], [1.0, 0.0, 1.0, 0.45455, 1.0, -0.45455, 1.0, 0.09091, 1.0, -0.09091, 1.0, 0.0, 1.0, -0.27273, 1.0, -0.18182, 1.0, 0.09091, 1.0, 0.0, 1.0, -0.36364, 1.0, 0.09091, 1.0, -0.09091, 1.0, -0.04914, 1.0, 0.45455, 1.0, -0.27273, 1.0, -0.18182], [1.0, 0.0, 0.62121, -0.63636, 0.0, 0.0, 0.0, 0.0, 0.3447, 0.28788, 0.42803, 0.39394, -0.07576, 0.51894, 0.36364, 0.31439, -0.53788, 0.32955, 0.12121, -0.14773, 0.01894, -0.53409, -0.57576, 0.17803, 0.29167, -0.27273, 0.25758, -0.57576, 0.43182, 0.24242, 0.18182, -0.02273, 0.17045, -0.41667], [1.0, 0.0, 1.0, 0.11765, 1.0, 0.23529, 1.0, 0.41176, 1.0, 0.05882, 1.0, 0.23529, 1.0, 0.11765, 1.0, 0.47059, 1.0, -0.05882, 1.0, -0.11765, 1.0, 0.35294, 1.0, 0.41176, 1.0, -0.11765, 1.0, 0.20225, 1.0, 0.05882, 1.0, 0.35294, 1.0, 0.23529], [1.0, 0.0, 0.0, 0.0, -1.0, -0.62766, 1.0, 0.51064, 0.07979, -0.23404, -1.0, -0.3617, 0.12766, -0.59043, 1.0, -1.0, 0.0, 0.0, 0.82979, -0.07979, -0.25, 1.0, 0.17021, -0.70745, 0.0, 0.0, -0.19149, -0.46809, -0.2234, -0.48936, 0.74468, 0.90426, -0.67553, 0.45745], [1.0, 0.0, 0.91667, 0.29167, 0.83333, -0.16667, 0.70833, 0.25, 0.875, -0.08333, 0.91667, 0.04167, 0.83333, 0.125, 0.70833, 0.0, 0.875, 0.04167, 1.0, 0.08333, 0.66667, -0.08333, 0.75, 0.16667, 0.83333, -0.125, 0.83796, 0.05503, 1.0, 0.20833, 0.70833, 0.0, 0.70833, 0.04167], [1.0, 0.0, 0.1859, -0.16667, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11538, -0.19071, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.05128, -0.06571, 0.07853, 0.08974, 0.17308, -0.10897, 0.125, 0.09615, 0.02564, -0.04808, 0.16827, 0.19551], [1.0, 0.0, 1.0, -0.08183, 1.0, -0.11326, 0.99246, -0.29802, 1.0, -0.33075, 0.96662, -0.34281, 0.85788, -0.47265, 0.91904, -0.4817, 0.73084, -0.65224, 0.68131, -0.63544, 0.8245, -0.78316, 0.58829, -0.74785, 0.67033, -0.96296, 0.48757, -0.85669, 0.37941, -0.83893, 0.24117, -0.88846, 0.29221, -0.89621], [1.0, 0.0, 1.0, 1.0, -1.0, 1.0, -1.0, -0.82456, 0.34649, 0.21053, 0.46053, 0.07018, 0.22807, 0.05702, 0.35088, 0.34649, 0.72807, -0.03947, 0.22807, 0.5307, 0.0, 0.0, -0.29825, -0.16228, 1.0, -0.66667, 1.0, -1.0, 1.0, -0.24561, 0.35088, 0.20175, 0.82895, 0.07895], [1.0, 0.0, 1.0, 0.24077, 0.99815, 0.00369, 0.80244, -0.30133, 0.89919, -0.23486, 0.70643, -0.24077, 0.73855, -0.30539, 0.71492, -0.36078, 0.47194, -0.61189, 0.40473, -0.55059, 0.61041, -0.39328, 0.53176, -0.32681, 0.23966, -0.52142, 0.29208, -0.4839, 0.12777, -0.39143, 0.15657, -0.51329, 0.18353, -0.46603], [0.0, 0.0, -1.0, 1.0, 1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 1.0, -1.0, 1.0, 1.0, 0.0, 0.0, 1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, -1.0, 1.0, 1.0, -1.0, -1.0, 1.0, -1.0, -1.0, 0.0, 0.0], [1.0, 0.0, 0.92247, -0.19448, 0.96419, -0.17674, 0.87024, -0.22602, 0.81702, -0.2707, 0.79271, -0.28909, 0.70302, -0.49639, 0.63338, -0.49967, 0.37254, -0.70729, 0.2707, -0.72109, 0.40506, -0.54172, 0.33509, -0.59691, 0.1475, -0.63601, 0.09312, -0.59589, -0.07162, -0.54928, -0.0184, -0.54074, -0.07457, -0.47898], [1.0, 0.0, -1.0, -1.0, -0.50694, 1.0, 1.0, -1.0, 1.0, 0.53819, 0.0, 0.0, 0.23958, -1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, -0.71528, 1.0, 0.33333, -1.0, 1.0, -1.0, 0.69792, -1.0, 0.47569, 1.0], [1.0, 0.0, 0.84177, 0.4346, 0.5, 0.7616, 0.09916, 0.9346, -0.37764, 0.88186, -0.72363, 0.61181, -0.93882, 0.19409, -0.86709, -0.25527, -0.62869, -0.65612, -0.25105, -0.85654, 0.16245, -0.86498, 0.51477, -0.66878, 0.74895, -0.28903, 0.77937, 0.07933, 0.64135, 0.42827, 0.31435, 0.62447, -0.00422, 0.69409], [1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, -1.0, -1.0, -1.0, 1.0, 1.0, 1.0, -1.0, 0.0, 0.0, 1.0, -1.0, 1.0, 1.0, 0.0, 0.0, 1.0, -1.0, -1.0, -1.0, 1.0, 1.0, -1.0, 1.0, -1.0, 1.0, 0.0, 0.0], [1.0, 0.0, 1.0, 0.63548, 1.0, 1.0, 0.77123, 1.0, -0.33333, 1.0, -1.0, 1.0, 0.0, 1.0, -1.0, 1.0, -1.0, 0.0, -1.0, -0.66667, -1.0, -0.92536, -1.0, -0.33333, -0.33333, -1.0, 0.19235, -1.0, 1.0, -1.0, 0.0, -1.0, 1.0, -0.66667], [0.0, 0.0, -1.0, 1.0, -1.0, -1.0, 0.0, 0.0, -1.0, 1.0, 1.0, -1.0, -1.0, -1.0, -1.0, 1.0, 0.0, 0.0, -1.0, -1.0, -1.0, 1.0, 0.0, 0.0, 1.0, -1.0, 1.0, 1.0, 1.0, -1.0, 1.0, 1.0, 0.0, 0.0], [1.0, 0.0, 1.0, 0.06843, 1.0, 0.14211, 1.0, 0.22108, 1.0, -0.125, 1.0, 0.39495, 1.0, 0.48981, 1.0, 0.58986, -0.375, 1.0, 1.0, 0.0, 1.0, 0.92001, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.25, 1.0, 1.0, 1.0, 1.0], [0.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, -1.0, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, 1.0, 1.0, 1.0, -1.0, 1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.64947, -0.07896, 0.58264, -0.1438, -0.13129, -0.21384, 0.29796, 0.04403, 0.38096, -0.26339, 0.28931, -0.31997, 0.03459, -0.18947, 0.20269, -0.29441, 0.15196, -0.29052, 0.09513, -0.31525, 0.06556, -0.26795, 0.03004, -0.25124, -0.00046, -0.2321, -0.02612, -0.21129, -0.04717, -0.1895, 0.01336, -0.27201], [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, -0.33333, 0.16667, 0.26042, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.19792, -0.21875, -0.16667, 0.90625, -1.0, 0.5, 0.04167, 0.75, -0.22917, -1.0, -0.125, -0.27083, -0.19792, -0.9375], [1.0, 0.0, 1.0, 0.05149, 0.99363, 0.10123, 0.96142, 0.14756, 0.95513, -0.26496, 0.66026, 0.54701, 0.80426, 0.25283, 0.73781, 0.2738, 0.66775, 0.28714, 0.59615, 0.29304, 0.52494, 0.292, 0.45582, 0.28476, 0.39023, 0.27226, 0.3293, 0.25553, 0.27381, 0.23568, 0.22427, 0.21378, 0.18086, 0.19083], [1.0, 0.0, 1.0, -0.09524, -1.0, -1.0, -1.0, -1.0, 1.0, 0.31746, 0.81349, 0.7619, -1.0, -1.0, -1.0, 1.0, 0.47364, 1.0, 1.0, 1.0, 0.68839, -1.0, -1.0, -1.0, 0.82937, 0.36508, 1.0, 1.0, 1.0, 0.50794, -1.0, -0.3254, -1.0, 0.72831], [1.0, 0.0, 0.93669, -0.0019, 0.60761, 0.43204, 0.92314, -0.40129, 0.93123, 0.16828, 0.96197, 0.09061, 0.99676, 0.08172, 0.91586, 0.05097, 0.84628, -0.25324, 0.87379, -0.14482, 0.84871, 0.26133, 0.75081, -0.03641, 0.84547, -0.02589, 0.87293, -0.02302, 0.98544, 0.09385, 0.78317, -0.10194, 0.85841, -0.14725], [1.0, 0.0, 1.0, -1.0, 1.0, 1.0, 1.0, 1.0, 1.0, -0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, -1.0, 1.0, 1.0, 1.0, 0.625, 1.0, -0.75, -0.75, 1.0, 1.0, 1.0], [1.0, 0.0, 1.0, 0.23058, 1.0, -0.78509, 1.0, -0.10401, 1.0, 0.15414, 1.0, 0.2782, 0.9812, -0.06861, 1.0, 0.0661, 0.95802, -0.18954, 0.83584, -0.15633, 0.974, 0.03728, 0.99624, 0.09242, 1.0, -0.01253, 0.96238, -0.04597, 0.91165, 0.03885, 1.0, -0.13722, 0.96523, -0.11717], [1.0, 0.0, 0.36876, -1.0, -1.0, -1.0, -0.07661, 1.0, 1.0, 0.95041, 0.74597, -0.3871, -1.0, -0.79313, -0.09677, 1.0, 0.48684, 0.46502, 0.31755, -0.27461, -0.14343, -0.20188, -0.11976, 0.06895, 0.03021, 0.06639, 0.03443, -0.01186, -0.00403, -0.01672, -0.00761, 0.00108, 0.00015, 0.00325], [1.0, 0.0, 0.79847, 0.38265, 0.80804, -0.16964, 1.0, -0.07653, 0.98151, -0.07398, 0.70217, 0.20663, 0.99745, 0.02105, 0.98214, 0.02487, 1.0, -0.13074, 0.95663, 0.07717, 1.0, 0.00191, 0.90306, 0.30804, 1.0, -0.14541, 1.0, -0.00394, 0.75638, 0.07908, 1.0, -0.1875, 1.0, -0.0574], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, -1.0, 0.0, 0.0, 1.0, 1.0, 1.0, -1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, -1.0, 0.0, 0.0], [1.0, 0.0, 1.0, -0.28428, 1.0, -0.25346, 0.94623, -0.35094, 1.0, -0.30566, 0.92736, -0.49057, 0.90818, -0.44119, 0.75723, -0.58899, 0.69748, -0.58019, 0.59623, -0.57579, 0.68459, -0.70975, 0.54465, -0.87327, 0.49214, -0.73333, 0.35504, -0.76054, 0.26352, -0.78239, 0.16604, -0.73145, 0.13994, -0.7], [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.85, -1.0, 0.0, 0.0, 1.0, -1.0, 0.0, 0.0, -1.0, -1.0, -1.0, -1.0, 1.0, -1.0, -0.6, -1.0, 1.0, 1.0, -1.0, -0.2, 1.0, -1.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 1.0, 0.09091, 0.95455, -0.09091, 0.77273, 0.0, 1.0, 0.0, 0.95455, 0.0, 1.0, 0.04545, 0.90909, -0.04545, 1.0, 0.0, 1.0, 0.0, 0.86364, 0.09091, 0.77273, 0.09091, 0.90909, 0.04545, 0.91541, 0.02897, 0.95455, 0.09091, 0.86364, -0.09091, 0.86364, 0.04545], [0.0, 0.0, 0.0, 0.0, -1.0, 1.0, 1.0, 1.0, -1.0, -1.0, 0.0, 0.0, -1.0, -1.0, -1.0, -0.3125, -1.0, -1.0, 1.0, -1.0, 1.0, -1.0, 0.0, 0.0, 1.0, -1.0, -1.0, -1.0, 0.0, 0.0, 1.0, -1.0, 0.0, 0.0], [1.0, 0.0, 0.91176, -0.08824, 0.97059, 0.17647, 0.82353, 0.08824, 0.91176, -0.02941, 0.97059, -0.17647, 0.97059, 0.14706, 0.94118, 0.02941, 1.0, 0.0, 1.0, 0.0, 0.76471, 0.11765, 0.88235, 0.02941, 0.85294, 0.02941, 0.92663, 0.026, 0.94118, -0.11765, 0.97059, 0.05882, 0.91176, 0.05882], [1.0, 0.0, -1.0, 1.0, -1.0, 0.15244, 0.28354, 1.0, -1.0, 1.0, -1.0, -1.0, 1.0, 1.0, -1.0, -0.23476, 0.28301, -1.0, 1.0, 1.0, -0.31402, -1.0, -1.0, -1.0, 1.0, -1.0, -1.0, -0.03578, 1.0, -1.0, -1.0, -0.32317, 0.14939, 1.0], [1.0, 0.0, 0.47368, -0.10526, 0.83781, 0.01756, 0.83155, 0.02615, 0.68421, -0.05263, 0.68421, 0.0, 0.79856, 0.05028, 0.78315, 0.05756, 0.84211, 0.47368, 1.0, 0.05263, 0.7255, 0.07631, 0.70301, 0.08141, 0.42105, 0.21053, 0.65419, 0.08968, 0.52632, -0.21053, 0.6015, 0.09534, 0.57418, 0.09719], [1.0, 0.0, -0.00641, -0.5, 0.0, 0.0, -0.01923, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3141, 0.92949, -0.35256, 0.74359, -0.34615, -0.80769, 0.0, 0.0, -0.61538, -0.51282, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 1.0, 0.45455, 1.0, 0.54545, 0.81818, 0.63636, 1.0, -0.09091, 1.0, 0.0, 0.81818, -0.45455, 0.63636, 0.27273, 1.0, -0.63636, 1.0, -0.27273, 0.90909, -0.45455, 1.0, 0.0775, 1.0, -0.09091, 1.0, 0.08867, 1.0, 0.36364, 1.0, 0.63636, 0.72727, 0.27273], [0.0, 0.0, -1.0, -1.0, 1.0, -1.0, -1.0, 1.0, 0.0, 0.0, 1.0, -1.0, 1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -1.0, 1.0, 1.0, -1.0, -1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.5, 0.0, 0.0], [1.0, 0.0, 0.45455, 0.09091, 0.63636, 0.09091, 0.27273, 0.18182, 0.63636, 0.0, 0.36364, -0.09091, 0.45455, -0.09091, 0.48612, -0.01343, 0.63636, -0.18182, 0.45455, 0.0, 0.36364, -0.09091, 0.27273, 0.18182, 0.36364, -0.09091, 0.34442, -0.01768, 0.27273, 0.0, 0.36364, 0.0, 0.28985, -0.01832], [1.0, 0.0, -1.0, -0.59677, 0.0, 0.0, -1.0, 0.64516, -0.87097, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.29839, 0.23387, 1.0, 0.51613, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 1.0, 0.14286, 1.0, 0.71429, 1.0, 0.71429, 1.0, -0.14286, 0.85714, -0.14286, 1.0, 0.02534, 1.0, 0.0, 0.42857, -0.14286, 1.0, 0.03617, 1.0, -0.28571, 1.0, 0.0, 0.28571, -0.28571, 1.0, 0.04891, 1.0, 0.05182, 1.0, 0.57143, 1.0, 0.0], [0.0, 0.0, 1.0, 1.0, 1.0, -1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, -1.0, 1.0, 1.0, 1.0, -1.0, 1.0, -1.0, 1.0, 1.0, 1.0, 1.0, 1.0, -1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], [1.0, 0.0, 0.87032, 0.46972, 0.53945, 0.82161, 0.1038, 0.95275, -0.38033, 0.87916, -0.73939, 0.58226, -0.92099, 0.16731, -0.82417, -0.24942, -0.59383, -0.63342, -0.24012, -0.82881, 0.18823, -0.78699, 0.51557, -0.5743, 0.69274, -0.24843, 0.69097, 0.10484, 0.52798, 0.39762, 0.25974, 0.56573, -0.06739, 0.57552], [0.0, 0.0, 1.0, -1.0, 1.0, 1.0, 1.0, -1.0, 1.0, 1.0, 1.0, -1.0, 1.0, -1.0, 1.0, -1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, -1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, -1.0], [1.0, 0.0, 0.92657, 0.04174, 0.89266, 0.15766, 0.86098, 0.19791, 0.83675, 0.36526, 0.80619, 0.40198, 0.76221, 0.40552, 0.66586, 0.4836, 0.60101, 0.51752, 0.53392, 0.5218, 0.48435, 0.54212, 0.42546, 0.55684, 0.3334, 0.55274, 0.26978, 0.54214, 0.22307, 0.53448, 0.14312, 0.49124, 0.11573, 0.46571], [0.0, 0.0, 1.0, 1.0, 1.0, -1.0, 1.0, -1.0, 1.0, 1.0, 0.0, 0.0, 1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0], [1.0, 0.0, 0.93537, 0.13645, 0.93716, 0.25359, 0.85705, 0.38779, 0.79039, 0.47127, 0.72352, 0.59942, 0.6526, 0.75, 0.5083, 0.73586, 0.41629, 0.82742, 0.25539, 0.85952, 0.13712, 0.85615, 0.00494, 0.88869, -0.07361, 0.7978, -0.20995, 0.78004, -0.33169, 0.71454, -0.38532, 0.64363, -0.47419, 0.55835], [0.0, 0.0, 1.0, -1.0, -1.0, 1.0, -1.0, 1.0, 1.0, 1.0, 1.0, 1.0, -1.0, -1.0, -1.0, -1.0, 1.0, 1.0, 1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 1.0, 0.0, 1.0, -1.0, 1.0, -1.0, -1.0, 1.0, -1.0, 1.0], [1.0, 0.0, 0.80627, 0.13069, 0.73061, 0.24323, 0.64615, 0.19038, 0.36923, 0.45577, 0.44793, 0.46439, 0.25, 0.57308, 0.25192, 0.37115, 0.15215, 0.51877, -0.09808, 0.575, -0.03462, 0.42885, -0.08856, 0.44424, -0.14943, 0.40006, -0.1994, 0.34976, -0.23832, 0.29541, -0.26634, 0.23896, -0.23846, 0.31154], [0.0, 0.0, 1.0, -1.0, 1.0, 1.0, 1.0, -1.0, 1.0, 1.0, 1.0, -1.0, 1.0, 1.0, 1.0, -1.0, 1.0, -1.0, 1.0, 1.0, 1.0, 1.0, 1.0, -1.0, 1.0, -1.0, 1.0, -1.0, 1.0, 1.0, 1.0, -1.0, 1.0, 1.0], [1.0, 0.0, 0.97467, 0.13082, 0.9412, 0.20036, 0.88783, 0.32248, 0.89009, 0.32711, 0.8555, 0.45217, 0.72298, 0.52284, 0.69946, 0.5882, 0.58548, 0.66893, 0.48869, 0.70398, 0.44245, 0.68159, 0.35289, 0.75622, 0.26832, 0.7621, 0.16813, 0.78541, 0.07497, 0.80439, -0.02962, 0.77702, -0.10289, 0.74242], [0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, -1.0, 0.0, 0.0, -1.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.92308, 0.15451, 0.86399, 0.29757, 0.72582, 0.3679, 0.70588, 0.5683, 0.57449, 0.62719, 0.4327, 0.74676, 0.31705, 0.67697, 0.19128, 0.76818, 0.04686, 0.76171, -0.12064, 0.76969, -0.18479, 0.71327, -0.29291, 0.65708, -0.38798, 0.58553, -0.46799, 0.50131, -0.53146, 0.40732, -0.56231, 0.35095], [0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, -1.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.88804, 0.38138, 0.65926, 0.69431, 0.29148, 0.87892, -0.06726, 0.90135, -0.39597, 0.80441, -0.64574, 0.56502, -0.8296, 0.26906, -0.7894, -0.08205, -0.6278, -0.30942, -0.46637, -0.55605, -0.16449, -0.64338, 0.09562, -0.61055, 0.30406, -0.48392, 0.43227, -0.29838, 0.47029, -0.09461, 0.42152, 0.12556], [0.0, 0.0, 1.0, -1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, -1.0, 1.0, 1.0, 1.0, 1.0, 1.0, -1.0, 1.0, -1.0, 1.0, -1.0, 1.0, -1.0, 1.0, 1.0, 1.0, -1.0, 1.0, 1.0, 1.0, 1.0], [1.0, 0.0, 0.73523, -0.38293, 0.80151, 0.10278, 0.78826, 0.15266, 0.5558, 0.05252, 1.0, 0.21225, 0.71947, 0.28954, 0.68798, 0.32925, 0.49672, 0.17287, 0.64333, -0.02845, 0.57399, 0.42528, 0.5312, 0.44872, 0.9453, 0.57549, 0.44174, 0.482, 0.12473, 1.0, 0.3507, 0.49721, 0.30588, 0.49831], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.94649, 0.00892, 0.97287, -0.0026, 0.98922, 0.00372, 0.95801, 0.01598, 0.94054, 0.0353, 0.97213, 0.04719, 0.98625, 0.01858, 0.94277, 0.07135, 0.98551, -0.00706, 0.9777, 0.0498, 0.96358, 0.07098, 0.93274, 0.08101, 0.95243, 0.04356, 0.97473, 0.00818, 0.97845, 0.07061, 1.0, -0.0026], [0.0, 0.0, 1.0, 1.0, -1.0, -1.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, -1.0, 0.0, 0.0, -1.0, -1.0, -1.0, -1.0], [1.0, 0.0, 0.50466, -0.169, 0.71442, 0.01513, 0.71063, 0.02258, 0.68065, 0.01282, 0.34615, 0.05594, 0.6905, 0.04393, 0.68101, 0.05058, 0.67023, 0.05692, 0.63403, -0.04662, 0.64503, 0.06856, 0.63077, 0.07381, 0.84033, 0.18065, 0.59935, 0.08304, 0.38228, 0.0676, 0.56466, 0.09046, 0.54632, 0.09346], [1.0, 0.0, 0.68729, 1.0, 0.91973, -0.76087, 0.81773, 0.04348, 0.76087, 0.10702, 0.86789, 0.73746, 0.70067, 0.18227, 0.7592, 0.13712, 0.93478, -0.25084, 0.70736, 0.18729, 0.64883, 0.24582, 0.60201, 0.77425, 1.0, -0.53846, 0.89262, 0.22216, 0.7107, 0.53846, 1.0, -0.06522, 0.56522, 0.23913], [1.0, 0.0, 0.76296, -0.07778, 1.0, -0.2963, 1.0, -0.85741, 0.8, 0.06111, 0.45556, -0.42778, 1.0, -0.12581, 1.0, -0.83519, 0.49259, 0.01852, 0.82222, -0.05926, 0.98215, -0.19938, 1.0, 0.22037, 0.6963, -0.26481, 0.92148, -0.24549, 0.78889, 0.02037, 0.87492, -0.27105, 1.0, -0.57037], [1.0, 0.0, 0.38521, 0.15564, 0.41245, 0.07393, 0.26459, 0.24125, 0.23346, 0.1323, 0.19455, 0.25292, 0.24514, 0.36965, 0.08949, 0.22957, -0.03891, 0.36965, 0.05058, 0.24903, 0.24903, 0.09728, 0.07782, 0.29961, -0.02494, 0.28482, -0.06024, 0.26256, -0.14786, 0.14786, -0.09339, 0.31128, -0.19066, 0.28794], [1.0, 0.0, 0.5754, -0.03175, 0.75198, -0.05357, 0.61508, -0.0119, 0.53968, 0.03373, 0.61706, 0.09921, 0.59127, -0.02381, 0.62698, 0.0119, 0.70833, 0.02579, 0.60317, 0.01587, 0.47817, -0.02778, 0.59127, 0.0377, 0.5, 0.03968, 0.61291, -0.01237, 0.61706, -0.13492, 0.68849, -0.01389, 0.625, -0.03175], [1.0, 0.0, 0.06404, -0.15271, -0.04433, 0.05911, 0.08374, -0.02463, -0.01478, 0.18719, 0.06404, 0.0, 0.12315, -0.09852, 0.05911, 0.0, 0.0197, -0.02956, -0.12808, -0.2069, 0.06897, 0.01478, 0.06897, 0.02956, 0.07882, 0.16256, 0.28079, -0.04926, -0.05911, -0.0936, 0.04433, 0.05419, 0.07389, -0.10837], [1.0, 0.0, 0.61857, 0.1085, 0.70694, -0.06935, 0.70358, 0.01678, 0.74273, 0.00224, 0.71029, 0.15772, 0.71588, -0.00224, 0.79754, 0.066, 0.83669, -0.16555, 0.6868, -0.0906, 0.62528, -0.01342, 0.60962, 0.11745, 0.71253, -0.09508, 0.69845, -0.01673, 0.63311, 0.0481, 0.78859, -0.05145, 0.65213, -0.04698], [1.0, 0.0, 0.25316, 0.35949, 0.0, 0.0, -0.2962, -1.0, 0.0, 0.0, 0.07595, -0.07342, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00759, 0.68101, -0.2, 0.33671, -0.1038, 0.35696, 0.0557, -1.0, 0.0, 0.0, 0.06329, -1.0, 0.0, 0.0], [1.0, 0.0, 0.88103, -0.00857, 0.89818, -0.02465, 0.94105, -0.01822, 0.89175, -0.12755, 0.82208, -0.10932, 0.88853, 0.01179, 0.90782, -0.13719, 0.87138, -0.06109, 0.90782, -0.02358, 0.87996, -0.14577, 0.82851, -0.12433, 0.90139, -0.19507, 0.88245, -0.14903, 0.84352, -0.12862, 0.88424, -0.18542, 0.91747, -0.16827], [1.0, 0.0, 0.42708, -0.5, 0.0, 0.0, 0.0, 0.0, 0.46458, 0.51042, 0.58958, 0.02083, 0.0, 0.0, 0.0, 0.0, 0.16458, -0.45417, 0.59167, -0.18333, 0.0, 0.0, 0.0, 0.0, 0.9875, -0.40833, -1.0, -1.0, -0.27917, -0.75625, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.88853, 0.01631, 0.92007, 0.01305, 0.92442, 0.01359, 0.89179, -0.10223, 0.90103, -0.08428, 0.9304, -0.01033, 0.93094, -0.08918, 0.86025, -0.05057, 0.89451, -0.04024, 0.88418, -0.12126, 0.88907, -0.11909, 0.8298, -0.14138, 0.86453, -0.11808, 0.85536, -0.13051, 0.83524, -0.12452, 0.86786, -0.12235], [1.0, 0.0, 0.0, 0.0, 1.0, 0.12889, 0.88444, -0.02, 0.0, 0.0, 1.0, -0.42444, 1.0, 0.19556, 1.0, -0.05333, 1.0, -0.81556, 0.0, 0.0, 1.0, -0.04, 1.0, -0.18667, 0.0, 0.0, 1.0, -1.0, 0.0, 0.0, 1.0, 0.11778, 0.90667, -0.09556], [1.0, 0.0, 0.81143, 0.03714, 0.85143, -0.00143, 0.79, 0.00714, 0.79571, -0.04286, 0.87571, 0.0, 0.85571, -0.06714, 0.86429, 0.00286, 0.82857, -0.05429, 0.81, -0.11857, 0.76857, -0.08429, 0.84286, -0.05, 0.77, -0.06857, 0.81598, -0.08669, 0.82571, -0.10429, 0.81429, -0.05, 0.82143, -0.15143], [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -1.0, 1.0, 1.0, 0.55172, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.4987, 0.01818, 0.43117, -0.0961, 0.50649, -0.04156, 0.5013, 0.0961, 0.44675, 0.05974, 0.55844, -0.11948, 0.51688, -0.03636, 0.52727, -0.05974, 0.55325, -0.01039, 0.48571, -0.03377, 0.49091, -0.01039, 0.59221, 0.0, 0.53215, -0.0328, 0.43117, 0.03377, 0.54545, -0.05455, 0.58961, -0.08571], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 1.0, 0.5, 1.0, 0.25, 0.25, 1.0, 0.16851, 0.9118, -0.13336, 0.80454, -0.34107, 0.60793, -0.4382, 0.37856, -0.43663, 0.16709, -0.36676, 0.00678, -0.26477, -0.09025, -0.16178, -0.12964, -0.07782, -0.12744, -0.02089, -0.10242, 0.01033, -0.07036, 0.02224, -0.04142, 0.02249, -0.02017], [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, -1.0, -1.0, 0.0, 0.0, 1.0, -0.11111, 0.0, 0.0, 0.0, 0.0, -1.0, 1.0, 1.0, 1.0, 1.0, -1.0, 0.0, 0.0, 1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0], [1.0, 0.0, 0.87048, 0.38027, 0.64099, 0.69212, 0.31347, 0.86625, -0.03933, 0.9074, -0.42173, 0.79346, -0.70561, 0.5156, -0.81049, 0.22735, -0.81136, -0.12539, -0.67474, -0.38102, -0.38334, -0.62861, -0.13013, -0.70762, 0.15552, -0.66421, 0.38544, -0.51568, 0.52573, -0.29897, 0.56239, -0.05938, 0.5146, 0.16645], [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -1.0, 1.0, 0.0, 0.0, 1.0, 0.37333, -0.12, -0.12, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, 1.0, -1.0, 0.0, 0.0, 1.0, 0.22667, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.88179, 0.43491, 0.59573, 0.77655, 0.19672, 0.94537, -0.24103, 0.92544, -0.62526, 0.71257, -0.86443, 0.33652, -0.92384, -0.05338, -0.77356, -0.44707, -0.4695, -0.73285, -0.10237, -0.82217, 0.26384, -0.7757, 0.55984, -0.5591, 0.72147, -0.24433, 0.72478, 0.09599, 0.58137, 0.38915, 0.34749, 0.57656], [1.0, 0.0, 0.32834, 0.0252, 0.15236, 0.21278, 0.14919, 0.74003, -0.25706, 0.92324, -0.10312, 0.1938, -0.61352, 0.25786, -0.94053, -0.05409, -0.13117, -0.14329, -0.30315, -0.44615, -0.11409, -0.85597, 0.02668, -0.22786, 0.27942, -0.06295, 0.33737, -0.11876, 0.27657, -0.11409, 0.15078, 0.13296, 0.12197, 0.20468], [1.0, 0.0, 0.83427, 0.39121, 0.5404, 0.78579, 0.12326, 0.89402, -0.33221, 0.83578, -0.70086, 0.59564, -0.86622, 0.21909, -0.84442, -0.24164, -0.59714, -0.61894, -0.19354, -0.87787, 0.12439, -0.89064, 0.51109, -0.72454, 0.79143, -0.27734, 0.83008, 0.08718, 0.66592, 0.49079, 0.37542, 0.70011, -0.03983, 0.79444], [1.0, 0.0, 0.62335, -0.0349, 0.59085, 0.00481, 0.60409, -0.07461, 0.63177, 0.00963, 0.62455, -0.07461, 0.67028, 0.0722, 0.62936, -0.08424, 0.67509, 0.09146, 0.67148, 0.0, 0.58965, 0.10108, 0.5006, 0.03129, 0.65945, 0.14079, 0.60463, 0.02019, 0.51384, 0.04452, 0.61733, -0.00963, 0.61372, -0.09146], [1.0, 0.0, 0.74449, -0.0239, 0.70772, 0.03309, 0.72243, 0.16912, 0.79228, 0.07721, 0.81434, 0.43934, 0.63787, 0.00551, 0.70772, 0.21691, 1.0, 0.06066, 0.61029, 0.05147, 0.67463, 0.04228, 0.52022, -0.25, 0.72978, -0.15809, 0.61727, 0.07124, 0.30882, 0.0864, 0.55916, 0.07458, 0.60294, 0.21691], [1.0, 0.0, 0.61538, 0.18923, 0.78157, 0.0178, 0.77486, 0.02647, 0.65077, -0.10308, 0.77538, 0.08, 0.73961, 0.0506, 0.72322, 0.05776, 0.68615, -0.08923, 0.61692, 0.16308, 0.66233, 0.07573, 0.63878, 0.08041, 0.60154, -0.07231, 0.58803, 0.08767, 0.55077, 0.25692, 0.53389, 0.09207, 0.50609, 0.09322], [1.0, 0.0, 0.68317, 0.05375, 0.84803, 0.00202, 0.84341, 0.00301, 0.843, 0.09901, 0.75813, 0.04102, 0.81892, 0.00585, 0.80738, 0.00673, 0.80622, -0.12447, 0.77935, -0.03536, 0.76365, 0.00909, 0.74635, 0.00978, 0.79632, -0.04243, 0.70824, 0.01096, 0.62235, 0.11598, 0.66624, 0.0119, 0.64407, 0.01227], [1.0, 0.0, 0.5, 0.0, 0.38696, 0.10435, 0.4913, 0.06522, 0.46957, -0.03913, 0.35652, -0.12609, 0.45652, 0.04783, 0.50435, 0.02609, 0.35652, 0.19565, 0.42174, 0.14783, 0.42174, -0.02609, 0.32174, -0.11304, 0.47391, -0.0087, 0.41789, 0.06908, 0.38696, 0.03913, 0.35217, 0.14783, 0.44783, 0.17391], [1.0, 0.0, 0.7983, 0.09417, 0.78129, 0.20656, 0.71628, 0.28068, 0.6932, 0.41252, 0.65917, 0.50122, 0.57898, 0.60814, 0.4921, 0.58445, 0.33354, 0.67861, 0.29587, 0.63548, 0.09599, 0.68104, 0.02066, 0.72236, -0.08748, 0.63183, -0.11925, 0.60696, -0.18226, 0.56015, -0.25516, 0.51701, -0.27339, 0.42467], [1.0, 0.0, 1.0, 0.09802, 1.0, 0.25101, 0.9839, 0.33044, 0.80365, 0.5302, 0.74977, 0.60297, 0.56937, 0.71942, 0.55311, 0.74079, 0.29452, 0.82193, 0.21137, 0.79777, 0.09709, 0.82162, -0.01734, 0.7987, -0.15144, 0.75596, -0.22839, 0.69187, -0.31713, 0.60948, -0.40291, 0.54522, -0.42815, 0.44534], [1.0, 0.0, 0.8941, 0.13425, 0.87001, 0.31543, 0.78896, 0.43388, 0.63388, 0.59975, 0.54003, 0.71016, 0.39699, 0.76161, 0.24266, 0.79523, 0.09134, 0.79598, -0.09159, 0.76261, -0.20201, 0.66926, -0.30263, 0.6261, -0.40552, 0.50489, -0.46215, 0.40753, -0.50314, 0.27252, -0.52823, 0.19172, -0.48808, 0.05972], [1.0, 0.0, 0.94631, 0.17498, 0.90946, 0.33143, 0.85096, 0.4996, 0.73678, 0.63842, 0.59215, 0.73838, 0.48698, 0.83614, 0.30459, 0.90665, 0.17959, 0.93429, -0.00701, 0.93109, -0.1888, 0.89383, -0.33023, 0.82492, -0.46534, 0.76482, -0.58563, 0.66335, -0.67929, 0.52564, -0.75321, 0.42488, -0.8121, 0.26092], [1.0, 0.0, 0.91767, 0.18198, 0.8609, 0.35543, 0.72873, 0.45747, 0.60425, 0.69865, 0.50376, 0.74922, 0.361, 0.81795, 0.15664, 0.83558, 0.00396, 0.8521, -0.1639, 0.77853, -0.35996, 0.76193, -0.43087, 0.65385, -0.5314, 0.53886, -0.60328, 0.40972, -0.64511, 0.27338, -0.6571, 0.13667, -0.64056, 0.05394], [1.0, 0.0, 0.76627, 0.21106, 0.63935, 0.38112, 0.48409, 0.525, 0.15, 0.22273, 0.13753, 0.59565, -0.07727, 0.44545, 0.0, 0.48636, -0.27491, 0.42014, -0.56136, 0.36818, -0.36591, 0.18864, -0.40533, 0.07588, -0.38483, -0.03229, -0.33942, -0.12486, -0.2754, -0.19714, -0.19962, -0.24648, -0.11894, -0.27218], [1.0, 0.0, 0.5894, -0.60927, 0.8543, 0.55298, 0.81126, 0.07285, 0.56623, 0.16225, 0.32781, 0.24172, 0.50331, 0.12252, 0.63907, 0.19868, 0.71854, 0.42715, 0.54305, 0.13907, 0.65232, 0.27815, 0.68874, 0.07285, 0.51872, 0.26653, 0.49013, 0.27687, 0.46216, 0.28574, 0.43484, 0.29324, 0.40821, 0.29942], [1.0, 0.0, 1.0, 0.11385, 0.70019, -0.12144, 0.81594, 0.09677, 0.71157, 0.01139, 0.56167, -0.0778, 0.6907, 0.12524, 0.58634, 0.03985, 0.53131, -0.03416, 0.6945, 0.16888, 0.72676, 0.07211, 0.32068, 0.05882, 0.53321, 0.37381, 0.4909, 0.17951, 0.1518, 0.32448, 0.44141, 0.18897, 0.56167, 0.1518], [1.0, 0.0, 0.84843, 0.06794, 0.80562, -0.02299, 0.77031, -0.03299, 0.66725, -0.0662, 0.59582, -0.07666, 0.6726, -0.05771, 0.6426, -0.06438, 0.39199, 0.0453, 0.71254, 0.01394, 0.5597, -0.08039, 0.5343, -0.08453, 0.47038, -0.22822, 0.48659, -0.09128, 0.52613, -0.08537, 0.44277, -0.09621, 0.42223, -0.09808], [1.0, 0.0, 1.0, 0.08013, 0.96775, -0.00482, 0.96683, -0.00722, 0.8798, -0.03923, 1.0, 0.01419, 0.96186, -0.01436, 0.95947, -0.01671, 0.98497, 0.01002, 0.91152, -0.08848, 0.95016, -0.02364, 0.94636, -0.02591, 0.98164, 0.02003, 0.93772, -0.03034, 1.0, -0.05843, 0.92774, -0.03464, 0.92226, -0.03673], [1.0, 0.0, 0.47938, -0.12371, 0.42784, -0.12371, 0.70103, -0.39175, 0.73196, 0.07216, 0.26289, -0.21649, 0.49485, 0.15979, 0.45361, -0.11856, 0.42268, 0.06186, 0.5, -0.2732, 0.54639, 0.18557, 0.42268, 0.08247, 0.70619, 0.19588, 0.53396, -0.12447, 0.15464, -0.26289, 0.47423, 0.04124, 0.45361, -0.51546], [1.0, 0.0, 0.6351, -0.04388, 0.7653, 0.02968, 0.61432, 0.36028, 0.65358, -0.00462, 0.64203, 0.08314, 0.79446, -0.43418, 0.72517, 0.54965, 0.59584, 0.13857, 0.6351, 0.2194, 0.63279, -0.25404, 0.70951, 0.15359, 0.64665, 0.23095, 0.68775, 0.17704, 0.61663, 0.07621, 0.66316, 0.19841, 0.69053, 0.36721], [1.0, 0.0, 0.50112, -0.03596, 0.61124, 0.01348, 0.58876, 0.01573, 0.58876, 0.02472, 0.66742, -0.00449, 0.71685, -0.04719, 0.66517, 0.00899, 0.57303, 0.02472, 0.64719, -0.07416, 0.56854, 0.14157, 0.57528, -0.03596, 0.46517, 0.04944, 0.56588, 0.00824, 0.4764, -0.03596, 0.54607, 0.10562, 0.60674, -0.0809], [1.0, 0.0, 0.71521, -0.00647, 0.66667, -0.04207, 0.63107, -0.05178, 0.77994, 0.08091, 0.67314, 0.09709, 0.64725, 0.15858, 0.60194, -0.01942, 0.54369, -0.04531, 0.46926, -0.10032, 0.64725, 0.14887, 0.39159, 0.21683, 0.52427, -0.05502, 0.45105, 0.0004, 0.31392, -0.06796, 0.49191, -0.1068, 0.30421, -0.05178], [1.0, 0.0, 0.68148, 0.1037, 0.77037, 0.03457, 0.65185, 0.08148, 0.60988, -0.00494, 0.79012, 0.11852, 0.59753, 0.04938, 0.62469, 0.0963, 0.78272, -0.17531, 0.73827, -0.10864, 0.48642, 0.00988, 0.60988, 0.08148, 0.66667, -0.1284, 0.63773, -0.02451, 0.76543, 0.02222, 0.61235, -0.0716, 0.51358, -0.04691], [1.0, 0.0, 0.60678, -0.02712, 0.67119, 0.04068, 0.52881, -0.04407, 0.50508, 0.03729, 0.70508, -0.07797, 0.57966, -0.02034, 0.5322, 0.07797, 0.64068, 0.11864, 0.56949, -0.02373, 0.5322, 0.00678, 0.71525, -0.0339, 0.52881, -0.0339, 0.57262, 0.0075, 0.58644, -0.00339, 0.58983, -0.02712, 0.50169, 0.0678], [1.0, 0.0, 0.49515, 0.09709, 0.29612, 0.05825, 0.34951, 0.0, 0.57282, -0.02427, 0.58252, 0.02427, 0.33495, 0.04854, 0.52427, 0.00485, 0.47087, -0.1068, 0.43204, 0.00485, 0.34951, 0.05825, 0.18932, 0.25728, 0.31068, -0.15049, 0.36547, 0.03815, 0.3932, 0.17476, 0.26214, 0.0, 0.37379, -0.01942], [1.0, 0.0, 0.98822, 0.02187, 0.93102, 0.341, 0.83904, 0.35222, 0.74706, 0.48906, 0.73584, 0.51879, 0.55076, 0.60179, 0.4313, 0.66237, 0.318, 0.70443, 0.28379, 0.68873, 0.07515, 0.73696, 0.06338, 0.71284, -0.16489, 0.69714, -0.16556, 0.6051, -0.16209, 0.55805, -0.34717, 0.44195, -0.33483, 0.37465], [1.0, 0.0, 0.97905, 0.1581, 0.90112, 0.35237, 0.82039, 0.48561, 0.7176, 0.64888, 0.58827, 0.73743, 0.40349, 0.83156, 0.2514, 0.84804, 0.047, 0.85475, -0.12193, 0.79749, -0.2618, 0.80754, -0.37835, 0.71676, -0.51034, 0.58324, -0.57587, 0.4604, -0.61899, 0.30796, -0.65754, 0.18345, -0.64134, 0.02968], [1.0, 0.0, 0.99701, 0.21677, 0.91966, 0.4703, 0.76902, 0.62415, 0.53312, 0.7812, 0.36774, 0.88291, 0.10107, 0.83312, -0.06827, 0.89274, -0.28269, 0.72073, -0.43707, 0.61688, -0.55769, 0.4812, -0.65, 0.35534, -0.64658, 0.15908, -0.66651, 0.02277, -0.64872, -0.13462, -0.54615, -0.22949, -0.47201, -0.35032], [1.0, 0.0, 0.94331, 0.19959, 0.96132, 0.40803, 0.80514, 0.56569, 0.56687, 0.7083, 0.41836, 0.8323, 0.14939, 0.89489, 0.05167, 0.93682, -0.24742, 0.83939, -0.42811, 0.75554, -0.50251, 0.62563, -0.65515, 0.50428, -0.68851, 0.30912, -0.77097, 0.15619, -0.75406, -0.04399, -0.75199, -0.17921, -0.66932, -0.34367], [1.0, 0.0, 0.93972, 0.28082, 0.80486, 0.52821, 0.58167, 0.73151, 0.34961, 0.80511, 0.10797, 0.90403, -0.20015, 0.89335, -0.3973, 0.82163, -0.58835, 0.62867, -0.76305, 0.40368, -0.81262, 0.18888, -0.81317, -0.04284, -0.75273, -0.26883, -0.63237, -0.46438, -0.46422, -0.61446, -0.26389, -0.70835, -0.08937, -0.71273], [1.0, 0.0, 0.89835, 0.35157, 0.67333, 0.62233, 0.43898, 0.94353, -0.03643, 0.8051, -0.22838, 0.75334, -0.25137, 0.48816, -0.57377, 0.28415, -0.6675, 0.10591, -0.47359, -0.06193, -0.81056, -0.06011, -0.33197, -0.47592, -0.12897, -0.5362, 0.07158, -0.51925, 0.24321, -0.43478, 0.36586, -0.30057, 0.42805, 0.13297], [1.0, 0.0, 0.29073, 0.10025, 0.23308, 0.17293, 0.03759, 0.34336, 0.1203, 0.26316, 0.06266, 0.21303, -0.04725, 0.12767, -0.06333, 0.07907, -0.06328, 0.04097, -0.05431, 0.01408, -0.04166, -0.0028, -0.02876, -0.01176, -0.01755, -0.01505, -0.00886, -0.01475, -0.0028, -0.0125, 0.00096, -0.00948, 0.0029, -0.00647], [1.0, 0.0, 0.58459, -0.35526, 1.0, 0.35338, 0.75376, -0.00564, 0.82519, 0.19361, 0.50188, -0.27632, 0.65977, 0.06391, 0.69737, 0.14662, 0.72368, -0.42669, 0.76128, 0.04511, 0.66917, 0.20489, 0.84774, -0.40977, 0.6485, -0.04699, 0.56836, -0.10571, 0.5282, -0.13346, 0.15602, -0.12218, 0.44767, -0.10309], [1.0, 0.0, 0.83609, 0.13215, 0.72171, 0.06059, 0.65829, 0.08315, 0.23888, 0.12961, 0.43837, 0.2033, 0.49418, 0.12686, 0.44747, 0.13507, 0.29352, 0.02922, 0.48158, 0.15756, 0.32835, 0.14616, 0.29495, 0.14638, 0.26436, 0.1453, 0.23641, 0.14314, 0.26429, 0.16137, 0.18767, 0.13632, 0.16655, 0.13198], [1.0, 0.0, 0.9408, 0.11933, 0.85738, 0.01038, 0.85124, 0.01546, 0.76966, -0.00278, 0.84459, 0.10916, 0.83289, 0.03027, 0.8268, 0.03506, 0.74838, 0.01943, 0.80019, 0.02405, 0.80862, 0.04901, 0.80259, 0.05352, 0.77336, 0.0222, 0.79058, 0.06235, 0.85939, 0.09251, 0.77863, 0.0709, 0.77269, 0.07508], [1.0, 0.0, 0.87111, 0.04326, 0.79946, 0.18297, 0.99009, 0.29292, 0.89455, -0.08337, 0.88598, -0.02028, 0.90446, -0.26724, 0.8941, 0.19964, 0.88644, -0.04642, 0.84452, -0.00991, 0.97882, -0.34024, 0.78954, -0.25101, 0.86661, -0.09193, 0.85967, -0.02908, 0.78774, -0.04101, 0.75935, 0.21812, 0.88238, 0.09193], [1.0, 0.0, 0.74916, 0.02549, 0.98994, 0.09792, 0.75855, 0.12877, 0.74313, -0.09188, 0.95842, 0.02482, 0.97921, -0.00469, 0.9611, 0.10195, 0.91482, 0.03756, 0.71026, 0.02683, 0.81221, -0.08048, 1.0, 0.0, 0.71764, -0.01207, 0.82271, 0.02552, 0.72435, -0.01073, 0.90409, 0.11066, 0.72837, 0.0275], [1.0, 0.0, 0.47337, 0.19527, 0.06213, -0.18343, 0.62316, 0.01006, 0.45562, -0.04438, 0.56509, 0.01775, 0.44675, 0.27515, 0.71598, -0.03846, 0.55621, 0.12426, 0.4142, 0.11538, 0.52767, 0.02842, 0.51183, -0.10651, 0.47929, -0.02367, 0.46514, 0.03259, 0.5355, 0.25148, 0.31953, -0.14497, 0.34615, -0.00296], [1.0, 0.0, 0.59887, 0.14689, 0.69868, -0.13936, 0.85122, -0.13936, 0.80979, 0.02448, 0.50471, 0.02825, 0.6742, -0.0452, 0.80791, -0.13748, 0.51412, -0.24482, 0.81544, -0.14313, 0.70245, -0.00377, 0.33333, 0.06215, 0.56121, -0.33145, 0.61444, -0.16837, 0.52731, -0.02072, 0.53861, -0.31262, 0.6742, -0.22034], [1.0, 0.0, 0.84713, -0.03397, 0.86412, -0.08493, 0.81953, 0.0, 0.73673, -0.07643, 0.71975, -0.13588, 0.74947, -0.11677, 0.77495, -0.18684, 0.78132, -0.21231, 0.61996, -0.10191, 0.79193, -0.15711, 0.89384, -0.03397, 0.84926, -0.26115, 0.74115, -0.23312, 0.66242, -0.22293, 0.72611, -0.37792, 0.65817, -0.24841], [1.0, 0.0, 0.87772, -0.08152, 0.83424, 0.07337, 0.84783, 0.04076, 0.77174, -0.02174, 0.77174, -0.05707, 0.82337, -0.10598, 0.67935, -0.00543, 0.88043, -0.20924, 0.83424, 0.03261, 0.86413, -0.05978, 0.97283, -0.27989, 0.85054, -0.1875, 0.83705, -0.10211, 0.8587, -0.03261, 0.78533, -0.1087, 0.79076, -0.00543], [1.0, 0.0, 0.74704, -0.13241, 0.53755, 0.16996, 0.72727, 0.09486, 0.69565, -0.11067, 0.66798, -0.23518, 0.87945, -0.1917, 0.73715, 0.0415, 0.63043, -0.00395, 0.63636, -0.11858, 0.79249, -0.25296, 0.66403, -0.28656, 0.67194, -0.10474, 0.61847, -0.12041, 0.60079, -0.20949, 0.37549, 0.06917, 0.61067, -0.01383], [1.0, 0.0, 0.46785, 0.11308, 0.5898, 0.00665, 0.55432, 0.06874, 0.47894, -0.13969, 0.52993, 0.0133, 0.63858, -0.16186, 0.67849, -0.03326, 0.54545, -0.13525, 0.52993, -0.04656, 0.47894, -0.19512, 0.50776, -0.13525, 0.41463, -0.20177, 0.5393, -0.11455, 0.59867, -0.02882, 0.53659, -0.11752, 0.56319, -0.04435], [1.0, 0.0, 0.88116, 0.27475, 0.72125, 0.42881, 0.61559, 0.63662, 0.38825, 0.90502, 0.09831, 0.96128, -0.20097, 0.892, -0.35737, 0.775, -0.65114, 0.6221, -0.78768, 0.45535, -0.81856, 0.19095, -0.83943, -0.08079, -0.78334, -0.26356, -0.67557, -0.45511, -0.54732, -0.60858, -0.30512, -0.667, -0.19312, -0.75597], [1.0, 0.0, 0.93147, 0.29282, 0.79917, 0.55756, 0.59952, 0.71596, 0.26203, 0.92651, 0.04636, 0.96748, -0.23237, 0.9513, -0.55926, 0.81018, -0.73329, 0.62385, -0.90995, 0.362, -0.92254, 0.0604, -0.93618, -0.19838, -0.83192, -0.46906, -0.65165, -0.69556, -0.41223, -0.85725, -0.1359, -0.93953, 0.10007, -0.94823], [1.0, 0.0, 0.88241, 0.30634, 0.73232, 0.57816, 0.34109, 0.58527, 0.05717, 1.0, -0.09238, 0.92118, -0.62403, 0.71996, -0.69767, 0.32558, -0.81422, 0.41195, -1.0, -0.00775, -0.78973, -0.41085, -0.76901, -0.45478, -0.57242, -0.67605, -0.3161, -0.81876, -0.02979, -0.86841, 0.25392, -0.82127, 0.00194, -0.81686], [1.0, 0.0, 0.83479, 0.28993, 0.69256, 0.47702, 0.49234, 0.68381, 0.21991, 0.86761, -0.08096, 0.85011, -0.35558, 0.77681, -0.52735, 0.58425, -0.7035, 0.31291, -0.75821, 0.03939, -0.71225, -0.15317, -0.58315, -0.39168, -0.37199, -0.52954, -0.1695, -0.60863, 0.08425, -0.61488, 0.25164, -0.48468, 0.40591, -0.35339], [1.0, 0.0, 0.9287, 0.33164, 0.76168, 0.62349, 0.49305, 0.84266, 0.21592, 0.95193, -0.13956, 0.96167, -0.47202, 0.8359, -0.70747, 0.6549, -0.87474, 0.3675, -0.91814, 0.05595, -0.89824, -0.26173, -0.73969, -0.54069, -0.50757, -0.74735, -0.22323, -0.86122, 0.0781, -0.87159, 0.36021, -0.78057, 0.59407, -0.6027], [1.0, 0.0, 0.83367, 0.31456, 0.65541, 0.57671, 0.34962, 0.70677, 0.17293, 0.78947, -0.18976, 0.79886, -0.41729, 0.66541, -0.68421, 0.47744, -0.74725, 0.19492, -0.7218, -0.04887, -0.6203, -0.28195, -0.49165, -0.53463, -0.26577, -0.66014, -0.0153, -0.69706, 0.22708, -0.64428, 0.431, -0.51206, 0.64662, -0.30075], [1.0, 0.0, 0.98455, -0.02736, 0.98058, -0.04104, 1.0, -0.07635, 0.9872, 0.01456, 0.95278, -0.02604, 0.985, -0.07458, 0.99382, -0.07149, 0.97396, -0.09532, 0.97264, -0.12224, 0.99294, -0.05252, 0.95278, -0.08914, 0.97352, -0.08341, 0.96653, -0.12912, 0.93469, -0.14916, 0.97132, -0.15755, 0.96778, -0.188], [1.0, 0.0, 0.94052, -0.01531, 0.9417, 0.01001, 0.94994, -0.01472, 0.95878, -0.0106, 0.94641, -0.0371, 0.97173, -0.01767, 0.97055, -0.03887, 0.95465, -0.04064, 0.9523, -0.04711, 0.94229, -0.02179, 0.92815, -0.04417, 0.92049, -0.04476, 0.92695, -0.05827, 0.90342, -0.07479, 0.91991, -0.07244, 0.92049, -0.0742], [1.0, 0.0, 0.97032, -0.14384, 0.91324, -0.00228, 0.96575, -0.17123, 0.9863, 0.18265, 0.91781, 0.00228, 0.93607, -0.08447, 0.91324, -0.00228, 0.86758, -0.08676, 0.97032, -0.21233, 1.0, 0.10274, 0.92009, -0.05251, 0.92466, 0.06849, 0.94043, -0.09252, 0.97032, -0.20091, 0.85388, -0.08676, 0.96575, -0.21918], [1.0, 0.0, 0.52542, -0.0339, 0.94915, 0.08475, 0.52542, -0.16949, 0.30508, -0.01695, 0.50847, -0.13559, 0.64407, 0.28814, 0.83051, -0.35593, 0.54237, 0.01695, 0.55932, 0.0339, 0.59322, 0.30508, 0.86441, 0.05085, 0.40678, 0.15254, 0.67287, -0.00266, 0.66102, -0.0339, 0.83051, -0.15254, 0.76271, -0.10169], [1.0, 0.0, 0.33333, -0.25, 0.44444, 0.22222, 0.38889, 0.16667, 0.41667, 0.13889, 0.5, -0.11111, 0.54911, -0.08443, 0.58333, 0.33333, 0.55556, 0.02778, 0.25, -0.19444, 0.47222, -0.05556, 0.52778, -0.02778, 0.38889, 0.08333, 0.41543, -0.14256, 0.19444, -0.13889, 0.36924, -0.14809, 0.08333, -0.5], [1.0, 0.0, 0.51207, 1.0, 1.0, 0.5381, 0.71178, 0.80833, 0.45622, 0.46427, 0.33081, 1.0, 0.21249, 1.0, -0.17416, 1.0, -0.33081, 0.98722, -0.61382, 1.0, -0.52674, 0.71699, -0.885, 0.47894, -1.0, 0.35175, -1.0, 0.09569, -1.0, -0.16713, -1.0, -0.42226, -0.91903, -0.65557], [1.0, 0.0, 0.75564, 0.49638, 0.8355, 0.54301, 0.54916, 0.72063, 0.35225, 0.70792, 0.13469, 0.94749, -0.09818, 0.93778, -0.37604, 0.82223, -0.52742, 0.71161, -0.68358, 0.67989, -0.70163, 0.24956, -0.79147, 0.02995, -0.98988, -0.29099, -0.70352, -0.32792, -0.63312, -0.19185, -0.34131, -0.60454, -0.19609, -0.62956], [1.0, 0.0, 0.83789, 0.42904, 0.72113, 0.58385, 0.45625, 0.78115, 0.1647, 0.82732, -0.13012, 0.86947, -0.46177, 0.78497, -0.59435, 0.5207, -0.7847, 0.26529, -0.84014, 0.03928, -0.62041, -0.31351, -0.47412, -0.48905, -0.37298, -0.67796, -0.05054, -0.62691, 0.1469, -0.45911, 0.37093, -0.39167, 0.48319, -0.24313], [1.0, 0.0, 0.93658, 0.35107, 0.75254, 0.6564, 0.45571, 0.88576, 0.15323, 0.95776, -0.21775, 0.96301, -0.56535, 0.83397, -0.78751, 0.58045, -0.93104, 0.2602, -0.93641, -0.06418, -0.87028, -0.40949, -0.65079, -0.67464, -0.36799, -0.84951, -0.04578, -0.91221, 0.2733, -0.85762, 0.54827, -0.69613, 0.74828, -0.44173], [1.0, 0.0, 0.92436, 0.36924, 0.71976, 0.6842, 0.29303, 0.94078, -0.11108, 0.76527, -0.31605, 0.92453, -0.66616, 0.78766, -0.92145, 0.42314, -0.94315, 0.09585, -1.0, 0.03191, -0.66431, -0.66278, -0.4601, -0.78174, -0.13486, -0.88082, 0.19765, -0.85137, 0.48904, -0.70247, 0.69886, -0.46048, 0.76066, -0.13194], [1.0, 0.0, 1.0, 0.16195, 1.0, -0.05558, 1.0, 0.01373, 1.0, -0.12352, 1.0, -0.01511, 1.0, -0.01731, 1.0, -0.06374, 1.0, -0.07157, 1.0, 0.059, 1.0, -0.10108, 1.0, -0.02685, 1.0, -0.22978, 1.0, -0.06823, 1.0, 0.08299, 1.0, -0.14194, 1.0, -0.07439], [1.0, 0.0, 0.95559, -0.00155, 0.86421, -0.13244, 0.94982, -0.00461, 0.82809, -0.51171, 0.92441, 0.10368, 1.0, -0.14247, 0.99264, -0.02542, 0.95853, -0.15518, 0.84013, 0.61739, 1.0, -0.16321, 0.87492, -0.08495, 0.85741, -0.01664, 0.84132, -0.01769, 0.82427, -0.01867, 0.80634, -0.01957, 0.78761, -0.02039], [1.0, 0.0, 0.79378, 0.29492, 0.64064, 0.52312, 0.41319, 0.68158, 0.14177, 0.83548, -0.16831, 0.78772, -0.42911, 0.72328, -0.57165, 0.41471, -0.75436, 0.16755, -0.69977, -0.09856, -0.57695, -0.23503, -0.40637, -0.38287, -0.17437, -0.5254, 0.01523, -0.48707, 0.1903, -0.38059, 0.31008, -0.23199, 0.34572, -0.08036], [1.0, 0.0, 0.88085, 0.35232, 0.68389, 0.65128, 0.34816, 0.79784, 0.05832, 0.90842, -0.29784, 0.8649, -0.62635, 0.6959, -0.77106, 0.39309, -0.85803, 0.08408, -0.81641, -0.24017, -0.64579, -0.50022, -0.39766, -0.68337, -0.11147, -0.75533, 0.17041, -0.71504, 0.40675, -0.57649, 0.56626, -0.36765, 0.62765, -0.13305], [1.0, 0.0, 0.89589, 0.39286, 0.66129, 0.71804, 0.29521, 0.90824, -0.04787, 0.94415, -0.45725, 0.84605, -0.7766, 0.58511, -0.92819, 0.25133, -0.92282, -0.15315, -0.76064, -0.48404, -0.50931, -0.76197, -0.14895, -0.88591, 0.21581, -0.85703, 0.53229, -0.68593, 0.74846, -0.40656, 0.83142, -0.07029, 0.76862, 0.27926], [1.0, 0.0, 1.0, -0.24051, 1.0, -0.20253, 0.87342, -0.10127, 0.88608, 0.01266, 1.0, 0.11392, 0.92405, 0.06329, 0.8481, -0.03797, 0.63291, -0.36709, 0.87342, -0.01266, 0.93671, 0.06329, 1.0, 0.25316, 0.62025, -0.37975, 0.84637, -0.0554, 1.0, -0.06329, 0.53165, 0.02532, 0.83544, -0.02532], [1.0, 0.0, 0.7479, 0.0084, 0.83312, 0.01659, 0.82638, 0.02469, 0.86555, 0.01681, 0.60504, 0.05882, 0.79093, 0.04731, 0.77441, 0.05407, 0.64706, 0.19328, 0.84034, 0.04202, 0.71285, 0.07122, 0.68895, 0.07577, 0.66387, 0.08403, 0.63728, 0.08296, 0.61345, 0.01681, 0.58187, 0.08757, 0.5533, 0.08891], [1.0, 0.0, 0.85013, 0.01809, 0.92211, 0.01456, 0.92046, 0.0218, 0.92765, 0.0801, 0.87597, 0.1137, 0.91161, 0.0432, 0.90738, 0.05018, 0.87339, 0.02842, 0.95866, 0.0, 0.89097, 0.07047, 0.8843, 0.07697, 0.83721, 0.10853, 0.86923, 0.0895, 0.87597, 0.08786, 0.85198, 0.10134, 0.84258, 0.10698], [1.0, 0.0, 1.0, -0.01179, 1.0, -0.00343, 1.0, -0.01565, 1.0, -0.01565, 1.0, -0.02809, 1.0, -0.02187, 0.99828, -0.03087, 0.99528, -0.03238, 0.99314, -0.03452, 1.0, -0.03881, 1.0, -0.05039, 1.0, -0.04931, 0.99842, -0.05527, 0.994, -0.06304, 0.99057, -0.06497, 0.98971, -0.06668], [1.0, 0.0, 0.89505, -0.03168, 0.87525, 0.05545, 0.89505, 0.01386, 0.92871, 0.02772, 0.91287, -0.0099, 0.94059, -0.01584, 0.91881, 0.03366, 0.93663, 0.0, 0.94257, 0.01386, 0.90495, 0.00792, 0.88713, -0.01782, 0.89307, 0.02376, 0.89002, 0.01611, 0.88119, 0.00198, 0.87327, 0.04158, 0.86733, 0.02376], [1.0, 0.0, 0.90071, 0.01773, 1.0, -0.01773, 0.90071, 0.00709, 0.84752, 0.05674, 1.0, 0.03546, 0.97872, 0.01064, 0.97518, 0.03546, 1.0, -0.03191, 0.89716, -0.03191, 0.8617, 0.07801, 1.0, 0.0922, 0.90071, 0.0461, 0.94305, 0.03247, 0.94681, 0.02482, 1.0, 0.01064, 0.93617, 0.02128], [1.0, 0.0, 0.39394, -0.24242, 0.62655, 0.0127, 0.45455, 0.09091, 0.63636, 0.09091, 0.21212, -0.21212, 0.57576, 0.15152, 0.39394, 0.0, 0.56156, 0.04561, 0.51515, 0.0303, 0.78788, 0.18182, 0.30303, -0.15152, 0.48526, 0.05929, 0.46362, 0.06142, 0.33333, -0.0303, 0.41856, 0.0641, 0.39394, 0.24242], [1.0, 0.0, 0.86689, 0.3595, 0.72014, 0.66667, 0.37201, 0.83049, 0.08646, 0.85893, -0.24118, 0.86121, -0.51763, 0.67577, -0.68714, 0.41524, -0.77019, 0.09898, -0.69397, -0.13652, -0.49488, -0.42207, -0.32537, -0.57679, -0.02844, -0.59954, 0.1536, -0.53127, 0.32309, -0.37088, 0.46189, -0.19681, 0.40956, 0.0182], [1.0, 0.0, 0.89563, 0.37917, 0.67311, 0.69438, 0.35916, 0.88696, -0.04193, 0.93345, -0.38875, 0.84414, -0.67274, 0.62078, -0.8268, 0.30356, -0.8615, -0.05365, -0.73564, -0.34275, -0.51778, -0.62443, -0.23428, -0.73855, 0.06911, -0.73856, 0.33531, -0.62296, 0.52414, -0.42086, 0.61217, -0.17343, 0.60073, 0.0866], [1.0, 0.0, 0.90547, 0.41113, 0.65354, 0.74761, 0.29921, 0.95905, -0.13342, 0.9782, -0.52236, 0.83263, -0.79657, 0.55086, -0.96631, 0.15192, -0.93001, -0.25554, -0.71863, -0.59379, -0.41546, -0.85205, -0.0225, -0.93788, 0.36318, -0.85368, 0.67538, -0.61959, 0.85977, -0.28123, 0.88654, 0.098, 0.75495, 0.46301], [1.0, 0.0, 1.0, 1.0, 0.367, 0.06158, 0.12993, 0.92713, -0.27586, 0.93596, -0.31527, 0.37685, -0.87192, 0.36946, -0.92857, -0.08867, -0.38916, -0.34236, -0.46552, -0.82512, -0.05419, -0.93596, 0.25616, -0.20443, 0.73792, -0.4595, 0.85471, -0.06831, 1.0, 1.0, 0.3867, 0.00246, 0.17758, 0.7979], [1.0, 0.0, 1.0, 0.51515, 0.45455, 0.33333, 0.06061, 0.36364, -0.32104, 0.73062, -0.45455, 0.48485, -0.57576, 0.0, -0.57576, -0.12121, -0.33333, -0.48485, -0.09091, -0.84848, 0.48485, -0.57576, 0.57576, -0.42424, 1.0, -0.39394, 0.72961, 0.12331, 0.9697, 0.57576, 0.24242, 0.36364, 0.09091, 0.33333], [1.0, 0.0, 0.8811, 0.0, 0.94817, -0.02744, 0.93598, -0.0122, 0.90244, 0.01829, 0.90244, 0.01829, 0.93902, 0.00915, 0.95732, 0.00305, 1.0, 0.02744, 0.94207, -0.0122, 0.90854, 0.02439, 0.91463, 0.05488, 0.99695, 0.04878, 0.89666, 0.02226, 0.90854, 0.00915, 1.0, 0.05488, 0.97561, -0.0122], [1.0, 0.0, 0.82624, 0.08156, 0.79078, -0.08156, 0.90426, -0.01773, 0.92908, 0.01064, 0.80142, 0.08865, 0.94681, -0.00709, 0.94326, 0.0, 0.93262, 0.20213, 0.95035, -0.00709, 0.91489, 0.00709, 0.80496, 0.07092, 0.91135, 0.15957, 0.89527, 0.08165, 0.7766, 0.06738, 0.92553, 0.18085, 0.92553, 0.0], [1.0, 0.0, 0.74468, 0.10638, 0.88706, 0.00982, 0.88542, 0.01471, 0.87234, -0.01418, 0.7305, 0.10638, 0.87657, 0.02912, 0.87235, 0.03382, 0.95745, 0.07801, 0.95035, 0.04255, 0.85597, 0.04743, 0.84931, 0.05178, 0.87234, 0.11348, 0.83429, 0.06014, 0.74468, -0.03546, 0.8171, 0.068, 0.80774, 0.07173], [1.0, 0.0, 0.87578, 0.03727, 0.89951, 0.00343, 0.8921, 0.0051, 0.86335, 0.0, 0.95031, 0.07453, 0.87021, 0.00994, 0.86303, 0.01151, 0.83851, -0.06211, 0.85714, 0.02484, 0.84182, 0.01603, 0.83486, 0.01749, 0.79503, -0.04348, 0.82111, 0.02033, 0.81988, 0.08696, 0.80757, 0.02308, 0.80088, 0.02441], [1.0, 0.0, 0.97513, 0.0071, 0.98579, 0.01954, 1.0, 0.01954, 0.9929, 0.01599, 0.95737, 0.02309, 0.97158, 0.03552, 1.0, 0.0373, 0.97869, 0.02131, 0.98579, 0.05684, 0.97158, 0.04796, 0.94494, 0.05506, 0.98401, 0.03552, 0.9754, 0.06477, 0.94849, 0.08171, 0.99112, 0.06217, 0.98934, 0.09947], [1.0, 0.0, 1.0, 0.01105, 1.0, 0.01105, 1.0, 0.0232, 0.99448, -0.01436, 0.99448, -0.00221, 0.98343, 0.0232, 1.0, 0.00884, 0.97569, 0.00773, 0.97901, 0.01657, 0.98011, 0.00663, 0.98122, 0.02099, 0.97127, -0.00663, 0.98033, 0.016, 0.97901, 0.01547, 0.98564, 0.02099, 0.98674, 0.02762], [1.0, 0.0, 1.0, -0.01342, 1.0, 0.01566, 1.0, -0.00224, 1.0, 0.06264, 0.97763, 0.04474, 0.95973, 0.02908, 1.0, 0.06488, 0.98881, 0.03356, 1.0, 0.03579, 0.99776, 0.09396, 0.95749, 0.07383, 1.0, 0.10067, 0.99989, 0.08763, 0.99105, 0.08501, 1.0, 0.10067, 1.0, 0.10067], [1.0, 0.0, 0.8842, 0.36724, 0.67123, 0.67382, 0.39613, 0.86399, 0.02424, 0.93182, -0.35148, 0.83713, -0.60316, 0.58842, -0.78658, 0.38778, -0.83285, -0.00642, -0.69318, -0.32963, -0.52504, -0.53924, -0.27377, -0.68126, 0.00806, -0.69774, 0.26028, -0.60678, 0.44569, -0.43383, 0.54209, -0.21542, 0.56286, 0.02823], [1.0, 0.0, 0.90147, 0.41786, 0.64131, 0.75725, 0.3044, 0.95148, -0.20449, 0.96534, -0.55483, 0.81191, -0.81857, 0.50949, -0.96986, 0.10345, -0.91456, -0.31412, -0.70163, -0.65461, -0.32354, -0.88999, 0.05865, -0.94172, 0.44483, -0.82154, 0.74105, -0.55231, 0.89415, -0.18725, 0.87893, 0.20359, 0.70555, 0.54852], [1.0, 0.0, 0.32789, 0.11042, 0.1597, 0.29308, 0.1402, 0.74485, -0.25131, 0.91993, -0.16503, 0.26664, -0.63714, 0.24865, -0.9765, -0.00337, -0.23227, -0.19909, -0.30522, -0.48886, -0.14426, -0.89991, 0.09345, -0.28916, 0.28307, -0.1856, 0.39599, -0.11498, 0.31005, 0.05614, 0.21443, 0.2054, 0.13376, 0.26422], [1.0, 0.0, 0.65845, 0.43617, 0.44681, 0.74804, 0.05319, 0.85106, -0.32027, 0.82139, -0.68253, 0.52408, -0.84211, 0.07111, -0.82811, -0.28723, -0.47032, -0.71725, -0.04759, -0.86002, 0.23292, -0.76316, 0.56663, -0.52128, 0.743, -0.18645, 0.74758, 0.23713, 0.45185, 0.59071, 0.20549, 0.76764, -0.18533, 0.74356], [1.0, 0.0, 0.19466, 0.05725, 0.04198, 0.25191, -0.10557, 0.48866, -0.18321, -0.18321, -0.41985, 0.06107, -0.4542, 0.0916, -0.16412, -0.30534, -0.10305, -0.39695, 0.18702, -0.17557, 0.34012, -0.11953, 0.28626, -0.16031, 0.21645, 0.24692, 0.03913, 0.31092, -0.03817, 0.26336, -0.16794, 0.16794, -0.30153, -0.33588], [1.0, 0.0, 0.98002, 0.00075, 1.0, 0.0, 0.98982, -0.00075, 0.94721, 0.02394, 0.977, 0.0213, 0.97888, 0.03073, 0.9917, 0.02338, 0.93929, 0.05713, 0.93552, 0.05279, 0.97738, 0.05524, 1.0, 0.06241, 0.94155, 0.08107, 0.96709, 0.07255, 0.95701, 0.08088, 0.9819, 0.08126, 0.97247, 0.08616], [1.0, 0.0, 0.82254, -0.07572, 0.80462, 0.00231, 0.87514, -0.01214, 0.86821, -0.07514, 0.72832, -0.11734, 0.84624, 0.05029, 0.83121, -0.07399, 0.74798, 0.06705, 0.78324, 0.06358, 0.86763, -0.0237, 0.78844, -0.06012, 0.74451, -0.0237, 0.76717, -0.02731, 0.74046, -0.0763, 0.70058, -0.0422, 0.78439, 0.01214], [1.0, 0.0, 0.35346, -0.13768, 0.69387, -0.02423, 0.68195, -0.03574, 0.55717, -0.06119, 0.61836, -0.10467, 0.62099, -0.06527, 0.59361, -0.07289, 0.42271, -0.26409, 0.58213, 0.04992, 0.49736, -0.08771, 0.46241, -0.08989, 0.45008, -0.00564, 0.39146, -0.09038, 0.35588, -0.10306, 0.32232, -0.08637, 0.28943, -0.083], [1.0, 0.0, 0.76046, 0.01092, 0.86335, 0.00258, 0.85821, 0.00384, 0.79988, 0.02304, 0.81504, 0.12068, 0.83096, 0.00744, 0.81815, 0.00854, 0.82777, -0.06974, 0.76531, 0.03881, 0.76979, 0.01148, 0.75071, 0.01232, 0.77138, -0.00303, 0.70886, 0.01375, 0.66161, 0.00849, 0.66298, 0.01484, 0.63887, 0.01525], [1.0, 0.0, 0.66667, -0.01366, 0.97404, 0.06831, 0.4959, 0.50137, 0.75683, -0.00273, 0.65164, -0.14071, 0.40164, -0.48907, 0.39208, 0.58743, 0.76776, 0.31831, 0.78552, 0.11339, 0.47541, -0.44945, 1.0, 0.00683, 0.60656, 0.06967, 0.68656, 0.17088, 0.87568, 0.07787, 0.55328, 0.2459, 0.13934, 0.48087], [1.0, 0.0, 0.83508, 0.08298, 0.73739, -0.14706, 0.84349, -0.05567, 0.90441, -0.04622, 0.89391, 0.1313, 0.81197, 0.06723, 0.79307, -0.08929, 1.0, -0.02101, 0.96639, 0.06618, 0.87605, 0.01155, 0.77521, 0.06618, 0.95378, -0.04202, 0.83479, 0.00123, 1.0, 0.12815, 0.8666, -0.10714, 0.90546, -0.04307], [1.0, 0.0, 0.95113, 0.00419, 0.95183, -0.02723, 0.93438, -0.0192, 0.9459, 0.01606, 0.9651, 0.03281, 0.94171, 0.0733, 0.94625, -0.01326, 0.97173, 0.0014, 0.94834, 0.06038, 0.9267, 0.08412, 0.93124, 0.10087, 0.9452, 0.01361, 0.93522, 0.04925, 0.93159, 0.08168, 0.94066, -0.00035, 0.91483, 0.04712], [1.0, 0.0, 0.94701, -0.00034, 0.93207, -0.03227, 0.95177, -0.03431, 0.95584, 0.02446, 0.94124, 0.01766, 0.92595, 0.04688, 0.93954, -0.01461, 0.94837, 0.02004, 0.93784, 0.01393, 0.91406, 0.07677, 0.8947, 0.06148, 0.93988, 0.03193, 0.92489, 0.02542, 0.9212, 0.02242, 0.92459, 0.00442, 0.92697, -0.00577], [1.0, 0.0, 0.90608, -0.01657, 0.98122, -0.01989, 0.95691, -0.03646, 0.85746, 0.0011, 0.89724, -0.03315, 0.89061, -0.01436, 0.90608, -0.0453, 0.91381, -0.00884, 0.80773, -0.12928, 0.88729, 0.01215, 0.92155, -0.0232, 0.9105, -0.02099, 0.89147, -0.0776, 0.82983, -0.17238, 0.96022, -0.03757, 0.87403, -0.16243], [1.0, 0.0, 0.8471, 0.13533, 0.73638, -0.06151, 0.87873, 0.0826, 0.88928, -0.09139, 0.78735, 0.06678, 0.80668, -0.00351, 0.79262, -0.01054, 0.85764, -0.04569, 0.8717, -0.03515, 0.81722, -0.0949, 0.71002, 0.04394, 0.86467, -0.15114, 0.81147, -0.04822, 0.78207, -0.00703, 0.75747, -0.06678, 0.85764, -0.06151]]\n",
      "[1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "filename = 'Dataset/ionosphere.csv'\n",
    "dataset,label=getData(filename)\n",
    "# dataset=pd.DataFrame(dataset) #from dataset_list to dataset_dataframe after suffling\n",
    "print(dataset)\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA(n_components=20)\n",
      "<class 'numpy.ndarray'>\n",
      "20\n",
      "[[-8.59332860e-01 -9.61406757e-01 -5.86082357e-01 ...  2.04483007e-03\n",
      "   6.17162292e-02 -9.51471379e-02]\n",
      " [ 7.65524410e-01 -1.06271411e+00 -1.39733865e+00 ...  4.29774597e-02\n",
      "   3.92008382e-01  3.03880796e-01]\n",
      " [-1.11681736e+00 -3.92255939e-01  7.98828031e-03 ...  9.68308725e-03\n",
      "   1.86505649e-01  7.08624174e-02]\n",
      " ...\n",
      " [-2.00968648e+00  7.02142791e-03  3.45603502e-01 ... -4.95037761e-03\n",
      "   6.48951591e-02 -1.61964951e-02]\n",
      " [-1.87850608e+00 -2.58263391e-01  2.79973413e-01 ...  7.72608660e-03\n",
      "   6.90995922e-02 -9.90757043e-02]\n",
      " [-1.54878315e+00 -1.87526433e-01  2.17570815e-01 ...  1.68335143e-03\n",
      "   8.91444630e-02  3.30264587e-02]]\n"
     ]
    }
   ],
   "source": [
    "pcaTrain = PCA(n_components=20).fit(dataset)# --train-- pca with the \"dataset\" Dataframe\n",
    "print(pcaTrain)\n",
    "compressed_dataset_X= pcaTrain.transform(dataset) # --transform-- the original \"dataset\" Dataframe into a lower-dimensional space based on the model's learned parameters\n",
    "print(type(compressed_dataset_X))\n",
    "print(len(compressed_dataset_X[0]))\n",
    "print(compressed_dataset_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34\n"
     ]
    }
   ],
   "source": [
    "# from NecessaryModules.splitData import split_data\n",
    "X_train, y_train, X_test, y_test = split_data(dataset,label)\n",
    "print(len(X_train[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compressed_dataset_X_train,y_train,compressed_dataset_X_test,y_test=split_data(compressed_dataset_X,label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "240\n",
      "[[-6.44376519e-01  7.08414856e-01  2.05374252e-01 ... -1.89439290e-01\n",
      "  -8.00161676e-02 -2.07967722e-01]\n",
      " [ 1.27183384e+00 -1.43762982e-01 -8.18662445e-01 ...  1.97904284e-02\n",
      "  -8.72081496e-02 -7.53467966e-02]\n",
      " [-2.14496873e+00  9.36788323e-02  4.70448766e-01 ... -1.82681734e-02\n",
      "   8.28670708e-02 -2.94827757e-02]\n",
      " ...\n",
      " [-9.63605279e-01 -2.62877885e-01 -7.59176594e-01 ... -2.75984479e-01\n",
      "  -5.06505550e-01 -6.87653819e-02]\n",
      " [ 1.29786762e+00 -1.54536987e-01 -8.76249845e-01 ...  1.32467045e-01\n",
      "   1.14410871e-01  7.20873736e-02]\n",
      " [ 2.53712244e+00 -7.67280221e-01  1.51674901e+00 ...  3.74291313e-02\n",
      "   2.53064984e-02  8.41975213e-04]]\n",
      "<class 'numpy.ndarray'>\n",
      "111\n",
      "[[ 0.84118993 -0.62380799 -0.910987   ... -0.04599337  0.00305829\n",
      "   0.03568066]\n",
      " [ 1.41301682 -0.68417543 -0.22045242 ... -0.11288988 -0.06433759\n",
      "   0.17074908]\n",
      " [-0.33590708  0.08206622 -0.26109527 ... -0.11845169  0.12477571\n",
      "   0.04755266]\n",
      " ...\n",
      " [ 1.27772236 -0.22899135 -0.23037415 ... -0.44203402 -0.26365095\n",
      "  -0.24165337]\n",
      " [ 2.47825589 -1.66184995  2.30654243 ... -0.03182704  0.10133671\n",
      "   0.01731148]\n",
      " [ 1.50086607  0.47237676 -1.5960987  ...  0.12541156 -0.10021715\n",
      "   0.91516179]]\n"
     ]
    }
   ],
   "source": [
    "compressed_dataset_X_train= pcaTrain.transform(X_train) # --transform-- the original \"dataset\" Dataframe into a lower-dimensional space based on the model's learned parameters\n",
    "print(type(compressed_dataset_X_train))\n",
    "print(len(compressed_dataset_X_train))\n",
    "print(compressed_dataset_X_train)\n",
    "\n",
    "compressed_dataset_X_test= pcaTrain.transform(X_test) # --transform-- the original \"dataset\" Dataframe into a lower-dimensional space based on the model's learned parameters\n",
    "print(type(compressed_dataset_X_test))\n",
    "print(len(compressed_dataset_X_test))\n",
    "print(compressed_dataset_X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tune D tree for Ada-boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(max_depth=12, max_features=&#x27;sqrt&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;DecisionTreeClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.tree.DecisionTreeClassifier.html\">?<span>Documentation for DecisionTreeClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>DecisionTreeClassifier(max_depth=12, max_features=&#x27;sqrt&#x27;)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier(max_depth=12, max_features='sqrt')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "params_dt = {'max_depth': 12,    \n",
    "             'max_features': \"sqrt\"}\n",
    "\n",
    "model_dt = DecisionTreeClassifier(**params_dt)\n",
    "\n",
    "model_dt.fit(compressed_dataset_X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.21621621621621623"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finding mean absolute error\n",
    "preds = model_dt.predict(compressed_dataset_X_test)\n",
    "preds = preds.astype(int)\n",
    "mae = np.abs(y_test-preds).mean()\n",
    "mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the best parameter with optuna\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "K = 5 # stratified 5 fold cross validation, The folds are made by preserving the percentage of samples for each class.\n",
    "skf = StratifiedKFold(n_splits = K, random_state = 42, shuffle = True)\n",
    "\n",
    "\n",
    "train_tunned_dt = np.array(compressed_dataset_X)\n",
    "target_train_tunned_dt = np.array(label)\n",
    "\n",
    "oof_preds_dt = np.zeros((len(train_tunned_dt)))\n",
    "abs_error_arr_dt=[]\n",
    "def objective(trial):\n",
    "\n",
    " for train_index, val_index in (skf.split(compressed_dataset_X,label)):\n",
    "    train_X, valid_X = train_tunned_dt[train_index], train_tunned_dt[val_index]\n",
    "    train_Y, valid_Y = target_train_tunned_dt[train_index], target_train_tunned_dt[val_index]\n",
    "    \n",
    "        \n",
    "        # train_x, test_x, train_y, test_y = train_test_split(data, target, test_size=0.25,random_state=0)\n",
    "    param = {\n",
    "        'criterion':trial.suggest_categorical('criterion',[\"gini\", \"entropy\", \"log_loss\"]), #The function to measure the quality of a split.\n",
    "        'splitter':trial.suggest_categorical('splitter',[\"best\", \"random\"]),\n",
    "        'max_features':trial.suggest_categorical('max_features',['sqrt','log2',1,2,3,4,5,6,7,8,9,10,11]), #a categorical value can be an integer\n",
    "        'random_state':trial.suggest_int('random_state',0,5),\n",
    "\n",
    "\n",
    "        }\n",
    "    model = DecisionTreeClassifier(**param)  \n",
    "        \n",
    "    model.fit(train_X,train_Y)\n",
    "        \n",
    "    preds = model.predict(valid_X)\n",
    "    oof_preds_dt[val_index] = preds # preds gives total 3846 predicted value for valid_X\n",
    "\n",
    "\n",
    " \n",
    "#  print(len(oof_preds_dt))\n",
    "      \n",
    " mae = mean_absolute_error(target_train_tunned_dt, oof_preds_dt)\n",
    "        \n",
    " return mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-18 22:33:22,055] A new study created in memory with name: no-name-f5666183-06cd-494e-ae63-11bfedb9df51\n"
     ]
    }
   ],
   "source": [
    "# this is the main optuna for optimizing a object-->\"objective\"\n",
    "study = optuna.create_study(direction='minimize')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-18 22:33:22,087] Trial 0 finished with value: 0.14814814814814814 and parameters: {'criterion': 'entropy', 'splitter': 'random', 'max_features': 11, 'random_state': 2}. Best is trial 0 with value: 0.14814814814814814.\n",
      "[I 2024-02-18 22:33:22,109] Trial 1 finished with value: 0.1282051282051282 and parameters: {'criterion': 'gini', 'splitter': 'random', 'max_features': 6, 'random_state': 5}. Best is trial 1 with value: 0.1282051282051282.\n",
      "[I 2024-02-18 22:33:22,136] Trial 2 finished with value: 0.11396011396011396 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'log2', 'random_state': 3}. Best is trial 2 with value: 0.11396011396011396.\n",
      "[I 2024-02-18 22:33:22,165] Trial 3 finished with value: 0.1396011396011396 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 6, 'random_state': 2}. Best is trial 2 with value: 0.11396011396011396.\n",
      "[I 2024-02-18 22:33:22,187] Trial 4 finished with value: 0.1225071225071225 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'sqrt', 'random_state': 2}. Best is trial 2 with value: 0.11396011396011396.\n",
      "[I 2024-02-18 22:33:22,218] Trial 5 finished with value: 0.15384615384615385 and parameters: {'criterion': 'entropy', 'splitter': 'random', 'max_features': 7, 'random_state': 5}. Best is trial 2 with value: 0.11396011396011396.\n",
      "[I 2024-02-18 22:33:22,243] Trial 6 finished with value: 0.13105413105413105 and parameters: {'criterion': 'entropy', 'splitter': 'random', 'max_features': 10, 'random_state': 4}. Best is trial 2 with value: 0.11396011396011396.\n",
      "[I 2024-02-18 22:33:22,280] Trial 7 finished with value: 0.13105413105413105 and parameters: {'criterion': 'log_loss', 'splitter': 'best', 'max_features': 5, 'random_state': 0}. Best is trial 2 with value: 0.11396011396011396.\n",
      "[I 2024-02-18 22:33:22,300] Trial 8 finished with value: 0.14814814814814814 and parameters: {'criterion': 'log_loss', 'splitter': 'random', 'max_features': 11, 'random_state': 2}. Best is trial 2 with value: 0.11396011396011396.\n",
      "[I 2024-02-18 22:33:22,340] Trial 9 finished with value: 0.13675213675213677 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 8, 'random_state': 1}. Best is trial 2 with value: 0.11396011396011396.\n",
      "[I 2024-02-18 22:33:22,398] Trial 10 finished with value: 0.10541310541310542 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 9, 'random_state': 4}. Best is trial 10 with value: 0.10541310541310542.\n",
      "[I 2024-02-18 22:33:22,440] Trial 11 finished with value: 0.1111111111111111 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'log2', 'random_state': 4}. Best is trial 10 with value: 0.10541310541310542.\n",
      "[I 2024-02-18 22:33:22,495] Trial 12 finished with value: 0.10541310541310542 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 9, 'random_state': 4}. Best is trial 10 with value: 0.10541310541310542.\n",
      "[I 2024-02-18 22:33:22,546] Trial 13 finished with value: 0.10541310541310542 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 9, 'random_state': 4}. Best is trial 10 with value: 0.10541310541310542.\n",
      "[I 2024-02-18 22:33:22,603] Trial 14 finished with value: 0.150997150997151 and parameters: {'criterion': 'log_loss', 'splitter': 'best', 'max_features': 9, 'random_state': 3}. Best is trial 10 with value: 0.10541310541310542.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-18 22:33:22,643] Trial 15 finished with value: 0.1111111111111111 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 4, 'random_state': 4}. Best is trial 10 with value: 0.10541310541310542.\n",
      "[I 2024-02-18 22:33:22,676] Trial 16 finished with value: 0.14245014245014245 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 1, 'random_state': 5}. Best is trial 10 with value: 0.10541310541310542.\n",
      "[I 2024-02-18 22:33:22,742] Trial 17 finished with value: 0.13675213675213677 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 2, 'random_state': 3}. Best is trial 10 with value: 0.10541310541310542.\n",
      "[I 2024-02-18 22:33:22,832] Trial 18 finished with value: 0.14245014245014245 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 9, 'random_state': 4}. Best is trial 10 with value: 0.10541310541310542.\n",
      "[I 2024-02-18 22:33:22,932] Trial 19 finished with value: 0.1339031339031339 and parameters: {'criterion': 'log_loss', 'splitter': 'best', 'max_features': 9, 'random_state': 5}. Best is trial 10 with value: 0.10541310541310542.\n",
      "[I 2024-02-18 22:33:22,993] Trial 20 finished with value: 0.1282051282051282 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 3, 'random_state': 3}. Best is trial 10 with value: 0.10541310541310542.\n",
      "[I 2024-02-18 22:33:23,084] Trial 21 finished with value: 0.10541310541310542 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 9, 'random_state': 4}. Best is trial 10 with value: 0.10541310541310542.\n",
      "[I 2024-02-18 22:33:23,149] Trial 22 finished with value: 0.10541310541310542 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 9, 'random_state': 4}. Best is trial 10 with value: 0.10541310541310542.\n",
      "[I 2024-02-18 22:33:23,209] Trial 23 finished with value: 0.1452991452991453 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 9, 'random_state': 3}. Best is trial 10 with value: 0.10541310541310542.\n",
      "[I 2024-02-18 22:33:23,259] Trial 24 finished with value: 0.150997150997151 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 9, 'random_state': 5}. Best is trial 10 with value: 0.10541310541310542.\n",
      "[I 2024-02-18 22:33:23,288] Trial 25 finished with value: 0.1111111111111111 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'sqrt', 'random_state': 4}. Best is trial 10 with value: 0.10541310541310542.\n",
      "[I 2024-02-18 22:33:23,315] Trial 26 finished with value: 0.15669515669515668 and parameters: {'criterion': 'gini', 'splitter': 'random', 'max_features': 3, 'random_state': 4}. Best is trial 10 with value: 0.10541310541310542.\n",
      "[I 2024-02-18 22:33:23,378] Trial 27 finished with value: 0.1225071225071225 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 7, 'random_state': 3}. Best is trial 10 with value: 0.10541310541310542.\n",
      "[I 2024-02-18 22:33:23,429] Trial 28 finished with value: 0.150997150997151 and parameters: {'criterion': 'log_loss', 'splitter': 'best', 'max_features': 5, 'random_state': 1}. Best is trial 10 with value: 0.10541310541310542.\n",
      "[I 2024-02-18 22:33:23,466] Trial 29 finished with value: 0.150997150997151 and parameters: {'criterion': 'entropy', 'splitter': 'random', 'max_features': 4, 'random_state': 5}. Best is trial 10 with value: 0.10541310541310542.\n",
      "[I 2024-02-18 22:33:23,509] Trial 30 finished with value: 0.12535612535612536 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 8, 'random_state': 1}. Best is trial 10 with value: 0.10541310541310542.\n",
      "[I 2024-02-18 22:33:23,556] Trial 31 finished with value: 0.10541310541310542 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 9, 'random_state': 4}. Best is trial 10 with value: 0.10541310541310542.\n",
      "[I 2024-02-18 22:33:23,592] Trial 32 finished with value: 0.10541310541310542 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 9, 'random_state': 4}. Best is trial 10 with value: 0.10541310541310542.\n",
      "[I 2024-02-18 22:33:23,631] Trial 33 finished with value: 0.150997150997151 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 9, 'random_state': 5}. Best is trial 10 with value: 0.10541310541310542.\n",
      "[I 2024-02-18 22:33:23,675] Trial 34 finished with value: 0.1168091168091168 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 10, 'random_state': 3}. Best is trial 10 with value: 0.10541310541310542.\n",
      "[I 2024-02-18 22:33:23,726] Trial 35 finished with value: 0.16524216524216523 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 6, 'random_state': 4}. Best is trial 10 with value: 0.10541310541310542.\n",
      "[I 2024-02-18 22:33:23,769] Trial 36 finished with value: 0.1168091168091168 and parameters: {'criterion': 'gini', 'splitter': 'random', 'max_features': 2, 'random_state': 5}. Best is trial 10 with value: 0.10541310541310542.\n",
      "[I 2024-02-18 22:33:23,802] Trial 37 finished with value: 0.150997150997151 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 1, 'random_state': 3}. Best is trial 10 with value: 0.10541310541310542.\n",
      "[I 2024-02-18 22:33:23,852] Trial 38 finished with value: 0.13675213675213677 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 11, 'random_state': 4}. Best is trial 10 with value: 0.10541310541310542.\n",
      "[I 2024-02-18 22:33:23,872] Trial 39 finished with value: 0.15954415954415954 and parameters: {'criterion': 'entropy', 'splitter': 'random', 'max_features': 9, 'random_state': 2}. Best is trial 10 with value: 0.10541310541310542.\n",
      "[I 2024-02-18 22:33:23,902] Trial 40 finished with value: 0.10541310541310542 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'log2', 'random_state': 5}. Best is trial 10 with value: 0.10541310541310542.\n",
      "[I 2024-02-18 22:33:23,934] Trial 41 finished with value: 0.10541310541310542 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 9, 'random_state': 4}. Best is trial 10 with value: 0.10541310541310542.\n",
      "[I 2024-02-18 22:33:23,964] Trial 42 finished with value: 0.10541310541310542 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 9, 'random_state': 4}. Best is trial 10 with value: 0.10541310541310542.\n",
      "[I 2024-02-18 22:33:24,004] Trial 43 finished with value: 0.10541310541310542 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 9, 'random_state': 4}. Best is trial 10 with value: 0.10541310541310542.\n",
      "[I 2024-02-18 22:33:24,025] Trial 44 finished with value: 0.11396011396011396 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'sqrt', 'random_state': 3}. Best is trial 10 with value: 0.10541310541310542.\n",
      "[I 2024-02-18 22:33:24,055] Trial 45 finished with value: 0.1282051282051282 and parameters: {'criterion': 'log_loss', 'splitter': 'best', 'max_features': 6, 'random_state': 4}. Best is trial 10 with value: 0.10541310541310542.\n",
      "[I 2024-02-18 22:33:24,097] Trial 46 finished with value: 0.1168091168091168 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 9, 'random_state': 0}. Best is trial 10 with value: 0.10541310541310542.\n",
      "[I 2024-02-18 22:33:24,127] Trial 47 finished with value: 0.13675213675213677 and parameters: {'criterion': 'gini', 'splitter': 'random', 'max_features': 10, 'random_state': 4}. Best is trial 10 with value: 0.10541310541310542.\n",
      "[I 2024-02-18 22:33:24,174] Trial 48 finished with value: 0.15384615384615385 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 7, 'random_state': 5}. Best is trial 10 with value: 0.10541310541310542.\n",
      "[I 2024-02-18 22:33:24,217] Trial 49 finished with value: 0.13105413105413105 and parameters: {'criterion': 'log_loss', 'splitter': 'best', 'max_features': 5, 'random_state': 3}. Best is trial 10 with value: 0.10541310541310542.\n",
      "[I 2024-02-18 22:33:24,259] Trial 50 finished with value: 0.14245014245014245 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 9, 'random_state': 4}. Best is trial 10 with value: 0.10541310541310542.\n",
      "[I 2024-02-18 22:33:24,307] Trial 51 finished with value: 0.10541310541310542 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 9, 'random_state': 4}. Best is trial 10 with value: 0.10541310541310542.\n",
      "[I 2024-02-18 22:33:24,336] Trial 52 finished with value: 0.10541310541310542 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 9, 'random_state': 4}. Best is trial 10 with value: 0.10541310541310542.\n",
      "[I 2024-02-18 22:33:24,375] Trial 53 finished with value: 0.10541310541310542 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 9, 'random_state': 4}. Best is trial 10 with value: 0.10541310541310542.\n",
      "[I 2024-02-18 22:33:24,411] Trial 54 finished with value: 0.13675213675213677 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 11, 'random_state': 4}. Best is trial 10 with value: 0.10541310541310542.\n",
      "[I 2024-02-18 22:33:24,442] Trial 55 finished with value: 0.13105413105413105 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 8, 'random_state': 5}. Best is trial 10 with value: 0.10541310541310542.\n",
      "[I 2024-02-18 22:33:24,476] Trial 56 finished with value: 0.13105413105413105 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 9, 'random_state': 2}. Best is trial 10 with value: 0.10541310541310542.\n",
      "[I 2024-02-18 22:33:24,496] Trial 57 finished with value: 0.11396011396011396 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 4, 'random_state': 3}. Best is trial 10 with value: 0.10541310541310542.\n",
      "[I 2024-02-18 22:33:24,534] Trial 58 finished with value: 0.150997150997151 and parameters: {'criterion': 'gini', 'splitter': 'random', 'max_features': 3, 'random_state': 5}. Best is trial 10 with value: 0.10541310541310542.\n",
      "[I 2024-02-18 22:33:24,573] Trial 59 finished with value: 0.1168091168091168 and parameters: {'criterion': 'log_loss', 'splitter': 'best', 'max_features': 'log2', 'random_state': 4}. Best is trial 10 with value: 0.10541310541310542.\n",
      "[I 2024-02-18 22:33:24,615] Trial 60 finished with value: 0.150997150997151 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 1, 'random_state': 3}. Best is trial 10 with value: 0.10541310541310542.\n",
      "[I 2024-02-18 22:33:24,653] Trial 61 finished with value: 0.10541310541310542 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 9, 'random_state': 4}. Best is trial 10 with value: 0.10541310541310542.\n",
      "[I 2024-02-18 22:33:24,702] Trial 62 finished with value: 0.10541310541310542 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 9, 'random_state': 4}. Best is trial 10 with value: 0.10541310541310542.\n",
      "[I 2024-02-18 22:33:24,729] Trial 63 finished with value: 0.10541310541310542 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 9, 'random_state': 4}. Best is trial 10 with value: 0.10541310541310542.\n",
      "[I 2024-02-18 22:33:24,759] Trial 64 finished with value: 0.1282051282051282 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 2, 'random_state': 4}. Best is trial 10 with value: 0.10541310541310542.\n",
      "[I 2024-02-18 22:33:24,797] Trial 65 finished with value: 0.150997150997151 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 9, 'random_state': 5}. Best is trial 10 with value: 0.10541310541310542.\n",
      "[I 2024-02-18 22:33:24,847] Trial 66 finished with value: 0.150997150997151 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 9, 'random_state': 3}. Best is trial 10 with value: 0.10541310541310542.\n",
      "[I 2024-02-18 22:33:24,880] Trial 67 finished with value: 0.10541310541310542 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 9, 'random_state': 4}. Best is trial 10 with value: 0.10541310541310542.\n",
      "[I 2024-02-18 22:33:24,910] Trial 68 finished with value: 0.1111111111111111 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'sqrt', 'random_state': 4}. Best is trial 10 with value: 0.10541310541310542.\n",
      "[I 2024-02-18 22:33:24,930] Trial 69 finished with value: 0.1111111111111111 and parameters: {'criterion': 'gini', 'splitter': 'random', 'max_features': 9, 'random_state': 3}. Best is trial 10 with value: 0.10541310541310542.\n",
      "[I 2024-02-18 22:33:24,963] Trial 70 finished with value: 0.15384615384615385 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 7, 'random_state': 5}. Best is trial 10 with value: 0.10541310541310542.\n",
      "[I 2024-02-18 22:33:24,991] Trial 71 finished with value: 0.10541310541310542 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'log2', 'random_state': 5}. Best is trial 10 with value: 0.10541310541310542.\n",
      "[I 2024-02-18 22:33:25,021] Trial 72 finished with value: 0.10541310541310542 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'log2', 'random_state': 5}. Best is trial 10 with value: 0.10541310541310542.\n",
      "[I 2024-02-18 22:33:25,051] Trial 73 finished with value: 0.15954415954415954 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 5, 'random_state': 4}. Best is trial 10 with value: 0.10541310541310542.\n",
      "[I 2024-02-18 22:33:25,081] Trial 74 finished with value: 0.10541310541310542 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'log2', 'random_state': 5}. Best is trial 10 with value: 0.10541310541310542.\n",
      "[I 2024-02-18 22:33:25,129] Trial 75 finished with value: 0.13675213675213677 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 10, 'random_state': 4}. Best is trial 10 with value: 0.10541310541310542.\n",
      "[I 2024-02-18 22:33:25,176] Trial 76 finished with value: 0.1282051282051282 and parameters: {'criterion': 'log_loss', 'splitter': 'best', 'max_features': 6, 'random_state': 4}. Best is trial 10 with value: 0.10541310541310542.\n",
      "[I 2024-02-18 22:33:25,236] Trial 77 finished with value: 0.150997150997151 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 9, 'random_state': 5}. Best is trial 10 with value: 0.10541310541310542.\n",
      "[I 2024-02-18 22:33:25,283] Trial 78 finished with value: 0.12535612535612536 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 8, 'random_state': 4}. Best is trial 10 with value: 0.10541310541310542.\n",
      "[I 2024-02-18 22:33:25,316] Trial 79 finished with value: 0.11396011396011396 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 4, 'random_state': 3}. Best is trial 10 with value: 0.10541310541310542.\n",
      "[I 2024-02-18 22:33:25,337] Trial 80 finished with value: 0.1908831908831909 and parameters: {'criterion': 'gini', 'splitter': 'random', 'max_features': 'log2', 'random_state': 4}. Best is trial 10 with value: 0.10541310541310542.\n",
      "[I 2024-02-18 22:33:25,376] Trial 81 finished with value: 0.1452991452991453 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 9, 'random_state': 1}. Best is trial 10 with value: 0.10541310541310542.\n",
      "[I 2024-02-18 22:33:25,412] Trial 82 finished with value: 0.10541310541310542 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 9, 'random_state': 4}. Best is trial 10 with value: 0.10541310541310542.\n",
      "[I 2024-02-18 22:33:25,442] Trial 83 finished with value: 0.10541310541310542 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 9, 'random_state': 4}. Best is trial 10 with value: 0.10541310541310542.\n",
      "[I 2024-02-18 22:33:25,482] Trial 84 finished with value: 0.10541310541310542 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 9, 'random_state': 4}. Best is trial 10 with value: 0.10541310541310542.\n",
      "[I 2024-02-18 22:33:25,512] Trial 85 finished with value: 0.13675213675213677 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 11, 'random_state': 4}. Best is trial 10 with value: 0.10541310541310542.\n",
      "[I 2024-02-18 22:33:25,541] Trial 86 finished with value: 0.13675213675213677 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 3, 'random_state': 4}. Best is trial 10 with value: 0.10541310541310542.\n",
      "[I 2024-02-18 22:33:25,581] Trial 87 finished with value: 0.150997150997151 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 9, 'random_state': 5}. Best is trial 10 with value: 0.10541310541310542.\n",
      "[I 2024-02-18 22:33:25,601] Trial 88 finished with value: 0.13675213675213677 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 2, 'random_state': 3}. Best is trial 10 with value: 0.10541310541310542.\n",
      "[I 2024-02-18 22:33:25,633] Trial 89 finished with value: 0.14245014245014245 and parameters: {'criterion': 'log_loss', 'splitter': 'best', 'max_features': 9, 'random_state': 4}. Best is trial 10 with value: 0.10541310541310542.\n",
      "[I 2024-02-18 22:33:25,663] Trial 90 finished with value: 0.14245014245014245 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 1, 'random_state': 5}. Best is trial 10 with value: 0.10541310541310542.\n",
      "[I 2024-02-18 22:33:25,707] Trial 91 finished with value: 0.10541310541310542 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 9, 'random_state': 4}. Best is trial 10 with value: 0.10541310541310542.\n",
      "[I 2024-02-18 22:33:25,769] Trial 92 finished with value: 0.10541310541310542 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 9, 'random_state': 4}. Best is trial 10 with value: 0.10541310541310542.\n",
      "[I 2024-02-18 22:33:25,820] Trial 93 finished with value: 0.10541310541310542 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 9, 'random_state': 4}. Best is trial 10 with value: 0.10541310541310542.\n",
      "[I 2024-02-18 22:33:25,859] Trial 94 finished with value: 0.10541310541310542 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 9, 'random_state': 4}. Best is trial 10 with value: 0.10541310541310542.\n",
      "[I 2024-02-18 22:33:25,889] Trial 95 finished with value: 0.10541310541310542 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 9, 'random_state': 4}. Best is trial 10 with value: 0.10541310541310542.\n",
      "[I 2024-02-18 22:33:25,928] Trial 96 finished with value: 0.1168091168091168 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'random_state': 4}. Best is trial 10 with value: 0.10541310541310542.\n",
      "[I 2024-02-18 22:33:25,951] Trial 97 finished with value: 0.1111111111111111 and parameters: {'criterion': 'gini', 'splitter': 'random', 'max_features': 9, 'random_state': 3}. Best is trial 10 with value: 0.10541310541310542.\n",
      "[I 2024-02-18 22:33:25,981] Trial 98 finished with value: 0.1396011396011396 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 7, 'random_state': 4}. Best is trial 10 with value: 0.10541310541310542.\n",
      "[I 2024-02-18 22:33:26,023] Trial 99 finished with value: 0.16524216524216523 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 6, 'random_state': 4}. Best is trial 10 with value: 0.10541310541310542.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of finished trials: 100\n",
      "Best trial: {'criterion': 'gini', 'splitter': 'best', 'max_features': 9, 'random_state': 4}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "study.optimize(objective, n_trials=100) # 150 bar \"objective\" object ke trial kore kore dekhbe, here total 5*100=750\n",
    "print('Number of finished trials:', len(study.trials))\n",
    "print('Best trial:', study.best_trial.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "dimensions": [
          {
           "label": "Objective Value",
           "range": [
            0.10541310541310542,
            0.1908831908831909
           ],
           "values": [
            0.14814814814814814,
            0.1282051282051282,
            0.11396011396011396,
            0.1396011396011396,
            0.1225071225071225,
            0.15384615384615385,
            0.13105413105413105,
            0.13105413105413105,
            0.14814814814814814,
            0.13675213675213677,
            0.10541310541310542,
            0.1111111111111111,
            0.10541310541310542,
            0.10541310541310542,
            0.150997150997151,
            0.1111111111111111,
            0.14245014245014245,
            0.13675213675213677,
            0.14245014245014245,
            0.1339031339031339,
            0.1282051282051282,
            0.10541310541310542,
            0.10541310541310542,
            0.1452991452991453,
            0.150997150997151,
            0.1111111111111111,
            0.15669515669515668,
            0.1225071225071225,
            0.150997150997151,
            0.150997150997151,
            0.12535612535612536,
            0.10541310541310542,
            0.10541310541310542,
            0.150997150997151,
            0.1168091168091168,
            0.16524216524216523,
            0.1168091168091168,
            0.150997150997151,
            0.13675213675213677,
            0.15954415954415954,
            0.10541310541310542,
            0.10541310541310542,
            0.10541310541310542,
            0.10541310541310542,
            0.11396011396011396,
            0.1282051282051282,
            0.1168091168091168,
            0.13675213675213677,
            0.15384615384615385,
            0.13105413105413105,
            0.14245014245014245,
            0.10541310541310542,
            0.10541310541310542,
            0.10541310541310542,
            0.13675213675213677,
            0.13105413105413105,
            0.13105413105413105,
            0.11396011396011396,
            0.150997150997151,
            0.1168091168091168,
            0.150997150997151,
            0.10541310541310542,
            0.10541310541310542,
            0.10541310541310542,
            0.1282051282051282,
            0.150997150997151,
            0.150997150997151,
            0.10541310541310542,
            0.1111111111111111,
            0.1111111111111111,
            0.15384615384615385,
            0.10541310541310542,
            0.10541310541310542,
            0.15954415954415954,
            0.10541310541310542,
            0.13675213675213677,
            0.1282051282051282,
            0.150997150997151,
            0.12535612535612536,
            0.11396011396011396,
            0.1908831908831909,
            0.1452991452991453,
            0.10541310541310542,
            0.10541310541310542,
            0.10541310541310542,
            0.13675213675213677,
            0.13675213675213677,
            0.150997150997151,
            0.13675213675213677,
            0.14245014245014245,
            0.14245014245014245,
            0.10541310541310542,
            0.10541310541310542,
            0.10541310541310542,
            0.10541310541310542,
            0.10541310541310542,
            0.1168091168091168,
            0.1111111111111111,
            0.1396011396011396,
            0.16524216524216523
           ]
          },
          {
           "label": "criterion",
           "range": [
            0,
            2
           ],
           "ticktext": [
            "entropy",
            "gini",
            "log_loss"
           ],
           "tickvals": [
            0,
            1,
            2
           ],
           "values": [
            0,
            1,
            1,
            1,
            1,
            0,
            0,
            2,
            2,
            1,
            1,
            1,
            1,
            1,
            2,
            1,
            1,
            1,
            0,
            2,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            2,
            0,
            0,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            0,
            1,
            1,
            1,
            1,
            1,
            2,
            1,
            1,
            1,
            2,
            0,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            2,
            1,
            1,
            1,
            1,
            1,
            1,
            0,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            2,
            1,
            0,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            2,
            1,
            1,
            1,
            1,
            1,
            1,
            0,
            1,
            1,
            1
           ]
          },
          {
           "label": "max_features",
           "range": [
            0,
            12
           ],
           "ticktext": [
            "11",
            "6",
            "log2",
            "sqrt",
            "7",
            "10",
            "5",
            "8",
            "9",
            "4",
            "1",
            "2",
            "3"
           ],
           "tickvals": [
            0,
            1,
            2,
            3,
            4,
            5,
            6,
            7,
            8,
            9,
            10,
            11,
            12
           ],
           "values": [
            0,
            1,
            2,
            1,
            3,
            4,
            5,
            6,
            0,
            7,
            8,
            2,
            8,
            8,
            8,
            9,
            10,
            11,
            8,
            8,
            12,
            8,
            8,
            8,
            8,
            3,
            12,
            4,
            6,
            9,
            7,
            8,
            8,
            8,
            5,
            1,
            11,
            10,
            0,
            8,
            2,
            8,
            8,
            8,
            3,
            1,
            8,
            5,
            4,
            6,
            8,
            8,
            8,
            8,
            0,
            7,
            8,
            9,
            12,
            2,
            10,
            8,
            8,
            8,
            11,
            8,
            8,
            8,
            3,
            8,
            4,
            2,
            2,
            6,
            2,
            5,
            1,
            8,
            7,
            9,
            2,
            8,
            8,
            8,
            8,
            0,
            12,
            8,
            11,
            8,
            10,
            8,
            8,
            8,
            8,
            8,
            3,
            8,
            4,
            1
           ]
          },
          {
           "label": "random_state",
           "range": [
            0,
            5
           ],
           "values": [
            2,
            5,
            3,
            2,
            2,
            5,
            4,
            0,
            2,
            1,
            4,
            4,
            4,
            4,
            3,
            4,
            5,
            3,
            4,
            5,
            3,
            4,
            4,
            3,
            5,
            4,
            4,
            3,
            1,
            5,
            1,
            4,
            4,
            5,
            3,
            4,
            5,
            3,
            4,
            2,
            5,
            4,
            4,
            4,
            3,
            4,
            0,
            4,
            5,
            3,
            4,
            4,
            4,
            4,
            4,
            5,
            2,
            3,
            5,
            4,
            3,
            4,
            4,
            4,
            4,
            5,
            3,
            4,
            4,
            3,
            5,
            5,
            5,
            4,
            5,
            4,
            4,
            5,
            4,
            3,
            4,
            1,
            4,
            4,
            4,
            4,
            4,
            5,
            3,
            4,
            5,
            4,
            4,
            4,
            4,
            4,
            4,
            3,
            4,
            4
           ]
          },
          {
           "label": "splitter",
           "range": [
            0,
            1
           ],
           "ticktext": [
            "random",
            "best"
           ],
           "tickvals": [
            0,
            1
           ],
           "values": [
            0,
            0,
            1,
            1,
            1,
            0,
            0,
            1,
            0,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            0,
            1,
            1,
            0,
            1,
            1,
            1,
            1,
            1,
            1,
            0,
            1,
            1,
            0,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            0,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            0,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            0,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            0,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            0,
            1,
            1
           ]
          }
         ],
         "labelangle": 30,
         "labelside": "bottom",
         "line": {
          "color": [
           0.14814814814814814,
           0.1282051282051282,
           0.11396011396011396,
           0.1396011396011396,
           0.1225071225071225,
           0.15384615384615385,
           0.13105413105413105,
           0.13105413105413105,
           0.14814814814814814,
           0.13675213675213677,
           0.10541310541310542,
           0.1111111111111111,
           0.10541310541310542,
           0.10541310541310542,
           0.150997150997151,
           0.1111111111111111,
           0.14245014245014245,
           0.13675213675213677,
           0.14245014245014245,
           0.1339031339031339,
           0.1282051282051282,
           0.10541310541310542,
           0.10541310541310542,
           0.1452991452991453,
           0.150997150997151,
           0.1111111111111111,
           0.15669515669515668,
           0.1225071225071225,
           0.150997150997151,
           0.150997150997151,
           0.12535612535612536,
           0.10541310541310542,
           0.10541310541310542,
           0.150997150997151,
           0.1168091168091168,
           0.16524216524216523,
           0.1168091168091168,
           0.150997150997151,
           0.13675213675213677,
           0.15954415954415954,
           0.10541310541310542,
           0.10541310541310542,
           0.10541310541310542,
           0.10541310541310542,
           0.11396011396011396,
           0.1282051282051282,
           0.1168091168091168,
           0.13675213675213677,
           0.15384615384615385,
           0.13105413105413105,
           0.14245014245014245,
           0.10541310541310542,
           0.10541310541310542,
           0.10541310541310542,
           0.13675213675213677,
           0.13105413105413105,
           0.13105413105413105,
           0.11396011396011396,
           0.150997150997151,
           0.1168091168091168,
           0.150997150997151,
           0.10541310541310542,
           0.10541310541310542,
           0.10541310541310542,
           0.1282051282051282,
           0.150997150997151,
           0.150997150997151,
           0.10541310541310542,
           0.1111111111111111,
           0.1111111111111111,
           0.15384615384615385,
           0.10541310541310542,
           0.10541310541310542,
           0.15954415954415954,
           0.10541310541310542,
           0.13675213675213677,
           0.1282051282051282,
           0.150997150997151,
           0.12535612535612536,
           0.11396011396011396,
           0.1908831908831909,
           0.1452991452991453,
           0.10541310541310542,
           0.10541310541310542,
           0.10541310541310542,
           0.13675213675213677,
           0.13675213675213677,
           0.150997150997151,
           0.13675213675213677,
           0.14245014245014245,
           0.14245014245014245,
           0.10541310541310542,
           0.10541310541310542,
           0.10541310541310542,
           0.10541310541310542,
           0.10541310541310542,
           0.1168091168091168,
           0.1111111111111111,
           0.1396011396011396,
           0.16524216524216523
          ],
          "colorbar": {
           "title": {
            "text": "Objective Value"
           }
          },
          "colorscale": [
           [
            0,
            "rgb(247,251,255)"
           ],
           [
            0.125,
            "rgb(222,235,247)"
           ],
           [
            0.25,
            "rgb(198,219,239)"
           ],
           [
            0.375,
            "rgb(158,202,225)"
           ],
           [
            0.5,
            "rgb(107,174,214)"
           ],
           [
            0.625,
            "rgb(66,146,198)"
           ],
           [
            0.75,
            "rgb(33,113,181)"
           ],
           [
            0.875,
            "rgb(8,81,156)"
           ],
           [
            1,
            "rgb(8,48,107)"
           ]
          ],
          "reversescale": true,
          "showscale": true
         },
         "type": "parcoords"
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Parallel Coordinate Plot"
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "fig_study = optuna.visualization.plot_parallel_coordinate(study, params=[\"criterion\", \"splitter\",\"max_features\",\"random_state\"])\n",
    "fig_study.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of finished trials:  100\n",
      "Best trial:\n",
      "  Value:  0.10541310541310542\n",
      "  Params: \n",
      "    criterion: gini\n",
      "    splitter: best\n",
      "    max_features: 9\n",
      "    random_state: 4\n"
     ]
    }
   ],
   "source": [
    "#evaluate the trial\n",
    "print(\"Number of finished trials: \", len(study.trials))\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "print(\"  Value: \", trial.value)\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(\"    {}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tune Adaboost classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>AdaBoostClassifier(algorithm=&#x27;SAMME&#x27;,\n",
       "                   estimator=DecisionTreeClassifier(max_features=9,\n",
       "                                                    random_state=4),\n",
       "                   learning_rate=1.2, n_estimators=180)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;AdaBoostClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.ensemble.AdaBoostClassifier.html\">?<span>Documentation for AdaBoostClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>AdaBoostClassifier(algorithm=&#x27;SAMME&#x27;,\n",
       "                   estimator=DecisionTreeClassifier(max_features=9,\n",
       "                                                    random_state=4),\n",
       "                   learning_rate=1.2, n_estimators=180)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">estimator: DecisionTreeClassifier</label><div class=\"sk-toggleable__content fitted\"><pre>DecisionTreeClassifier(max_features=9, random_state=4)</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;DecisionTreeClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.tree.DecisionTreeClassifier.html\">?<span>Documentation for DecisionTreeClassifier</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>DecisionTreeClassifier(max_features=9, random_state=4)</pre></div> </div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME',\n",
       "                   estimator=DecisionTreeClassifier(max_features=9,\n",
       "                                                    random_state=4),\n",
       "                   learning_rate=1.2, n_estimators=180)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the model with random parameter\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "# Preparing the regressor and fitting data with some parameters\n",
    "dt_params = study.best_trial.params\n",
    "model_dt = DecisionTreeClassifier(**dt_params)\n",
    "#model_dt = estimator\n",
    "#model = predictor = model_dt.fit()\n",
    "\n",
    "model_Ada = AdaBoostClassifier(\n",
    "        estimator=model_dt,\n",
    "        n_estimators=180, # maximum number of estimators at which boosting is terminated\n",
    "        learning_rate=1.2,\n",
    "        algorithm=\"SAMME\", #SAMME.R=real boosting algorithm\n",
    "        \n",
    "     )\n",
    "\n",
    "model_Ada.fit(compressed_dataset_X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16216216216216217"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finding mean absolute error\n",
    "preds = model_Ada.predict(compressed_dataset_X_test)\n",
    "preds = preds.astype(int)\n",
    "mae = np.abs(y_test-preds).mean()\n",
    "mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the best parameter with optuna\n",
    "\n",
    "K = 5 # 5 fold cross validation\n",
    "skf = StratifiedKFold(n_splits = K, random_state = 42, shuffle = True)\n",
    "\n",
    "\n",
    "train_tunned_Ada= np.array(compressed_dataset_X)\n",
    "target_train_tunned_Ada = np.array(label)\n",
    "\n",
    "# test = np.array(X)\n",
    "# target_train = df_train['congestion'].values\n",
    "\n",
    "# test_preds = np.zeros((len(test)))\n",
    "oof_preds_Ada = np.zeros((len(train_tunned_Ada)))\n",
    "abs_error_arr_Ada=[]\n",
    "def objective_Ada(trial):\n",
    "\n",
    " for train_index, val_index in (skf.split(compressed_dataset_X,label)):\n",
    "    train_X, valid_X = train_tunned_Ada[train_index], train_tunned_Ada[val_index]\n",
    "    train_Y, valid_Y = target_train_tunned_Ada[train_index], target_train_tunned_Ada[val_index]\n",
    "    \n",
    "        \n",
    "        # train_x, test_x, train_y, test_y = train_test_split(data, target, test_size=0.25,random_state=0)\n",
    "    param = {\n",
    "            # 'tree_method':'gpu_hist',  # this parameter means using the GPU when training our model to speedup the training process \n",
    "        'estimator':model_dt,\n",
    "        'n_estimators':trial.suggest_int(\"n_estimators\",50,500), # maximum number of estimators at which boosting is terminated\n",
    "        'learning_rate':trial.suggest_float(\"learning_rate\",1,3),\n",
    "        'algorithm':trial.suggest_categorical(\"algorithm\",[\"SAMME\",\"SAMME.R\"]),\n",
    "        'random_state':trial.suggest_int('random_state',0,5),\n",
    "        }\n",
    "    model_2 = AdaBoostClassifier(**param)  \n",
    "        \n",
    "    model_2.fit(train_X,train_Y)\n",
    "        \n",
    "    preds = model_2.predict(valid_X)\n",
    "    oof_preds_Ada[val_index] = preds # preds gives total 3846 predicted value for valid_X\n",
    "\n",
    "#  abs_error=np.abs(oof_preds-target_train_tunned).mean() \n",
    "#  abs_error_arr.append(abs_error)  \n",
    "#  abs_error=np.abs(oof_preds-target_train).mean()\n",
    " \n",
    "#  print(len(oof_preds))\n",
    "      \n",
    " mae = mean_absolute_error(target_train_tunned_Ada, oof_preds_Ada)\n",
    "        \n",
    " return mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-18 22:33:26,836] A new study created in memory with name: Ada_tunning\n"
     ]
    }
   ],
   "source": [
    "# this is the main optuna for optimizing a object-->\"objective\"\n",
    "study_Ada = optuna.create_study(direction='minimize',study_name=\"Ada_tunning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning:\n",
      "\n",
      "The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "\n",
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning:\n",
      "\n",
      "The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "\n",
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning:\n",
      "\n",
      "The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "\n",
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning:\n",
      "\n",
      "The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "\n",
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning:\n",
      "\n",
      "The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "\n",
      "[I 2024-02-18 22:33:26,906] Trial 0 finished with value: 0.11396011396011396 and parameters: {'n_estimators': 492, 'learning_rate': 1.4181100555797042, 'algorithm': 'SAMME.R', 'random_state': 0}. Best is trial 0 with value: 0.11396011396011396.\n",
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning:\n",
      "\n",
      "The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "\n",
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning:\n",
      "\n",
      "The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "\n",
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning:\n",
      "\n",
      "The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "\n",
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning:\n",
      "\n",
      "The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "\n",
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning:\n",
      "\n",
      "The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "\n",
      "[I 2024-02-18 22:33:26,950] Trial 1 finished with value: 0.1225071225071225 and parameters: {'n_estimators': 369, 'learning_rate': 2.3058664813194323, 'algorithm': 'SAMME.R', 'random_state': 3}. Best is trial 0 with value: 0.11396011396011396.\n",
      "[I 2024-02-18 22:33:26,996] Trial 2 finished with value: 0.14245014245014245 and parameters: {'n_estimators': 288, 'learning_rate': 1.114558762325345, 'algorithm': 'SAMME', 'random_state': 2}. Best is trial 0 with value: 0.11396011396011396.\n",
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning:\n",
      "\n",
      "The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "\n",
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning:\n",
      "\n",
      "The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "\n",
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning:\n",
      "\n",
      "The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "\n",
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning:\n",
      "\n",
      "The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "\n",
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning:\n",
      "\n",
      "The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "\n",
      "[I 2024-02-18 22:33:27,032] Trial 3 finished with value: 0.12535612535612536 and parameters: {'n_estimators': 433, 'learning_rate': 2.2387392646727804, 'algorithm': 'SAMME.R', 'random_state': 1}. Best is trial 0 with value: 0.11396011396011396.\n",
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning:\n",
      "\n",
      "The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "\n",
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning:\n",
      "\n",
      "The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "\n",
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning:\n",
      "\n",
      "The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "\n",
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning:\n",
      "\n",
      "The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "\n",
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning:\n",
      "\n",
      "The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "\n",
      "[I 2024-02-18 22:33:27,064] Trial 4 finished with value: 0.1396011396011396 and parameters: {'n_estimators': 83, 'learning_rate': 2.381377585207958, 'algorithm': 'SAMME.R', 'random_state': 5}. Best is trial 0 with value: 0.11396011396011396.\n",
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning:\n",
      "\n",
      "The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "\n",
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning:\n",
      "\n",
      "The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "\n",
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning:\n",
      "\n",
      "The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "\n",
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning:\n",
      "\n",
      "The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "\n",
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning:\n",
      "\n",
      "The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "\n",
      "[I 2024-02-18 22:33:27,119] Trial 5 finished with value: 0.12535612535612536 and parameters: {'n_estimators': 437, 'learning_rate': 1.7342984400951023, 'algorithm': 'SAMME.R', 'random_state': 1}. Best is trial 0 with value: 0.11396011396011396.\n",
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning:\n",
      "\n",
      "The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "\n",
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning:\n",
      "\n",
      "The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "\n",
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning:\n",
      "\n",
      "The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "\n",
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning:\n",
      "\n",
      "The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "\n",
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning:\n",
      "\n",
      "The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "\n",
      "[I 2024-02-18 22:33:27,155] Trial 6 finished with value: 0.1225071225071225 and parameters: {'n_estimators': 281, 'learning_rate': 2.3211414031320894, 'algorithm': 'SAMME.R', 'random_state': 3}. Best is trial 0 with value: 0.11396011396011396.\n",
      "[I 2024-02-18 22:33:27,196] Trial 7 finished with value: 0.14245014245014245 and parameters: {'n_estimators': 402, 'learning_rate': 1.4058016391112529, 'algorithm': 'SAMME', 'random_state': 2}. Best is trial 0 with value: 0.11396011396011396.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning:\n",
      "\n",
      "The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "\n",
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning:\n",
      "\n",
      "The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "\n",
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning:\n",
      "\n",
      "The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "\n",
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning:\n",
      "\n",
      "The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "\n",
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning:\n",
      "\n",
      "The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "\n",
      "[I 2024-02-18 22:33:27,287] Trial 8 finished with value: 0.14245014245014245 and parameters: {'n_estimators': 246, 'learning_rate': 1.145491521104714, 'algorithm': 'SAMME.R', 'random_state': 2}. Best is trial 0 with value: 0.11396011396011396.\n",
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning:\n",
      "\n",
      "The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "\n",
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning:\n",
      "\n",
      "The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "\n",
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning:\n",
      "\n",
      "The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "\n",
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning:\n",
      "\n",
      "The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "\n",
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning:\n",
      "\n",
      "The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "\n",
      "[I 2024-02-18 22:33:27,420] Trial 9 finished with value: 0.16809116809116809 and parameters: {'n_estimators': 497, 'learning_rate': 2.387229511316181, 'algorithm': 'SAMME.R', 'random_state': 4}. Best is trial 0 with value: 0.11396011396011396.\n",
      "[I 2024-02-18 22:33:27,596] Trial 10 finished with value: 0.11396011396011396 and parameters: {'n_estimators': 141, 'learning_rate': 1.774336147360879, 'algorithm': 'SAMME', 'random_state': 0}. Best is trial 0 with value: 0.11396011396011396.\n",
      "[I 2024-02-18 22:33:27,707] Trial 11 finished with value: 0.11396011396011396 and parameters: {'n_estimators': 112, 'learning_rate': 1.8593750321939577, 'algorithm': 'SAMME', 'random_state': 0}. Best is trial 0 with value: 0.11396011396011396.\n",
      "[I 2024-02-18 22:33:27,777] Trial 12 finished with value: 0.11396011396011396 and parameters: {'n_estimators': 176, 'learning_rate': 1.5640692182492093, 'algorithm': 'SAMME', 'random_state': 0}. Best is trial 0 with value: 0.11396011396011396.\n",
      "[I 2024-02-18 22:33:27,864] Trial 13 finished with value: 0.11396011396011396 and parameters: {'n_estimators': 195, 'learning_rate': 2.8437418740469225, 'algorithm': 'SAMME', 'random_state': 0}. Best is trial 0 with value: 0.11396011396011396.\n",
      "[I 2024-02-18 22:33:27,925] Trial 14 finished with value: 0.12535612535612536 and parameters: {'n_estimators': 333, 'learning_rate': 1.443666775618988, 'algorithm': 'SAMME', 'random_state': 1}. Best is trial 0 with value: 0.11396011396011396.\n",
      "[I 2024-02-18 22:33:27,999] Trial 15 finished with value: 0.11396011396011396 and parameters: {'n_estimators': 51, 'learning_rate': 2.0082212381218367, 'algorithm': 'SAMME', 'random_state': 0}. Best is trial 0 with value: 0.11396011396011396.\n",
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning:\n",
      "\n",
      "The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "\n",
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning:\n",
      "\n",
      "The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "\n",
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning:\n",
      "\n",
      "The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "\n",
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning:\n",
      "\n",
      "The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "\n",
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning:\n",
      "\n",
      "The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "\n",
      "[I 2024-02-18 22:33:28,090] Trial 16 finished with value: 0.11396011396011396 and parameters: {'n_estimators': 155, 'learning_rate': 1.0110815902513468, 'algorithm': 'SAMME.R', 'random_state': 0}. Best is trial 0 with value: 0.11396011396011396.\n",
      "[I 2024-02-18 22:33:28,199] Trial 17 finished with value: 0.12535612535612536 and parameters: {'n_estimators': 496, 'learning_rate': 1.6583845958463903, 'algorithm': 'SAMME', 'random_state': 1}. Best is trial 0 with value: 0.11396011396011396.\n",
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning:\n",
      "\n",
      "The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "\n",
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning:\n",
      "\n",
      "The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "\n",
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning:\n",
      "\n",
      "The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "\n",
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning:\n",
      "\n",
      "The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "\n",
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning:\n",
      "\n",
      "The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "\n",
      "[I 2024-02-18 22:33:28,302] Trial 18 finished with value: 0.12535612535612536 and parameters: {'n_estimators': 223, 'learning_rate': 1.979803911764945, 'algorithm': 'SAMME.R', 'random_state': 1}. Best is trial 0 with value: 0.11396011396011396.\n",
      "[I 2024-02-18 22:33:28,378] Trial 19 finished with value: 0.16809116809116809 and parameters: {'n_estimators': 129, 'learning_rate': 1.336415767684171, 'algorithm': 'SAMME', 'random_state': 4}. Best is trial 0 with value: 0.11396011396011396.\n",
      "[I 2024-02-18 22:33:28,451] Trial 20 finished with value: 0.11396011396011396 and parameters: {'n_estimators': 328, 'learning_rate': 2.749964380323651, 'algorithm': 'SAMME', 'random_state': 0}. Best is trial 0 with value: 0.11396011396011396.\n",
      "[I 2024-02-18 22:33:28,544] Trial 21 finished with value: 0.11396011396011396 and parameters: {'n_estimators': 106, 'learning_rate': 1.8414370263742859, 'algorithm': 'SAMME', 'random_state': 0}. Best is trial 0 with value: 0.11396011396011396.\n",
      "[I 2024-02-18 22:33:28,625] Trial 22 finished with value: 0.12535612535612536 and parameters: {'n_estimators': 141, 'learning_rate': 1.9416282985467213, 'algorithm': 'SAMME', 'random_state': 1}. Best is trial 0 with value: 0.11396011396011396.\n",
      "[I 2024-02-18 22:33:28,680] Trial 23 finished with value: 0.11396011396011396 and parameters: {'n_estimators': 82, 'learning_rate': 2.1517859626981752, 'algorithm': 'SAMME', 'random_state': 0}. Best is trial 0 with value: 0.11396011396011396.\n",
      "[I 2024-02-18 22:33:28,741] Trial 24 finished with value: 0.11396011396011396 and parameters: {'n_estimators': 216, 'learning_rate': 1.6067147351175661, 'algorithm': 'SAMME', 'random_state': 0}. Best is trial 0 with value: 0.11396011396011396.\n",
      "[I 2024-02-18 22:33:28,790] Trial 25 finished with value: 0.12535612535612536 and parameters: {'n_estimators': 53, 'learning_rate': 1.296496408447632, 'algorithm': 'SAMME', 'random_state': 1}. Best is trial 0 with value: 0.11396011396011396.\n",
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning:\n",
      "\n",
      "The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "\n",
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning:\n",
      "\n",
      "The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "\n",
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning:\n",
      "\n",
      "The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "\n",
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning:\n",
      "\n",
      "The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "\n",
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning:\n",
      "\n",
      "The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "\n",
      "[I 2024-02-18 22:33:28,850] Trial 26 finished with value: 0.14245014245014245 and parameters: {'n_estimators': 169, 'learning_rate': 1.8090327699132707, 'algorithm': 'SAMME.R', 'random_state': 2}. Best is trial 0 with value: 0.11396011396011396.\n",
      "[I 2024-02-18 22:33:28,900] Trial 27 finished with value: 0.11396011396011396 and parameters: {'n_estimators': 116, 'learning_rate': 1.5574344353530751, 'algorithm': 'SAMME', 'random_state': 0}. Best is trial 0 with value: 0.11396011396011396.\n",
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning:\n",
      "\n",
      "The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "\n",
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning:\n",
      "\n",
      "The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "\n",
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning:\n",
      "\n",
      "The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "\n",
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning:\n",
      "\n",
      "The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "\n",
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning:\n",
      "\n",
      "The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "\n",
      "[I 2024-02-18 22:33:28,950] Trial 28 finished with value: 0.12535612535612536 and parameters: {'n_estimators': 243, 'learning_rate': 2.523905776478717, 'algorithm': 'SAMME.R', 'random_state': 1}. Best is trial 0 with value: 0.11396011396011396.\n",
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning:\n",
      "\n",
      "The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "\n",
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning:\n",
      "\n",
      "The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "\n",
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning:\n",
      "\n",
      "The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "\n",
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning:\n",
      "\n",
      "The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "\n",
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning:\n",
      "\n",
      "The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "\n",
      "[I 2024-02-18 22:33:29,000] Trial 29 finished with value: 0.1225071225071225 and parameters: {'n_estimators': 330, 'learning_rate': 2.118452212663199, 'algorithm': 'SAMME.R', 'random_state': 3}. Best is trial 0 with value: 0.11396011396011396.\n",
      "[I 2024-02-18 22:33:29,060] Trial 30 finished with value: 0.16809116809116809 and parameters: {'n_estimators': 375, 'learning_rate': 1.8409616936662674, 'algorithm': 'SAMME', 'random_state': 4}. Best is trial 0 with value: 0.11396011396011396.\n",
      "[I 2024-02-18 22:33:29,109] Trial 31 finished with value: 0.11396011396011396 and parameters: {'n_estimators': 182, 'learning_rate': 1.5089449813449576, 'algorithm': 'SAMME', 'random_state': 0}. Best is trial 0 with value: 0.11396011396011396.\n",
      "[I 2024-02-18 22:33:29,159] Trial 32 finished with value: 0.11396011396011396 and parameters: {'n_estimators': 102, 'learning_rate': 1.2458919409587883, 'algorithm': 'SAMME', 'random_state': 0}. Best is trial 0 with value: 0.11396011396011396.\n",
      "[I 2024-02-18 22:33:29,206] Trial 33 finished with value: 0.11396011396011396 and parameters: {'n_estimators': 150, 'learning_rate': 1.6806048068450115, 'algorithm': 'SAMME', 'random_state': 0}. Best is trial 0 with value: 0.11396011396011396.\n",
      "[I 2024-02-18 22:33:29,256] Trial 34 finished with value: 0.12535612535612536 and parameters: {'n_estimators': 200, 'learning_rate': 1.5563630029310471, 'algorithm': 'SAMME', 'random_state': 1}. Best is trial 0 with value: 0.11396011396011396.\n",
      "[I 2024-02-18 22:33:29,308] Trial 35 finished with value: 0.11396011396011396 and parameters: {'n_estimators': 84, 'learning_rate': 1.7581595720825687, 'algorithm': 'SAMME', 'random_state': 0}. Best is trial 0 with value: 0.11396011396011396.\n",
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning:\n",
      "\n",
      "The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "\n",
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning:\n",
      "\n",
      "The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "\n",
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning:\n",
      "\n",
      "The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "\n",
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning:\n",
      "\n",
      "The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "\n",
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning:\n",
      "\n",
      "The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "\n",
      "[I 2024-02-18 22:33:29,358] Trial 36 finished with value: 0.1396011396011396 and parameters: {'n_estimators': 300, 'learning_rate': 1.4248773574959317, 'algorithm': 'SAMME.R', 'random_state': 5}. Best is trial 0 with value: 0.11396011396011396.\n",
      "[I 2024-02-18 22:33:29,417] Trial 37 finished with value: 0.14245014245014245 and parameters: {'n_estimators': 465, 'learning_rate': 1.1792854614262893, 'algorithm': 'SAMME', 'random_state': 2}. Best is trial 0 with value: 0.11396011396011396.\n",
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning:\n",
      "\n",
      "The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "\n",
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning:\n",
      "\n",
      "The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "\n",
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning:\n",
      "\n",
      "The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "\n",
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning:\n",
      "\n",
      "The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "\n",
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning:\n",
      "\n",
      "The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "\n",
      "[I 2024-02-18 22:33:29,458] Trial 38 finished with value: 0.12535612535612536 and parameters: {'n_estimators': 247, 'learning_rate': 1.9087190169001422, 'algorithm': 'SAMME.R', 'random_state': 1}. Best is trial 0 with value: 0.11396011396011396.\n",
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning:\n",
      "\n",
      "The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "\n",
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning:\n",
      "\n",
      "The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "\n",
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning:\n",
      "\n",
      "The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "\n",
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning:\n",
      "\n",
      "The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "\n",
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning:\n",
      "\n",
      "The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "\n",
      "[I 2024-02-18 22:33:29,516] Trial 39 finished with value: 0.12535612535612536 and parameters: {'n_estimators': 421, 'learning_rate': 2.0783042050211824, 'algorithm': 'SAMME.R', 'random_state': 1}. Best is trial 0 with value: 0.11396011396011396.\n",
      "[I 2024-02-18 22:33:29,561] Trial 40 finished with value: 0.11396011396011396 and parameters: {'n_estimators': 159, 'learning_rate': 1.7001639030990972, 'algorithm': 'SAMME', 'random_state': 0}. Best is trial 0 with value: 0.11396011396011396.\n",
      "[I 2024-02-18 22:33:29,614] Trial 41 finished with value: 0.11396011396011396 and parameters: {'n_estimators': 191, 'learning_rate': 2.974178773860559, 'algorithm': 'SAMME', 'random_state': 0}. Best is trial 0 with value: 0.11396011396011396.\n",
      "[I 2024-02-18 22:33:29,662] Trial 42 finished with value: 0.11396011396011396 and parameters: {'n_estimators': 125, 'learning_rate': 2.4984625808382, 'algorithm': 'SAMME', 'random_state': 0}. Best is trial 0 with value: 0.11396011396011396.\n",
      "[I 2024-02-18 22:33:29,713] Trial 43 finished with value: 0.11396011396011396 and parameters: {'n_estimators': 210, 'learning_rate': 2.7892984158350487, 'algorithm': 'SAMME', 'random_state': 0}. Best is trial 0 with value: 0.11396011396011396.\n",
      "[I 2024-02-18 22:33:29,753] Trial 44 finished with value: 0.12535612535612536 and parameters: {'n_estimators': 177, 'learning_rate': 2.240492348230625, 'algorithm': 'SAMME', 'random_state': 1}. Best is trial 0 with value: 0.11396011396011396.\n",
      "[I 2024-02-18 22:33:29,810] Trial 45 finished with value: 0.11396011396011396 and parameters: {'n_estimators': 237, 'learning_rate': 1.4704849133741091, 'algorithm': 'SAMME', 'random_state': 0}. Best is trial 0 with value: 0.11396011396011396.\n",
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning:\n",
      "\n",
      "The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "\n",
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning:\n",
      "\n",
      "The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "\n",
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning:\n",
      "\n",
      "The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "\n",
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning:\n",
      "\n",
      "The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "\n",
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning:\n",
      "\n",
      "The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "\n",
      "[I 2024-02-18 22:33:29,852] Trial 46 finished with value: 0.14245014245014245 and parameters: {'n_estimators': 273, 'learning_rate': 1.3293583915294545, 'algorithm': 'SAMME.R', 'random_state': 2}. Best is trial 0 with value: 0.11396011396011396.\n",
      "[I 2024-02-18 22:33:29,901] Trial 47 finished with value: 0.12535612535612536 and parameters: {'n_estimators': 82, 'learning_rate': 1.6415795125882622, 'algorithm': 'SAMME', 'random_state': 1}. Best is trial 0 with value: 0.11396011396011396.\n",
      "[I 2024-02-18 22:33:29,953] Trial 48 finished with value: 0.11396011396011396 and parameters: {'n_estimators': 374, 'learning_rate': 1.7453597367868672, 'algorithm': 'SAMME', 'random_state': 0}. Best is trial 0 with value: 0.11396011396011396.\n",
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning:\n",
      "\n",
      "The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "\n",
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning:\n",
      "\n",
      "The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "\n",
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning:\n",
      "\n",
      "The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "\n",
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning:\n",
      "\n",
      "The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "\n",
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning:\n",
      "\n",
      "The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "\n",
      "[I 2024-02-18 22:33:30,003] Trial 49 finished with value: 0.12535612535612536 and parameters: {'n_estimators': 144, 'learning_rate': 2.047508780104631, 'algorithm': 'SAMME.R', 'random_state': 1}. Best is trial 0 with value: 0.11396011396011396.\n",
      "[I 2024-02-18 22:33:30,053] Trial 50 finished with value: 0.11396011396011396 and parameters: {'n_estimators': 130, 'learning_rate': 1.1002263888699844, 'algorithm': 'SAMME', 'random_state': 0}. Best is trial 0 with value: 0.11396011396011396.\n",
      "[I 2024-02-18 22:33:30,103] Trial 51 finished with value: 0.11396011396011396 and parameters: {'n_estimators': 51, 'learning_rate': 1.8933281678715026, 'algorithm': 'SAMME', 'random_state': 0}. Best is trial 0 with value: 0.11396011396011396.\n",
      "[I 2024-02-18 22:33:30,160] Trial 52 finished with value: 0.11396011396011396 and parameters: {'n_estimators': 65, 'learning_rate': 1.3908460030299787, 'algorithm': 'SAMME', 'random_state': 0}. Best is trial 0 with value: 0.11396011396011396.\n",
      "[I 2024-02-18 22:33:30,212] Trial 53 finished with value: 0.11396011396011396 and parameters: {'n_estimators': 92, 'learning_rate': 2.7387992205523912, 'algorithm': 'SAMME', 'random_state': 0}. Best is trial 0 with value: 0.11396011396011396.\n",
      "[I 2024-02-18 22:33:30,275] Trial 54 finished with value: 0.11396011396011396 and parameters: {'n_estimators': 109, 'learning_rate': 2.0157715425812026, 'algorithm': 'SAMME', 'random_state': 0}. Best is trial 0 with value: 0.11396011396011396.\n",
      "[I 2024-02-18 22:33:30,325] Trial 55 finished with value: 0.12535612535612536 and parameters: {'n_estimators': 69, 'learning_rate': 1.5961189594181635, 'algorithm': 'SAMME', 'random_state': 1}. Best is trial 0 with value: 0.11396011396011396.\n",
      "[I 2024-02-18 22:33:30,377] Trial 56 finished with value: 0.11396011396011396 and parameters: {'n_estimators': 266, 'learning_rate': 2.385246464969483, 'algorithm': 'SAMME', 'random_state': 0}. Best is trial 0 with value: 0.11396011396011396.\n",
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning:\n",
      "\n",
      "The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "\n",
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning:\n",
      "\n",
      "The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "\n",
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning:\n",
      "\n",
      "The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "\n",
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning:\n",
      "\n",
      "The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "\n",
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning:\n",
      "\n",
      "The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "\n",
      "[I 2024-02-18 22:33:30,427] Trial 57 finished with value: 0.1225071225071225 and parameters: {'n_estimators': 168, 'learning_rate': 2.212766548215724, 'algorithm': 'SAMME.R', 'random_state': 3}. Best is trial 0 with value: 0.11396011396011396.\n",
      "[I 2024-02-18 22:33:30,485] Trial 58 finished with value: 0.12535612535612536 and parameters: {'n_estimators': 304, 'learning_rate': 1.7747078488849795, 'algorithm': 'SAMME', 'random_state': 1}. Best is trial 0 with value: 0.11396011396011396.\n",
      "[I 2024-02-18 22:33:30,541] Trial 59 finished with value: 0.11396011396011396 and parameters: {'n_estimators': 134, 'learning_rate': 2.982866712357873, 'algorithm': 'SAMME', 'random_state': 0}. Best is trial 0 with value: 0.11396011396011396.\n",
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning:\n",
      "\n",
      "The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "\n",
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning:\n",
      "\n",
      "The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "\n",
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning:\n",
      "\n",
      "The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "\n",
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning:\n",
      "\n",
      "The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "\n",
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning:\n",
      "\n",
      "The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "\n",
      "[I 2024-02-18 22:33:30,596] Trial 60 finished with value: 0.11396011396011396 and parameters: {'n_estimators': 468, 'learning_rate': 2.4942601301794878, 'algorithm': 'SAMME.R', 'random_state': 0}. Best is trial 0 with value: 0.11396011396011396.\n",
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning:\n",
      "\n",
      "The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "\n",
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning:\n",
      "\n",
      "The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "\n",
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning:\n",
      "\n",
      "The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "\n",
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning:\n",
      "\n",
      "The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "\n",
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning:\n",
      "\n",
      "The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "\n",
      "[I 2024-02-18 22:33:30,646] Trial 61 finished with value: 0.11396011396011396 and parameters: {'n_estimators': 152, 'learning_rate': 1.2079215996293484, 'algorithm': 'SAMME.R', 'random_state': 0}. Best is trial 0 with value: 0.11396011396011396.\n",
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning:\n",
      "\n",
      "The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "\n",
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning:\n",
      "\n",
      "The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "\n",
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning:\n",
      "\n",
      "The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "\n",
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning:\n",
      "\n",
      "The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "\n",
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning:\n",
      "\n",
      "The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "\n",
      "[I 2024-02-18 22:33:30,704] Trial 62 finished with value: 0.11396011396011396 and parameters: {'n_estimators': 201, 'learning_rate': 1.016682706677418, 'algorithm': 'SAMME.R', 'random_state': 0}. Best is trial 0 with value: 0.11396011396011396.\n",
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning:\n",
      "\n",
      "The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "\n",
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning:\n",
      "\n",
      "The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "\n",
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning:\n",
      "\n",
      "The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "\n",
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning:\n",
      "\n",
      "The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "\n",
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning:\n",
      "\n",
      "The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "\n",
      "[I 2024-02-18 22:33:30,761] Trial 63 finished with value: 0.11396011396011396 and parameters: {'n_estimators': 116, 'learning_rate': 1.0831596363272127, 'algorithm': 'SAMME.R', 'random_state': 0}. Best is trial 0 with value: 0.11396011396011396.\n",
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning:\n",
      "\n",
      "The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "\n",
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning:\n",
      "\n",
      "The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "\n",
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning:\n",
      "\n",
      "The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "\n",
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning:\n",
      "\n",
      "The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "\n",
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning:\n",
      "\n",
      "The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "\n",
      "[I 2024-02-18 22:33:30,811] Trial 64 finished with value: 0.11396011396011396 and parameters: {'n_estimators': 166, 'learning_rate': 1.964313911593234, 'algorithm': 'SAMME.R', 'random_state': 0}. Best is trial 0 with value: 0.11396011396011396.\n",
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning:\n",
      "\n",
      "The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "\n",
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning:\n",
      "\n",
      "The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "\n",
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning:\n",
      "\n",
      "The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "\n",
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning:\n",
      "\n",
      "The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "\n",
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning:\n",
      "\n",
      "The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "\n",
      "[I 2024-02-18 22:33:30,863] Trial 65 finished with value: 0.16809116809116809 and parameters: {'n_estimators': 95, 'learning_rate': 1.5288322997429462, 'algorithm': 'SAMME.R', 'random_state': 4}. Best is trial 0 with value: 0.11396011396011396.\n",
      "[I 2024-02-18 22:33:30,923] Trial 66 finished with value: 0.11396011396011396 and parameters: {'n_estimators': 182, 'learning_rate': 1.8492152387346377, 'algorithm': 'SAMME', 'random_state': 0}. Best is trial 0 with value: 0.11396011396011396.\n",
      "[I 2024-02-18 22:33:30,973] Trial 67 finished with value: 0.12535612535612536 and parameters: {'n_estimators': 219, 'learning_rate': 1.258728805654134, 'algorithm': 'SAMME', 'random_state': 1}. Best is trial 0 with value: 0.11396011396011396.\n",
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning:\n",
      "\n",
      "The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "\n",
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning:\n",
      "\n",
      "The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "\n",
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning:\n",
      "\n",
      "The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "\n",
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning:\n",
      "\n",
      "The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "\n",
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning:\n",
      "\n",
      "The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "\n",
      "[I 2024-02-18 22:33:31,023] Trial 68 finished with value: 0.12535612535612536 and parameters: {'n_estimators': 353, 'learning_rate': 1.373960861108685, 'algorithm': 'SAMME.R', 'random_state': 1}. Best is trial 0 with value: 0.11396011396011396.\n",
      "[I 2024-02-18 22:33:31,073] Trial 69 finished with value: 0.11396011396011396 and parameters: {'n_estimators': 66, 'learning_rate': 1.4676173512141029, 'algorithm': 'SAMME', 'random_state': 0}. Best is trial 0 with value: 0.11396011396011396.\n",
      "[I 2024-02-18 22:33:31,121] Trial 70 finished with value: 0.11396011396011396 and parameters: {'n_estimators': 232, 'learning_rate': 1.6135446279127497, 'algorithm': 'SAMME', 'random_state': 0}. Best is trial 0 with value: 0.11396011396011396.\n",
      "[I 2024-02-18 22:33:31,177] Trial 71 finished with value: 0.11396011396011396 and parameters: {'n_estimators': 403, 'learning_rate': 2.9137751905934683, 'algorithm': 'SAMME', 'random_state': 0}. Best is trial 0 with value: 0.11396011396011396.\n",
      "[I 2024-02-18 22:33:31,220] Trial 72 finished with value: 0.11396011396011396 and parameters: {'n_estimators': 257, 'learning_rate': 2.640494140893212, 'algorithm': 'SAMME', 'random_state': 0}. Best is trial 0 with value: 0.11396011396011396.\n",
      "[I 2024-02-18 22:33:31,290] Trial 73 finished with value: 0.11396011396011396 and parameters: {'n_estimators': 450, 'learning_rate': 2.8456674401736293, 'algorithm': 'SAMME', 'random_state': 0}. Best is trial 0 with value: 0.11396011396011396.\n",
      "[I 2024-02-18 22:33:31,345] Trial 74 finished with value: 0.1396011396011396 and parameters: {'n_estimators': 194, 'learning_rate': 2.7176208724530917, 'algorithm': 'SAMME', 'random_state': 5}. Best is trial 0 with value: 0.11396011396011396.\n",
      "[I 2024-02-18 22:33:31,396] Trial 75 finished with value: 0.11396011396011396 and parameters: {'n_estimators': 123, 'learning_rate': 2.587920997536956, 'algorithm': 'SAMME', 'random_state': 0}. Best is trial 0 with value: 0.11396011396011396.\n",
      "[I 2024-02-18 22:33:31,446] Trial 76 finished with value: 0.12535612535612536 and parameters: {'n_estimators': 141, 'learning_rate': 1.6956463647293631, 'algorithm': 'SAMME', 'random_state': 1}. Best is trial 0 with value: 0.11396011396011396.\n",
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning:\n",
      "\n",
      "The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "\n",
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning:\n",
      "\n",
      "The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "\n",
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning:\n",
      "\n",
      "The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "\n",
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning:\n",
      "\n",
      "The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "\n",
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning:\n",
      "\n",
      "The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "\n",
      "[I 2024-02-18 22:33:31,505] Trial 77 finished with value: 0.11396011396011396 and parameters: {'n_estimators': 315, 'learning_rate': 1.8065810966056643, 'algorithm': 'SAMME.R', 'random_state': 0}. Best is trial 0 with value: 0.11396011396011396.\n",
      "[I 2024-02-18 22:33:31,555] Trial 78 finished with value: 0.11396011396011396 and parameters: {'n_estimators': 163, 'learning_rate': 2.888522088158753, 'algorithm': 'SAMME', 'random_state': 0}. Best is trial 0 with value: 0.11396011396011396.\n",
      "[I 2024-02-18 22:33:31,607] Trial 79 finished with value: 0.12535612535612536 and parameters: {'n_estimators': 182, 'learning_rate': 2.3302461345642724, 'algorithm': 'SAMME', 'random_state': 1}. Best is trial 0 with value: 0.11396011396011396.\n",
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning:\n",
      "\n",
      "The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "\n",
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning:\n",
      "\n",
      "The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "\n",
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning:\n",
      "\n",
      "The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "\n",
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning:\n",
      "\n",
      "The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "\n",
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning:\n",
      "\n",
      "The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "\n",
      "[I 2024-02-18 22:33:31,657] Trial 80 finished with value: 0.11396011396011396 and parameters: {'n_estimators': 151, 'learning_rate': 1.9286759538284426, 'algorithm': 'SAMME.R', 'random_state': 0}. Best is trial 0 with value: 0.11396011396011396.\n",
      "[I 2024-02-18 22:33:31,715] Trial 81 finished with value: 0.11396011396011396 and parameters: {'n_estimators': 115, 'learning_rate': 1.8443063312787293, 'algorithm': 'SAMME', 'random_state': 0}. Best is trial 0 with value: 0.11396011396011396.\n",
      "[I 2024-02-18 22:33:31,764] Trial 82 finished with value: 0.11396011396011396 and parameters: {'n_estimators': 84, 'learning_rate': 2.1561929891128435, 'algorithm': 'SAMME', 'random_state': 0}. Best is trial 0 with value: 0.11396011396011396.\n",
      "[I 2024-02-18 22:33:31,826] Trial 83 finished with value: 0.11396011396011396 and parameters: {'n_estimators': 97, 'learning_rate': 1.8731214959318165, 'algorithm': 'SAMME', 'random_state': 0}. Best is trial 0 with value: 0.11396011396011396.\n",
      "[I 2024-02-18 22:33:31,878] Trial 84 finished with value: 0.11396011396011396 and parameters: {'n_estimators': 107, 'learning_rate': 1.7181443227056925, 'algorithm': 'SAMME', 'random_state': 0}. Best is trial 0 with value: 0.11396011396011396.\n",
      "[I 2024-02-18 22:33:31,930] Trial 85 finished with value: 0.11396011396011396 and parameters: {'n_estimators': 74, 'learning_rate': 1.6518598529461304, 'algorithm': 'SAMME', 'random_state': 0}. Best is trial 0 with value: 0.11396011396011396.\n",
      "[I 2024-02-18 22:33:31,988] Trial 86 finished with value: 0.11396011396011396 and parameters: {'n_estimators': 135, 'learning_rate': 2.0135853650030504, 'algorithm': 'SAMME', 'random_state': 0}. Best is trial 0 with value: 0.11396011396011396.\n",
      "[I 2024-02-18 22:33:32,042] Trial 87 finished with value: 0.12535612535612536 and parameters: {'n_estimators': 496, 'learning_rate': 1.7703117284342116, 'algorithm': 'SAMME', 'random_state': 1}. Best is trial 0 with value: 0.11396011396011396.\n",
      "[I 2024-02-18 22:33:32,092] Trial 88 finished with value: 0.11396011396011396 and parameters: {'n_estimators': 355, 'learning_rate': 1.577745277475598, 'algorithm': 'SAMME', 'random_state': 0}. Best is trial 0 with value: 0.11396011396011396.\n",
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning:\n",
      "\n",
      "The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "\n",
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning:\n",
      "\n",
      "The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "\n",
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning:\n",
      "\n",
      "The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "\n",
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning:\n",
      "\n",
      "The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "\n",
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning:\n",
      "\n",
      "The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "\n",
      "[I 2024-02-18 22:33:32,152] Trial 89 finished with value: 0.11396011396011396 and parameters: {'n_estimators': 387, 'learning_rate': 1.4926701592725813, 'algorithm': 'SAMME.R', 'random_state': 0}. Best is trial 0 with value: 0.11396011396011396.\n",
      "[I 2024-02-18 22:33:32,208] Trial 90 finished with value: 0.11396011396011396 and parameters: {'n_estimators': 123, 'learning_rate': 1.0396588229206876, 'algorithm': 'SAMME', 'random_state': 0}. Best is trial 0 with value: 0.11396011396011396.\n",
      "[I 2024-02-18 22:33:32,263] Trial 91 finished with value: 0.11396011396011396 and parameters: {'n_estimators': 59, 'learning_rate': 2.083727698465922, 'algorithm': 'SAMME', 'random_state': 0}. Best is trial 0 with value: 0.11396011396011396.\n",
      "[I 2024-02-18 22:33:32,322] Trial 92 finished with value: 0.11396011396011396 and parameters: {'n_estimators': 80, 'learning_rate': 2.1531584720042583, 'algorithm': 'SAMME', 'random_state': 0}. Best is trial 0 with value: 0.11396011396011396.\n",
      "[I 2024-02-18 22:33:32,372] Trial 93 finished with value: 0.11396011396011396 and parameters: {'n_estimators': 97, 'learning_rate': 1.9895825304000032, 'algorithm': 'SAMME', 'random_state': 0}. Best is trial 0 with value: 0.11396011396011396.\n",
      "[I 2024-02-18 22:33:32,429] Trial 94 finished with value: 0.11396011396011396 and parameters: {'n_estimators': 287, 'learning_rate': 2.454655288802137, 'algorithm': 'SAMME', 'random_state': 0}. Best is trial 0 with value: 0.11396011396011396.\n",
      "[I 2024-02-18 22:33:32,474] Trial 95 finished with value: 0.11396011396011396 and parameters: {'n_estimators': 154, 'learning_rate': 1.136996290120707, 'algorithm': 'SAMME', 'random_state': 0}. Best is trial 0 with value: 0.11396011396011396.\n",
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning:\n",
      "\n",
      "The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "\n",
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning:\n",
      "\n",
      "The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "\n",
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning:\n",
      "\n",
      "The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "\n",
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning:\n",
      "\n",
      "The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "\n",
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning:\n",
      "\n",
      "The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "\n",
      "[I 2024-02-18 22:33:32,530] Trial 96 finished with value: 0.11396011396011396 and parameters: {'n_estimators': 175, 'learning_rate': 1.9119172886710891, 'algorithm': 'SAMME.R', 'random_state': 0}. Best is trial 0 with value: 0.11396011396011396.\n",
      "[I 2024-02-18 22:33:32,580] Trial 97 finished with value: 0.11396011396011396 and parameters: {'n_estimators': 51, 'learning_rate': 1.8172542653331256, 'algorithm': 'SAMME', 'random_state': 0}. Best is trial 0 with value: 0.11396011396011396.\n",
      "[I 2024-02-18 22:33:32,639] Trial 98 finished with value: 0.14245014245014245 and parameters: {'n_estimators': 109, 'learning_rate': 2.8132935934927676, 'algorithm': 'SAMME', 'random_state': 2}. Best is trial 0 with value: 0.11396011396011396.\n",
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning:\n",
      "\n",
      "The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "\n",
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning:\n",
      "\n",
      "The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "\n",
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning:\n",
      "\n",
      "The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "\n",
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning:\n",
      "\n",
      "The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "\n",
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning:\n",
      "\n",
      "The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "\n",
      "[I 2024-02-18 22:33:32,698] Trial 99 finished with value: 0.12535612535612536 and parameters: {'n_estimators': 90, 'learning_rate': 2.709213164251522, 'algorithm': 'SAMME.R', 'random_state': 1}. Best is trial 0 with value: 0.11396011396011396.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of finished trials: 100\n",
      "Best trial: {'n_estimators': 492, 'learning_rate': 1.4181100555797042, 'algorithm': 'SAMME.R', 'random_state': 0}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "study_Ada.optimize(objective_Ada, n_trials=100) # 150 bar \"objective\" object ke trial kore kore dekhbe, here total 5*100=750\n",
    "print('Number of finished trials:', len(study_Ada.trials))\n",
    "print('Best trial:', study_Ada.best_trial.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# model_tuned=AdaBoostClassifier(**study_Ada.best_trial.params)\n",
    "# pickle.dump(model_tuned, open(\"all_pkl_file/all_tuned_model/PCA_Ada.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "dimensions": [
          {
           "label": "Objective Value",
           "range": [
            0.11396011396011396,
            0.16809116809116809
           ],
           "values": [
            0.11396011396011396,
            0.1225071225071225,
            0.14245014245014245,
            0.12535612535612536,
            0.1396011396011396,
            0.12535612535612536,
            0.1225071225071225,
            0.14245014245014245,
            0.14245014245014245,
            0.16809116809116809,
            0.11396011396011396,
            0.11396011396011396,
            0.11396011396011396,
            0.11396011396011396,
            0.12535612535612536,
            0.11396011396011396,
            0.11396011396011396,
            0.12535612535612536,
            0.12535612535612536,
            0.16809116809116809,
            0.11396011396011396,
            0.11396011396011396,
            0.12535612535612536,
            0.11396011396011396,
            0.11396011396011396,
            0.12535612535612536,
            0.14245014245014245,
            0.11396011396011396,
            0.12535612535612536,
            0.1225071225071225,
            0.16809116809116809,
            0.11396011396011396,
            0.11396011396011396,
            0.11396011396011396,
            0.12535612535612536,
            0.11396011396011396,
            0.1396011396011396,
            0.14245014245014245,
            0.12535612535612536,
            0.12535612535612536,
            0.11396011396011396,
            0.11396011396011396,
            0.11396011396011396,
            0.11396011396011396,
            0.12535612535612536,
            0.11396011396011396,
            0.14245014245014245,
            0.12535612535612536,
            0.11396011396011396,
            0.12535612535612536,
            0.11396011396011396,
            0.11396011396011396,
            0.11396011396011396,
            0.11396011396011396,
            0.11396011396011396,
            0.12535612535612536,
            0.11396011396011396,
            0.1225071225071225,
            0.12535612535612536,
            0.11396011396011396,
            0.11396011396011396,
            0.11396011396011396,
            0.11396011396011396,
            0.11396011396011396,
            0.11396011396011396,
            0.16809116809116809,
            0.11396011396011396,
            0.12535612535612536,
            0.12535612535612536,
            0.11396011396011396,
            0.11396011396011396,
            0.11396011396011396,
            0.11396011396011396,
            0.11396011396011396,
            0.1396011396011396,
            0.11396011396011396,
            0.12535612535612536,
            0.11396011396011396,
            0.11396011396011396,
            0.12535612535612536,
            0.11396011396011396,
            0.11396011396011396,
            0.11396011396011396,
            0.11396011396011396,
            0.11396011396011396,
            0.11396011396011396,
            0.11396011396011396,
            0.12535612535612536,
            0.11396011396011396,
            0.11396011396011396,
            0.11396011396011396,
            0.11396011396011396,
            0.11396011396011396,
            0.11396011396011396,
            0.11396011396011396,
            0.11396011396011396,
            0.11396011396011396,
            0.11396011396011396,
            0.14245014245014245,
            0.12535612535612536
           ]
          },
          {
           "label": "algorithm",
           "range": [
            0,
            1
           ],
           "ticktext": [
            "SAMME.R",
            "SAMME"
           ],
           "tickvals": [
            0,
            1
           ],
           "values": [
            0,
            0,
            1,
            0,
            0,
            0,
            0,
            1,
            0,
            0,
            1,
            1,
            1,
            1,
            1,
            1,
            0,
            1,
            0,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            0,
            1,
            0,
            0,
            1,
            1,
            1,
            1,
            1,
            1,
            0,
            1,
            0,
            0,
            1,
            1,
            1,
            1,
            1,
            1,
            0,
            1,
            1,
            0,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            0,
            1,
            1,
            0,
            0,
            0,
            0,
            0,
            0,
            1,
            1,
            0,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            0,
            1,
            1,
            0,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            0,
            1,
            1,
            1,
            1,
            1,
            1,
            0,
            1,
            1,
            0
           ]
          },
          {
           "label": "learning_rate",
           "range": [
            1.0110815902513468,
            2.982866712357873
           ],
           "values": [
            1.4181100555797042,
            2.3058664813194323,
            1.114558762325345,
            2.2387392646727804,
            2.381377585207958,
            1.7342984400951023,
            2.3211414031320894,
            1.4058016391112529,
            1.145491521104714,
            2.387229511316181,
            1.774336147360879,
            1.8593750321939577,
            1.5640692182492093,
            2.8437418740469225,
            1.443666775618988,
            2.0082212381218367,
            1.0110815902513468,
            1.6583845958463903,
            1.979803911764945,
            1.336415767684171,
            2.749964380323651,
            1.8414370263742859,
            1.9416282985467213,
            2.1517859626981752,
            1.6067147351175661,
            1.296496408447632,
            1.8090327699132707,
            1.5574344353530751,
            2.523905776478717,
            2.118452212663199,
            1.8409616936662674,
            1.5089449813449576,
            1.2458919409587883,
            1.6806048068450115,
            1.5563630029310471,
            1.7581595720825687,
            1.4248773574959317,
            1.1792854614262893,
            1.9087190169001422,
            2.0783042050211824,
            1.7001639030990972,
            2.974178773860559,
            2.4984625808382,
            2.7892984158350487,
            2.240492348230625,
            1.4704849133741091,
            1.3293583915294545,
            1.6415795125882622,
            1.7453597367868672,
            2.047508780104631,
            1.1002263888699844,
            1.8933281678715026,
            1.3908460030299787,
            2.7387992205523912,
            2.0157715425812026,
            1.5961189594181635,
            2.385246464969483,
            2.212766548215724,
            1.7747078488849795,
            2.982866712357873,
            2.4942601301794878,
            1.2079215996293484,
            1.016682706677418,
            1.0831596363272127,
            1.964313911593234,
            1.5288322997429462,
            1.8492152387346377,
            1.258728805654134,
            1.373960861108685,
            1.4676173512141029,
            1.6135446279127497,
            2.9137751905934683,
            2.640494140893212,
            2.8456674401736293,
            2.7176208724530917,
            2.587920997536956,
            1.6956463647293631,
            1.8065810966056643,
            2.888522088158753,
            2.3302461345642724,
            1.9286759538284426,
            1.8443063312787293,
            2.1561929891128435,
            1.8731214959318165,
            1.7181443227056925,
            1.6518598529461304,
            2.0135853650030504,
            1.7703117284342116,
            1.577745277475598,
            1.4926701592725813,
            1.0396588229206876,
            2.083727698465922,
            2.1531584720042583,
            1.9895825304000032,
            2.454655288802137,
            1.136996290120707,
            1.9119172886710891,
            1.8172542653331256,
            2.8132935934927676,
            2.709213164251522
           ]
          },
          {
           "label": "n_estimators",
           "range": [
            51,
            497
           ],
           "values": [
            492,
            369,
            288,
            433,
            83,
            437,
            281,
            402,
            246,
            497,
            141,
            112,
            176,
            195,
            333,
            51,
            155,
            496,
            223,
            129,
            328,
            106,
            141,
            82,
            216,
            53,
            169,
            116,
            243,
            330,
            375,
            182,
            102,
            150,
            200,
            84,
            300,
            465,
            247,
            421,
            159,
            191,
            125,
            210,
            177,
            237,
            273,
            82,
            374,
            144,
            130,
            51,
            65,
            92,
            109,
            69,
            266,
            168,
            304,
            134,
            468,
            152,
            201,
            116,
            166,
            95,
            182,
            219,
            353,
            66,
            232,
            403,
            257,
            450,
            194,
            123,
            141,
            315,
            163,
            182,
            151,
            115,
            84,
            97,
            107,
            74,
            135,
            496,
            355,
            387,
            123,
            59,
            80,
            97,
            287,
            154,
            175,
            51,
            109,
            90
           ]
          },
          {
           "label": "random_state",
           "range": [
            0,
            5
           ],
           "values": [
            0,
            3,
            2,
            1,
            5,
            1,
            3,
            2,
            2,
            4,
            0,
            0,
            0,
            0,
            1,
            0,
            0,
            1,
            1,
            4,
            0,
            0,
            1,
            0,
            0,
            1,
            2,
            0,
            1,
            3,
            4,
            0,
            0,
            0,
            1,
            0,
            5,
            2,
            1,
            1,
            0,
            0,
            0,
            0,
            1,
            0,
            2,
            1,
            0,
            1,
            0,
            0,
            0,
            0,
            0,
            1,
            0,
            3,
            1,
            0,
            0,
            0,
            0,
            0,
            0,
            4,
            0,
            1,
            1,
            0,
            0,
            0,
            0,
            0,
            5,
            0,
            1,
            0,
            0,
            1,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            1,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            2,
            1
           ]
          }
         ],
         "labelangle": 30,
         "labelside": "bottom",
         "line": {
          "color": [
           0.11396011396011396,
           0.1225071225071225,
           0.14245014245014245,
           0.12535612535612536,
           0.1396011396011396,
           0.12535612535612536,
           0.1225071225071225,
           0.14245014245014245,
           0.14245014245014245,
           0.16809116809116809,
           0.11396011396011396,
           0.11396011396011396,
           0.11396011396011396,
           0.11396011396011396,
           0.12535612535612536,
           0.11396011396011396,
           0.11396011396011396,
           0.12535612535612536,
           0.12535612535612536,
           0.16809116809116809,
           0.11396011396011396,
           0.11396011396011396,
           0.12535612535612536,
           0.11396011396011396,
           0.11396011396011396,
           0.12535612535612536,
           0.14245014245014245,
           0.11396011396011396,
           0.12535612535612536,
           0.1225071225071225,
           0.16809116809116809,
           0.11396011396011396,
           0.11396011396011396,
           0.11396011396011396,
           0.12535612535612536,
           0.11396011396011396,
           0.1396011396011396,
           0.14245014245014245,
           0.12535612535612536,
           0.12535612535612536,
           0.11396011396011396,
           0.11396011396011396,
           0.11396011396011396,
           0.11396011396011396,
           0.12535612535612536,
           0.11396011396011396,
           0.14245014245014245,
           0.12535612535612536,
           0.11396011396011396,
           0.12535612535612536,
           0.11396011396011396,
           0.11396011396011396,
           0.11396011396011396,
           0.11396011396011396,
           0.11396011396011396,
           0.12535612535612536,
           0.11396011396011396,
           0.1225071225071225,
           0.12535612535612536,
           0.11396011396011396,
           0.11396011396011396,
           0.11396011396011396,
           0.11396011396011396,
           0.11396011396011396,
           0.11396011396011396,
           0.16809116809116809,
           0.11396011396011396,
           0.12535612535612536,
           0.12535612535612536,
           0.11396011396011396,
           0.11396011396011396,
           0.11396011396011396,
           0.11396011396011396,
           0.11396011396011396,
           0.1396011396011396,
           0.11396011396011396,
           0.12535612535612536,
           0.11396011396011396,
           0.11396011396011396,
           0.12535612535612536,
           0.11396011396011396,
           0.11396011396011396,
           0.11396011396011396,
           0.11396011396011396,
           0.11396011396011396,
           0.11396011396011396,
           0.11396011396011396,
           0.12535612535612536,
           0.11396011396011396,
           0.11396011396011396,
           0.11396011396011396,
           0.11396011396011396,
           0.11396011396011396,
           0.11396011396011396,
           0.11396011396011396,
           0.11396011396011396,
           0.11396011396011396,
           0.11396011396011396,
           0.14245014245014245,
           0.12535612535612536
          ],
          "colorbar": {
           "title": {
            "text": "Objective Value"
           }
          },
          "colorscale": [
           [
            0,
            "rgb(247,251,255)"
           ],
           [
            0.125,
            "rgb(222,235,247)"
           ],
           [
            0.25,
            "rgb(198,219,239)"
           ],
           [
            0.375,
            "rgb(158,202,225)"
           ],
           [
            0.5,
            "rgb(107,174,214)"
           ],
           [
            0.625,
            "rgb(66,146,198)"
           ],
           [
            0.75,
            "rgb(33,113,181)"
           ],
           [
            0.875,
            "rgb(8,81,156)"
           ],
           [
            1,
            "rgb(8,48,107)"
           ]
          ],
          "reversescale": true,
          "showscale": true
         },
         "type": "parcoords"
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Parallel Coordinate Plot"
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "fig_study = optuna.visualization.plot_parallel_coordinate(study_Ada, params=[\"n_estimators\", \"learning_rate\",\"algorithm\",\"random_state\"])\n",
    "fig_study.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of finished trials:  100\n",
      "Best trial:\n",
      "  Value:  0.11396011396011396\n",
      "  Params: \n",
      "    n_estimators: 492\n",
      "    learning_rate: 1.4181100555797042\n",
      "    algorithm: SAMME.R\n",
      "    random_state: 0\n"
     ]
    }
   ],
   "source": [
    "#evaluate the trial\n",
    "print(\"Number of finished trials: \", len(study_Ada.trials))\n",
    "print(\"Best trial:\")\n",
    "trial = study_Ada.best_trial\n",
    "print(\"  Value: \", trial.value)\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(\"    {}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fit AdaBoost classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "K = 5 # 5 fold cross validation\n",
    "skf = StratifiedKFold(n_splits = K, random_state = 42, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning:\n",
      "\n",
      "The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "\n",
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning:\n",
      "\n",
      "The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "\n",
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning:\n",
      "\n",
      "The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "\n",
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning:\n",
      "\n",
      "The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "\n",
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning:\n",
      "\n",
      "The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "\n",
      "100%|| 5/5 [00:00<00:00, 128.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Let us make predictions for each of the 5 models and find mean \n",
    "# of those predictions\n",
    "\n",
    "from tqdm import tqdm\n",
    "train_Ada = np.array(compressed_dataset_X_train)\n",
    "target_train_Ada = np.array(y_train)\n",
    "\n",
    "test_Ada = np.array(compressed_dataset_X_test) # or test_Ada = np.array(X)\n",
    "\n",
    "\n",
    "test_preds_Ada = np.zeros((len(test_Ada)))\n",
    "oof_preds_Ada = np.zeros((len(train_Ada)))\n",
    "\n",
    "for train_index, val_index in tqdm(skf.split(compressed_dataset_X_train,y_train), total=5):\n",
    "    train_X, valid_X = train_Ada[train_index], train_Ada[val_index]\n",
    "    train_y, valid_y = target_train_Ada[train_index], target_train_Ada[val_index]\n",
    "    ada_params = study_Ada.best_trial.params\n",
    "    model_Ada_2 = AdaBoostClassifier(**ada_params,estimator=model_dt)\n",
    "    model_Ada_2.fit(train_X, train_y)\n",
    "    # for train accuracy\n",
    "    preds = model_Ada_2.predict(valid_X)\n",
    "    oof_preds_Ada[val_index] = preds\n",
    "    # for test accuracy\n",
    "    preds = model_Ada_2.predict(test_Ada)\n",
    "    test_preds_Ada += (preds)/5\n",
    "print(np.abs(oof_preds_Ada-target_train_Ada).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8875\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "valid_Acc_Ada=accuracy_score(target_train_Ada,oof_preds_Ada)\n",
    "print(valid_Acc_Ada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9791666666666666\n"
     ]
    }
   ],
   "source": [
    "train_Acc_Ada=model_Ada_2.score(compressed_dataset_X_train,y_train)\n",
    "print(train_Acc_Ada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8198198198198198\n"
     ]
    }
   ],
   "source": [
    "test_Acc_Ada=model_Ada_2.score(compressed_dataset_X_test,y_test)\n",
    "print(test_Acc_Ada)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0.,\n",
       "       0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0.,\n",
       "       0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0.,\n",
       "       1., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 0., 1., 1., 0., 0., 1.,\n",
       "       0., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 1., 0., 1., 1., 0., 1.,\n",
       "       1., 1., 1., 1., 0., 0., 0., 1., 0.])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_preds_Ada.round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAq0AAAJOCAYAAACdjD6HAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAABjjUlEQVR4nO3deVxVdf7H8fcBBdwAV5ZSXEMtFZeRaHFJFM1KR2dcshEZl6m0VDSXyr2izNTsZ9ri2mhmi5ZZmmloJmqilJU6apiWgKYBggkK5/eH4x1vLHKRK+fG6+njPOJ+z/d8z+fLDfr08Xu/xzBN0xQAAABgYW6lHQAAAABwLSStAAAAsDySVgAAAFgeSSsAAAAsj6QVAAAAlkfSCgAAAMsjaQUAAIDlkbQCAADA8khaAQAAYHkkrQAs7/Dhw+rSpYt8fHxkGIbWrl1bouMfO3ZMhmFo6dKlJTquK+vQoYM6dOhQ2mEAgA1JK4AiOXr0qP71r3+pfv368vLykre3t+688069/PLL+v33351678jISO3fv1/PPvus3nrrLbVp08ap97uRBg0aJMMw5O3tne/38fDhwzIMQ4ZhaNasWQ6Pf/LkSU2dOlUJCQklEC0AlJ5ypR0AAOtbv369/v73v8vT01MDBw7UbbfdpuzsbG3fvl1PPPGEvv/+e73++utOuffvv/+uuLg4PfXUUxoxYoRT7hEUFKTff/9d5cuXd8r411KuXDmdP39e69atU58+fezOrVixQl5eXrpw4UKxxj558qSmTZumunXrKiQkpMjXffbZZ8W6HwA4C0krgEIlJiaqX79+CgoK0pYtWxQQEGA7N3z4cB05ckTr16932v1Pnz4tSfL19XXaPQzDkJeXl9PGvxZPT0/deeedevvtt/MkrStXrlT37t31/vvv35BYzp8/r4oVK8rDw+OG3A8AiorlAQAKNXPmTGVkZGjRokV2CesVDRs21MiRI22vL126pBkzZqhBgwby9PRU3bp19eSTTyorK8vuurp16+q+++7T9u3b1bZtW3l5eal+/fpavny5rc/UqVMVFBQkSXriiSdkGIbq1q0r6fJfq1/5+mpTp06VYRh2bZs2bdJdd90lX19fVa5cWcHBwXryySdt5wta07plyxbdfffdqlSpknx9fdWjRw8dOHAg3/sdOXJEgwYNkq+vr3x8fBQVFaXz588X/I39gwcffFCffvqpUlNTbW1ff/21Dh8+rAcffDBP/7Nnz2rs2LFq1qyZKleuLG9vb3Xr1k3ffPONrU9sbKz+8pe/SJKioqJsywyuzLNDhw667bbbFB8fr3bt2qlixYq278sf17RGRkbKy8srz/wjIiJUtWpVnTx5sshzBYDiIGkFUKh169apfv36uuOOO4rUf8iQIZo8ebJatWqlOXPmqH379oqJiVG/fv3y9D1y5Ij+9re/qXPnznrppZdUtWpVDRo0SN9//70kqVevXpozZ44kqX///nrrrbc0d+5ch+L//vvvdd999ykrK0vTp0/XSy+9pAceeEBfffVVodd9/vnnioiI0KlTpzR16lRFR0drx44duvPOO3Xs2LE8/fv06aNz584pJiZGffr00dKlSzVt2rQix9mrVy8ZhqEPPvjA1rZy5Uo1btxYrVq1ytP/xx9/1Nq1a3Xfffdp9uzZeuKJJ7R//361b9/elkA2adJE06dPlyQNGzZMb731lt566y21a9fONs6ZM2fUrVs3hYSEaO7cuerYsWO+8b388suqWbOmIiMjlZOTI0l67bXX9Nlnn+mVV15RYGBgkecKAMViAkAB0tLSTElmjx49itQ/ISHBlGQOGTLErn3s2LGmJHPLli22tqCgIFOSuW3bNlvbqVOnTE9PT3PMmDG2tsTERFOS+eKLL9qNGRkZaQYFBeWJYcqUKebVv9rmzJljSjJPnz5dYNxX7rFkyRJbW0hIiFmrVi3zzJkztrZvvvnGdHNzMwcOHJjnfv/85z/txvzrX/9qVq9evcB7Xj2PSpUqmaZpmn/729/MTp06maZpmjk5Oaa/v785bdq0fL8HFy5cMHNycvLMw9PT05w+fbqt7euvv84ztyvat29vSjIXLlyY77n27dvbtW3cuNGUZD7zzDPmjz/+aFauXNns2bPnNecIACWBSiuAAqWnp0uSqlSpUqT+n3zyiSQpOjrarn3MmDGSlGfta9OmTXX33XfbXtesWVPBwcH68ccfix3zH11ZC/vhhx8qNze3SNckJSUpISFBgwYNUrVq1WztzZs3V+fOnW3zvNrDDz9s9/ruu+/WmTNnbN/DonjwwQcVGxur5ORkbdmyRcnJyfkuDZAur4N1c7v8KzwnJ0dnzpyxLX3Yu3dvke/p6empqKioIvXt0qWL/vWvf2n69Onq1auXvLy89NprrxX5XgBwPUhaARTI29tbknTu3Lki9f/pp5/k5uamhg0b2rX7+/vL19dXP/30k117nTp18oxRtWpV/fbbb8WMOK++ffvqzjvv1JAhQ+Tn56d+/fpp9erVhSawV+IMDg7Oc65Jkyb69ddflZmZadf+x7lUrVpVkhyay7333qsqVaronXfe0YoVK/SXv/wlz/fyitzcXM2ZM0eNGjWSp6enatSooZo1a+rbb79VWlpake950003OfShq1mzZqlatWpKSEjQvHnzVKtWrSJfCwDXg6QVQIG8vb0VGBio7777zqHr/vhBqIK4u7vn226aZrHvcWW95RUVKlTQtm3b9Pnnn+sf//iHvv32W/Xt21edO3fO0/d6XM9crvD09FSvXr20bNkyrVmzpsAqqyQ999xzio6OVrt27fTvf/9bGzdu1KZNm3TrrbcWuaIsXf7+OGLfvn06deqUJGn//v0OXQsA14OkFUCh7rvvPh09elRxcXHX7BsUFKTc3FwdPnzYrj0lJUWpqam2nQBKQtWqVe0+aX/FH6u5kuTm5qZOnTpp9uzZ+uGHH/Tss89qy5Yt+uKLL/Id+0qchw4dynPu4MGDqlGjhipVqnR9EyjAgw8+qH379uncuXP5fnjtivfee08dO3bUokWL1K9fP3Xp0kXh4eF5vidF/R+IosjMzFRUVJSaNm2qYcOGaebMmfr6669LbHwAKAxJK4BCjRs3TpUqVdKQIUOUkpKS5/zRo0f18ssvS7r819uS8nzCf/bs2ZKk7t27l1hcDRo0UFpamr799ltbW1JSktasWWPX7+zZs3muvbLJ/h+34boiICBAISEhWrZsmV0S+N133+mzzz6zzdMZOnbsqBkzZuj//u//5O/vX2A/d3f3PFXcd999V7/88otd25XkOr8E31Hjx4/X8ePHtWzZMs2ePVt169ZVZGRkgd9HAChJPFwAQKEaNGiglStXqm/fvmrSpIndE7F27Nihd999V4MGDZIktWjRQpGRkXr99deVmpqq9u3ba/fu3Vq2bJl69uxZ4HZKxdGvXz+NHz9ef/3rX/X444/r/PnzWrBggW655Ra7DyJNnz5d27ZtU/fu3RUUFKRTp07p1Vdf1c0336y77rqrwPFffPFFdevWTWFhYRo8eLB+//13vfLKK/Lx8dHUqVNLbB5/5Obmpqeffvqa/e677z5Nnz5dUVFRuuOOO7R//36tWLFC9evXt+vXoEED+fr6auHChapSpYoqVaqk0NBQ1atXz6G4tmzZoldffVVTpkyxbcG1ZMkSdejQQZMmTdLMmTMdGg8AHEWlFcA1PfDAA/r222/1t7/9TR9++KGGDx+uCRMm6NixY3rppZc0b948W98333xT06ZN09dff61Ro0Zpy5YtmjhxolatWlWiMVWvXl1r1qxRxYoVNW7cOC1btkwxMTG6//7788Rep04dLV68WMOHD9f8+fPVrl07bdmyRT4+PgWOHx4erg0bNqh69eqaPHmyZs2apdtvv11fffWVwwmfMzz55JMaM2aMNm7cqJEjR2rv3r1av369ateubdevfPnyWrZsmdzd3fXwww+rf//+2rp1q0P3OnfunP75z3+qZcuWeuqpp2ztd999t0aOHKmXXnpJO3fuLJF5AUBBDNORTwkAAAAApYBKKwAAACyPpBUAAACWR9IKAAAAy3OZpPXs2bMaMGCAvL295evrq8GDBysjI6PQazp06CDDMOyOPz5q8fjx4+revbsqVqyoWrVq6YknntClS5ecORUAAAA4yGW2vBowYICSkpK0adMmXbx4UVFRURo2bJhWrlxZ6HVDhw7V9OnTba8rVqxo+zonJ0fdu3eXv7+/duzYoaSkJA0cOFDly5fXc88957S5AAAAwDEusXvAgQMH1LRpU3399ddq06aNJGnDhg2699579fPPPyswMDDf6zp06KCQkJA8G51f8emnn+q+++7TyZMn5efnJ0lauHChxo8fr9OnTzv0PG4AAAA4j0tUWuPi4uTr62tLWKXLeyi6ublp165d+utf/1rgtStWrNC///1v+fv76/7779ekSZNs1da4uDg1a9bMlrBKUkREhB555BF9//33atmyZb5jZmVl2T0BJjc3V2fPnlX16tVL9JGJAACg9JimqXPnzikwMFBubtZZUXnhwgVlZ2c79R4eHh7y8vJy6j0c5RJJa3JysmrVqmXXVq5cOVWrVk3JyckFXvfggw8qKChIgYGB+vbbbzV+/HgdOnRIH3zwgW3cqxNWSbbXhY0bExOjadOmFXc6AADAhZw4cUI333xzaYch6XLCWr1CZZ1XjlPv4+/vr8TEREslrqWatE6YMEEvvPBCoX0OHDhQ7PGHDRtm+7pZs2YKCAhQp06ddPToUTVo0KDY406cOFHR0dG212lpaapTp4529HtDlT0qFnIlgD8Dv+e7lHYIAG6Ac+fOqWFwfVWpUqW0Q7HJzs7WeeVogG6Sh5M+T5+tXK1I/kXZ2dkkrVeMGTPG9szygtSvX1/+/v46deqUXfulS5d09uxZ+fv7F/l+oaGhkqQjR46oQYMG8vf31+7du+36pKSkSFKh43p6esrT0zNPe2WPiqpC0gr86Xl7e5d2CABuICsu/fOSu9OSVjdZb75SKSetNWvWVM2aNa/ZLywsTKmpqYqPj1fr1q0lSVu2bFFubq4tES2KhIQESVJAQIBt3GeffVanTp2yLT/YtGmTvL291bRpUwdnAwAAAGexzqriQjRp0kRdu3bV0KFDtXv3bn311VcaMWKE+vXrZ9s54JdfflHjxo1tldOjR49qxowZio+P17Fjx/TRRx9p4MCBateunZo3by5J6tKli5o2bap//OMf+uabb7Rx40Y9/fTTGj58eL6VVAAAACswnPzHilwiaZUu7wLQuHFjderUSffee6/uuusuvf7667bzFy9e1KFDh3T+/HlJlz/19vnnn6tLly5q3LixxowZo969e2vdunW2a9zd3fXxxx/L3d1dYWFheuihhzRw4EC7fV0BAABQ+lxi9wBJqlatWqEPEqhbt66u3nK2du3a2rp16zXHDQoK0ieffFIiMQIAANwIbjKctvbUqmtaXabSCgAAgLLLZSqtAAAAuMz4b63VOWNbE5VWAAAAWB6VVgAAABdjyHlrT6m0AgAAAMVEpRUAAMDFOHM/VfZpBQAAAIqJSisAAICLYZ9WAAAAwIKotAIAALgY1rQCAAAAFkSlFQAAwMWwphUAAACwICqtAAAALoY1rQAAAIAFUWkFAABwMaxpBQAAACyISisAAICLMf5ba3XO2KZTxr1eVFoBAABgeVRaAQAAXAxrWgEAAAALotIKAADgYqi0AgAAAA745Zdf9NBDD6l69eqqUKGCmjVrpj179tjOm6apyZMnKyAgQBUqVFB4eLgOHz7s8H1IWgEAAFyM4eQ/RfXbb7/pzjvvVPny5fXpp5/qhx9+0EsvvaSqVava+sycOVPz5s3TwoULtWvXLlWqVEkRERG6cOGCQ3NmeQAAAACK5YUXXlDt2rW1ZMkSW1u9evVsX5umqblz5+rpp59Wjx49JEnLly+Xn5+f1q5dq379+hX5XlRaAQAAXIxh26m15A9HKq0fffSR2rRpo7///e+qVauWWrZsqTfeeMN2PjExUcnJyQoPD7e1+fj4KDQ0VHFxcQ7NmaQVAAAAeaSnp9sdWVlZefr8+OOPWrBggRo1aqSNGzfqkUce0eOPP65ly5ZJkpKTkyVJfn5+dtf5+fnZzhUVSSsAAICLuRFrWmvXri0fHx/bERMTkyeO3NxctWrVSs8995xatmypYcOGaejQoVq4cGGJz5k1rQAAAMjjxIkT8vb2tr329PTM0ycgIEBNmza1a2vSpInef/99SZK/v78kKSUlRQEBAbY+KSkpCgkJcSgeKq0AAAAuxlnrWa/e/9Xb29vuyC9pvfPOO3Xo0CG7tv/85z8KCgqSdPlDWf7+/tq8ebPtfHp6unbt2qWwsDCH5kylFQAAAMUyevRo3XHHHXruuefUp08f7d69W6+//rpef/11SZJhGBo1apSeeeYZNWrUSPXq1dOkSZMUGBionj17OnQvklYAAAAX4+h+qo6OXVR/+ctftGbNGk2cOFHTp09XvXr1NHfuXA0YMMDWZ9y4ccrMzNSwYcOUmpqqu+66Sxs2bJCXl5dDcZG0AgAAoNjuu+8+3XfffQWeNwxD06dP1/Tp06/rPiStAAAALsbtv3+cM7bplHGvFx/EAgAAgOVRaQUAAHAxhhxbe+ro2FZEpRUAAACWR6UVAADAxVy9n6ozxrYiKq0AAACwPCqtAAAALsYq+7TeSFRaAQAAYHlUWgEAAFwMa1oBAAAAC6LSCgAA4GJY0woAAABYEJVWAAAAF8OaVgAAAMCCqLQCAAC4GCqtAAAAgAVRaQUAAHA5l2utzhrbikhaAQAAXAzLAwAAAAALcpmk9ezZsxowYIC8vb3l6+urwYMHKyMjo9D+jz32mIKDg1WhQgXVqVNHjz/+uNLS0uz6GYaR51i1apWzpwMAAFBshpP/WJHLLA8YMGCAkpKStGnTJl28eFFRUVEaNmyYVq5cmW//kydP6uTJk5o1a5aaNm2qn376SQ8//LBOnjyp9957z67vkiVL1LVrV9trX19fZ04FAAAADnKJpPXAgQPasGGDvv76a7Vp00aS9Morr+jee+/VrFmzFBgYmOea2267Te+//77tdYMGDfTss8/qoYce0qVLl1Su3P+m7uvrK39/f+dPBAAAoASwptWi4uLi5Ovra0tYJSk8PFxubm7atWtXkcdJS0uTt7e3XcIqScOHD1eNGjXUtm1bLV68WKZpFjpOVlaW0tPT7Q4AAAA4j0tUWpOTk1WrVi27tnLlyqlatWpKTk4u0hi//vqrZsyYoWHDhtm1T58+Xffcc48qVqyozz77TI8++qgyMjL0+OOPFzhWTEyMpk2b5vhEAAAASoAz155adU1rqVZaJ0yYkO8Hoa4+Dh48eN33SU9PV/fu3dW0aVNNnTrV7tykSZN05513qmXLlho/frzGjRunF198sdDxJk6cqLS0NNtx4sSJ644RAAAABSvVSuuYMWM0aNCgQvvUr19f/v7+OnXqlF37pUuXdPbs2WuuRT137py6du2qKlWqaM2aNSpfvnyh/UNDQzVjxgxlZWXJ09Mz3z6enp4FngMAAHA2NxlyM5y0ptW0ZqW1VJPWmjVrqmbNmtfsFxYWptTUVMXHx6t169aSpC1btig3N1ehoaEFXpeenq6IiAh5enrqo48+kpeX1zXvlZCQoKpVq5KUAgAAWIhLrGlt0qSJunbtqqFDh2rhwoW6ePGiRowYoX79+tl2Dvjll1/UqVMnLV++XG3btlV6erq6dOmi8+fP69///rfdB6Zq1qwpd3d3rVu3TikpKbr99tvl5eWlTZs26bnnntPYsWNLc7oAAACFcpPz1nha9VP6LpG0StKKFSs0YsQIderUSW5uburdu7fmzZtnO3/x4kUdOnRI58+flyTt3bvXtrNAw4YN7cZKTExU3bp1Vb58ec2fP1+jR4+WaZpq2LChZs+eraFDh964iQEAAOCaXCZprVatWoEPEpCkunXr2m1V1aFDh2tuXdW1a1e7hwoAAAC4gisfWHfK2DKkwlOoUmHVCjAAAABg4zKVVgAAAFxWFte0WjUuAAAAwIZKKwAAgItxM5y4TytrWgEAAIDiodIKAADgYoz//nHW2FZEpRUAAACWR6UVAADAxRiG5Oakgqg166xUWgEAAOACqLQCAAC4GKfvHmBBVFoBAABgeVRaAQAAXIwh5609tWadlUorAAAAXACVVgAAABfjZsiJa1qtyapxAQAAADZUWgEAAFyMmwynfcqf3QMAAACAYqLSCgAA4GLcnPhELKtWNK0aFwAAAGBDpRUAAMDFGP/946yxrYhKKwAAACyPSisAAICLYU0rAAAAYEFUWgEAAFyMm2E48YlYrGkFAAAAioVKKwAAgIth9wAAAADAgqi0AgAAuBh2DwAAAAAsiEorAACAizFkOO1T/qxpBQAAAIqJSisAAICLMYzLh1PGds6w141KKwAAACyPSisAAICLcXPimlaeiAUAAAAUE5VWAAAAF+NmGHJz0qJWKq0AAABAMVFpBQAAcDGGnPcpf2vWWam0AgAAwAVQaQUAAHAxrGkFAAAALIhKKwAAgItxMy4fThnbOcNeN6vGBQAAANhQaQUAAHAxPBELAAAAcMDUqVNlGIbd0bhxY9v5CxcuaPjw4apevboqV66s3r17KyUlxeH7kLQCAAC4mD8miSV9OOrWW29VUlKS7di+fbvt3OjRo7Vu3Tq9++672rp1q06ePKlevXo5fA+WBwCFqNK+rqp0qKdy1StKkrJPnlPaxwf1+3en8vSt9XiYKjbz06n5u3Q+IelGhwrAyV586UVNnvK0hj86QrNmvlTa4QCWUq5cOfn7++dpT0tL06JFi7Ry5Urdc889kqQlS5aoSZMm2rlzp26//fYi34NKK1CIS79d0G/v/6CTz8Tq5LOxunDwtGoNv13lA6vY9fMObyDJLJ0gATjdnvg9WrT4DTW7rVlphwJIupzAOfOQpPT0dLsjKyurwHgOHz6swMBA1a9fXwMGDNDx48clSfHx8bp48aLCw8NtfRs3bqw6deooLi7O4TkDKMDv3ybr9+9SdOlUpi6lZCp17QHlZl2SZ/1qtj4etX3k3aWhzizdV4qRAnCWjIwMRQ2O1Kv/t0C+vlVLOxzghqldu7Z8fHxsR0xMTL79QkNDtXTpUm3YsEELFixQYmKi7r77bp07d07Jycny8PCQr6+v3TV+fn5KTk52KB6WBwBFZUiV2twkNw93ZR09e7nJw101hrTWmRXfKCe94P8DBeC6RkWPVNeIbrqnYyc9/8LzpR0OIOnGPBHrxIkT8vb2trV7enrm279bt262r5s3b67Q0FAFBQVp9erVqlChQonFRdIKXEP5m7wVMKGdjPJuMrNydOrV3bqYdE6SVK3Pbco6ela/f+PY/y0CcA2r312thIR92r5tR2mHAtxw3t7edklrUfn6+uqWW27RkSNH1LlzZ2VnZys1NdWu2pqSkpLvGtjCsDwAuIaLyed0cvoXSnpuq9JjE1Xjn61UPqCKKrTwl1fjmjr7zv7SDhGAE5z4+YSeGDdGSxYvk5eXV2mHA+RhOOm4XhkZGTp69KgCAgLUunVrlS9fXps3b7adP3TokI4fP66wsDCHxnW5pHX+/PmqW7euvLy8FBoaqt27dxfa/91331Xjxo3l5eWlZs2a6ZNPPrE7b5qmJk+erICAAFWoUEHh4eE6fPiwM6cAV5Nj6tLpTGUfT1Pqmh+UfSJN3p3qq0LjmipXs5LqvNxdQQsfUNDCByRJNR9pK/+xd5Vy0ACu1759e3Xq9CmF3Rmqyj4VVdmnor7cvk2vLpivyj4VlZOTU9ohogy7sjzAWYcjxo4dq61bt+rYsWPasWOH/vrXv8rd3V39+/eXj4+PBg8erOjoaH3xxReKj49XVFSUwsLCHNo5QHKx5QHvvPOOoqOjtXDhQoWGhmru3LmKiIjQoUOHVKtWrTz9d+zYof79+ysmJkb33XefVq5cqZ49e2rv3r267bbbJEkzZ87UvHnztGzZMtWrV0+TJk1SRESEfvjhB/7PGvlzM2SUd1fqRwd17stjdqdumtZJZ9/Zr9+/ZbkA4Oo6drhHe3bttWsb9shQBd8SrDGjx8rd3b2UIgOs5eeff1b//v115swZ1axZU3fddZd27typmjVrSpLmzJkjNzc39e7dW1lZWYqIiNCrr77q8H0M0zRdZp+e0NBQ/eUvf9H//d//SZJyc3NVu3ZtPfbYY5owYUKe/n379lVmZqY+/vhjW9vtt9+ukJAQLVy4UKZpKjAwUGPGjNHYsWMlXd5PzM/PT0uXLlW/fv2KFFd6erp8fHz07cAVquJRsQRmCqvw/WtT/f5dinLO/i7Dq5wqtb1ZPl0bKWXuDl04cDpP/7pv9GSf1jLAf+69pR0CSkmXrp3VvHlz9mktI9LT0+UXWFNpaWnFWtvpDFdyjq1V/6rKRnmn3CPDvKj2v62x1LwlF1oekJ2drfj4eLt9vtzc3BQeHl7gPl9xcXF2/SUpIiLC1j8xMVHJycl2fXx8fBQaGlro3mFZWVl59i7Dn5O7t6dq/rO1bprRSf7Rd8qzrm+BCSsAAHAel1ke8OuvvyonJ0d+fn527X5+fjp48GC+1yQnJ+fb/8q+YFf+WVif/MTExGjatGkOzwGu58wyx/ZePTZ0rXMCAWAJn23YVNohAJJK7kNTBY1tRS5TabWSiRMnKi0tzXacOHGitEMCAAD4U3OZSmuNGjXk7u6ulJQUu/bC9vny9/cvtP+Vf6akpCggIMCuT0hISIGxeHp6FrjBLgAAgLMZcpNhOKf2aJjWrGlaM6p8eHh4qHXr1nb7fOXm5mrz5s0F7vMVFhZm11+SNm3aZOtfr149+fv72/VJT0/Xrl27HN47DAAAAM7jMpVWSYqOjlZkZKTatGmjtm3bau7cucrMzFRUVJQkaeDAgbrppptsz8YdOXKk2rdvr5deekndu3fXqlWrtGfPHr3++uuSJMMwNGrUKD3zzDNq1KiRbcurwMBA9ezZs7SmCQAAUCjDcGKl1UnjXi+XSlr79u2r06dPa/LkyUpOTlZISIg2bNhg+yDV8ePH5eb2v2/0HXfcoZUrV+rpp5/Wk08+qUaNGmnt2rW2PVolady4ccrMzNSwYcOUmpqqu+66Sxs2bGCPVgAAAAtxqX1arYp9WoGyhX1agbLByvu0flWtjyq7OWmf1tyLuvPsakvNW3KhNa0AAAAou1xqeQAAAAAkGYbkrLWnhjV3aqXSCgAAAMuj0goAAOBiyuLuAdaMCgAAALgKlVYAAAAXYxiGDCetPXXWuNeLSisAAAAsj0orAACAizHkJsNJtUdnjXu9rBkVAAAAcBUqrQAAAK7GMJy3nyprWgEAAIDiodIKAADgYtinFQAAALAgKq0AAAAuht0DAAAAAAui0goAAOBieCIWAAAAYEFUWgEAAFwMuwcAAAAAFkSlFQAAwNUYbpcPZ41tQdaMCgAAALgKlVYAAAAXY/z3j7PGtiIqrQAAALA8Kq0AAAAu5vI+rc7aPYBKKwAAAFAsVFoBAABcjRP3aWX3AAAAAKCYqLQCAAC4GHYPAAAAACyISisAAICr4YlYAAAAgPVQaQUAAHAxl/dpddKaVvZpBQAAAIqHSisAAICLMZy4T6vT9n+9TtaMCgAAALgKlVYAAAAXY8hNhpNqj84a93pZMyoAAADgKlRaAQAAXI1hXD6cNbYFUWkFAACA5VFpBQAAcDHsHgAAAABYEJVWAAAAF8PuAQAAAIAFUWkFAABwMYZhyHDSp/ydNe71otIKAAAAy6PSCgAA4GIMGc7bPUBUWgEAAIBiodIKAADgangiFgAAAGA9VFoBAABcDPu0AgAAABZEpRUAAMDFGIab83YPcNK418uaURVi/vz5qlu3rry8vBQaGqrdu3cX2PeNN97Q3XffrapVq6pq1aoKDw/P03/QoEG2DXqvHF27dnX2NAAAAOAAl0pa33nnHUVHR2vKlCnau3evWrRooYiICJ06dSrf/rGxserfv7+++OILxcXFqXbt2urSpYt++eUXu35du3ZVUlKS7Xj77bdvxHQAAACK5Y8Ft5I+rMilktbZs2dr6NChioqKUtOmTbVw4UJVrFhRixcvzrf/ihUr9OijjyokJESNGzfWm2++qdzcXG3evNmun6enp/z9/W1H1apVb8R0AAAAUEQuk7RmZ2crPj5e4eHhtjY3NzeFh4crLi6uSGOcP39eFy9eVLVq1ezaY2NjVatWLQUHB+uRRx7RmTNnCh0nKytL6enpdgcAAMCNcmVNq7MOK7JmVPn49ddflZOTIz8/P7t2Pz8/JScnF2mM8ePHKzAw0C7x7dq1q5YvX67NmzfrhRde0NatW9WtWzfl5OQUOE5MTIx8fHxsR+3atYs3KQAAgOK48nABZx0WVGZ2D3j++ee1atUqxcbGysvLy9ber18/29fNmjVT8+bN1aBBA8XGxqpTp075jjVx4kRFR0fbXqenp5O4AgAAOJHLJK01atSQu7u7UlJS7NpTUlLk7+9f6LWzZs3S888/r88//1zNmzcvtG/9+vVVo0YNHTlypMCk1dPTU56eno5NAAAAoKS4uV0+nMG05l/EWzOqfHh4eKh169Z2H6K68qGqsLCwAq+bOXOmZsyYoQ0bNqhNmzbXvM/PP/+sM2fOKCAgoETiBgAAwPVzmUqrJEVHRysyMlJt2rRR27ZtNXfuXGVmZioqKkqSNHDgQN10002KiYmRJL3wwguaPHmyVq5cqbp169rWvlauXFmVK1dWRkaGpk2bpt69e8vf319Hjx7VuHHj1LBhQ0VERJTaPAEAAApjGoZMJ609dda418ulkta+ffvq9OnTmjx5spKTkxUSEqINGzbYPpx1/PhxuV1VKl+wYIGys7P1t7/9zW6cKVOmaOrUqXJ3d9e3336rZcuWKTU1VYGBgerSpYtmzJjBX/8DAABYiEslrZI0YsQIjRgxIt9zsbGxdq+PHTtW6FgVKlTQxo0bSygyAACAG8TNuHw4g2nNSqvLrGkFAABA2eVylVYAAIAyj0orAAAAUDzPP/+8DMPQqFGjbG0XLlzQ8OHDVb16dVWuXFm9e/fOs4VpUZC0AgAAuJorlVZnHcXw9ddf67XXXsuzJ/7o0aO1bt06vfvuu9q6datOnjypXr16OT7lYkUFAAAA/FdGRoYGDBigN954Q1WrVrW1p6WladGiRZo9e7buuecetW7dWkuWLNGOHTu0c+dOh+5B0goAAOBiTDdDppubk47Lldb09HS7Iysrq8B4hg8fru7duys8PNyuPT4+XhcvXrRrb9y4serUqaO4uDiH5kzSCgAAgDxq164tHx8f23Hl4U1/tGrVKu3duzff88nJyfLw8JCvr69du5+fn+2hT0XF7gEAAACuxnDi7gG5l8c9ceKEvL29bc35PXjpxIkTGjlypDZt2iQvLy/nxPNfVFoBAACQh7e3t92RX9IaHx+vU6dOqVWrVipXrpzKlSunrVu3at68eSpXrpz8/PyUnZ2t1NRUu+tSUlLk7+/vUDxUWgEAAFyNM/dpdWDcTp06af/+/XZtUVFRaty4scaPH6/atWurfPny2rx5s3r37i1JOnTokI4fP66wsDCHwiJpBQAAQLFUqVJFt912m11bpUqVVL16dVv74MGDFR0drWrVqsnb21uPPfaYwsLCdPvttzt0L5JWAAAAV2ORSmtRzJkzR25uburdu7eysrIUERGhV1991eFxSFoBAABQYmJjY+1ee3l5af78+Zo/f/51jUvSCgAA4GIu79PqnEqrs8a9XuweAAAAAMuj0goAAOBqDLfLh7PGtiBrRgUAAABchUorAACAq3Gh3QNKCpVWAAAAWB6VVgAAAFdDpRUAAACwHiqtAAAALoZ9WgEAAAALotIKAADgasrgmtYiJa0fffRRkQd84IEHih0MAAAAkJ8iJa09e/Ys0mCGYSgnJ+d64gEAAMC1uLldPpw1tgUVKWnNzc11dhwAAABAga5rTeuFCxfk5eVVUrEAAACgKAwnrmk1rLmm1eH6b05OjmbMmKGbbrpJlStX1o8//ihJmjRpkhYtWlTiAQIAAAAOJ63PPvusli5dqpkzZ8rDw8PWftttt+nNN98s0eAAAACQ15V9Wp11WJHDSevy5cv1+uuva8CAAXJ3d7e1t2jRQgcPHizR4AAAAACpGGtaf/nlFzVs2DBPe25uri5evFgiQQEAAKAQhuG8tad/ljWtTZs21Zdffpmn/b333lPLli1LJCgAAADgag5XWidPnqzIyEj98ssvys3N1QcffKBDhw5p+fLl+vjjj50RIwAAAK5WBp+I5XCltUePHlq3bp0+//xzVapUSZMnT9aBAwe0bt06de7c2RkxAgAAoIwr1j6td999tzZt2lTSsQAAAKAoymCltdgPF9izZ48OHDgg6fI619atW5dYUAAAAMDVHE5af/75Z/Xv319fffWVfH19JUmpqam64447tGrVKt18880lHSMAAACucnk/VYdXeRZ5bCtyeLZDhgzRxYsXdeDAAZ09e1Znz57VgQMHlJubqyFDhjgjRgAAAJRxDldat27dqh07dig4ONjWFhwcrFdeeUV33313iQYHAACAfJTBNa0OV1pr166d70MEcnJyFBgYWCJBAQAAAFdzOGl98cUX9dhjj2nPnj22tj179mjkyJGaNWtWiQYHAACAfFyptDrrsKAiLQ+oWrWqjKse6ZWZmanQ0FCVK3f58kuXLqlcuXL65z//qZ49ezolUAAAAJRdRUpa586d6+QwAAAAUGRlcE1rkZLWyMhIZ8cBAAAAFKjYDxeQpAsXLig7O9uuzdvb+7oCAgAAQOEu79PqnIron2af1szMTI0YMUK1atVSpUqVVLVqVbsDAAAAKGkOJ63jxo3Tli1btGDBAnl6eurNN9/UtGnTFBgYqOXLlzsjRgAAAFzNcJPcnHQYznnS1vVyeHnAunXrtHz5cnXo0EFRUVG6++671bBhQwUFBWnFihUaMGCAM+IEAABAGeZwKn327FnVr19f0uX1q2fPnpUk3XXXXdq2bVvJRgcAAIC8DMO5hwU5nLTWr19fiYmJkqTGjRtr9erVki5XYH19fUs0OAAAAEAqRtIaFRWlb775RpI0YcIEzZ8/X15eXho9erSeeOKJEg8QAAAAf1AGn4jlcNI6evRoPf7445Kk8PBwHTx4UCtXrtS+ffs0cuTIEg/wj+bPn6+6devKy8tLoaGh2r17d4F9ly5dKsMw7A4vLy+7PqZpavLkyQoICFCFChUUHh6uw4cPO3saAAAAcMB1fzwsKChIvXr1UvPmzUsinkK98847io6O1pQpU7R37161aNFCEREROnXqVIHXeHt7KykpyXb89NNPdudnzpypefPmaeHChdq1a5cqVaqkiIgIXbhwwdnTAQAAKJYr+7Q667CiIu0eMG/evCIPeKUK6wyzZ8/W0KFDFRUVJUlauHCh1q9fr8WLF2vChAn5XmMYhvz9/fM9Z5qm5s6dq6efflo9evSQJC1fvlx+fn5au3at+vXr55yJAAAAwCFFSlrnzJlTpMEMw3Ba0pqdna34+HhNnDjR1ubm5qbw8HDFxcUVeF1GRoaCgoKUm5urVq1a6bnnntOtt94qSUpMTFRycrLCw8Nt/X18fBQaGqq4uDiSVgAAYE3OXHvqypXWK7sFlKZff/1VOTk58vPzs2v38/PTwYMH870mODhYixcvVvPmzZWWlqZZs2bpjjvu0Pfff6+bb75ZycnJtjH+OOaVc/nJyspSVlaW7XV6erokqcrT7VWlCo+xBf7sRlW+pbRDAHADZCu3tEPAVaz5yIMSEhYWpoEDByokJETt27fXBx98oJo1a+q11167rnFjYmLk4+NjO2rXrl1CEQMAABQBuwdYV40aNeTu7q6UlBS79pSUlALXrP5R+fLl1bJlSx05ckSSbNc5OubEiROVlpZmO06cOOHIVAAAAK6LaRhOPazIZZJWDw8PtW7dWps3b7a15ebmavPmzQoLCyvSGDk5Odq/f78CAgIkSfXq1ZO/v7/dmOnp6dq1a1ehY3p6esrb29vuAAAAgPMUaU2rVURHRysyMlJt2rRR27ZtNXfuXGVmZtp2Exg4cKBuuukmxcTESJKmT5+u22+/XQ0bNlRqaqpefPFF/fTTTxoyZIikyx8cGzVqlJ555hk1atRI9erV06RJkxQYGKiePXuW1jQBAAAK5cytqVx6yyur6Nu3r06fPq3JkycrOTlZISEh2rBhg+2DVMePH5eb2/+Kx7/99puGDh2q5ORkVa1aVa1bt9aOHTvUtGlTW59x48YpMzNTw4YNU2pqqu666y5t2LAhz0MIAAAAUHoM0zRNRy/68ssv9dprr+no0aN67733dNNNN+mtt95SvXr1dNdddzkjTktLT0+Xj4+PEv/zM7sHAGXAUwHNSjsEADdAtnK1RCeUlpZmmaWAV3KOhCHvqIpHRafc41z2eYW82ddS85aKsab1/fffV0REhCpUqKB9+/bZtn5KS0vTc889V+IBAgAAAA4nrc8884wWLlyoN954Q+XLl7e133nnndq7d2+JBgcAAIC8TDfnHlbkcFiHDh1Su3bt8rT7+PgoNTW1JGICAAAA7DictPr7+9v2Ob3a9u3bVb9+/RIJCgAAAAVjn9YiGDp0qEaOHKldu3bJMAydPHlSK1as0NixY/XII484I0YAAACUcQ5veTVhwgTl5uaqU6dOOn/+vNq1aydPT0+NHTtWjz32mDNiBAAAwNUMJz5u1aKVVoeTVsMw9NRTT+mJJ57QkSNHlJGRoaZNm6py5crOiA8AAAAo/sMFPDw87DbpBwAAwA1iSKazCqLWLLQ6nrR27NhRRiFl4y1btlxXQAAAAMAfOZy0hoSE2L2+ePGiEhIS9N133ykyMrKk4gIAAEABTDdDppPWtDpr3OvlcNI6Z86cfNunTp2qjIyM6w4IAAAA+KMSe+bBQw89pMWLF5fUcAAAACiAaThzr9bSnl3+SixpjYuLk5eXV0kNBwAAANg4vDygV69edq9N01RSUpL27NmjSZMmlVhgAAAAKIBhOG8/1T/LPq0+Pj52r93c3BQcHKzp06erS5cuJRYYAAAAcIVDSWtOTo6ioqLUrFkzVa1a1VkxAQAAoBCm2+XDWWNbkUNhubu7q0uXLkpNTXVSOAAAAEBeDufSt912m3788UdnxAIAAIAicN7OAZcPK3I4aX3mmWc0duxYffzxx0pKSlJ6errdAQAAAJS0Iq9pnT59usaMGaN7771XkvTAAw/YPc7VNE0ZhqGcnJySjxIAAAD/42ZcPpw1tgUVOWmdNm2aHn74YX3xxRfOjAcAAADIo8hJq2makqT27ds7LRgAAABc2+UnYjlvbCtyaE2rYdGFuQAAAPhzcyhpveWWW1StWrVCDwAAADiX6WY49XDEggUL1Lx5c3l7e8vb21thYWH69NNPbecvXLig4cOHq3r16qpcubJ69+6tlJQUh+fs0MMFpk2blueJWAAAACi7br75Zj3//PNq1KiRTNPUsmXL1KNHD+3bt0+33nqrRo8erfXr1+vdd9+Vj4+PRowYoV69eumrr75y6D4OJa39+vVTrVq1HLoBAAAASphhXD6cNbYD7r//frvXzz77rBYsWKCdO3fq5ptv1qJFi7Ry5Urdc889kqQlS5aoSZMm2rlzp26//fYi36fIywNYzwoAAFB2/HEv/qysrGtek5OTo1WrVikzM1NhYWGKj4/XxYsXFR4ebuvTuHFj1alTR3FxcQ7FU+Sk9cruAQAAAChdN2JNa+3ateXj42M7YmJiCoxn//79qly5sjw9PfXwww9rzZo1atq0qZKTk+Xh4SFfX1+7/n5+fkpOTnZozkVeHpCbm+vQwAAAAHBdJ06ckLe3t+21p6dngX2Dg4OVkJCgtLQ0vffee4qMjNTWrVtLNB6H1rQCAACg9Jly4j6t//3nld0AisLDw0MNGzaUJLVu3Vpff/21Xn75ZfXt21fZ2dlKTU21q7ampKTI39/fobgc2vIKAAAAuJbc3FxlZWWpdevWKl++vDZv3mw7d+jQIR0/flxhYWEOjUmlFQAAwNW4GZcPZ43tgIkTJ6pbt26qU6eOzp07p5UrVyo2NlYbN26Uj4+PBg8erOjoaFWrVk3e3t567LHHFBYW5tDOARJJKwAAAK7DqVOnNHDgQCUlJcnHx0fNmzfXxo0b1blzZ0nSnDlz5Obmpt69eysrK0sRERF69dVXHb4PSSsAAICLMQ1DppO2I3V03EWLFhV63svLS/Pnz9f8+fOvJyzWtAIAAMD6qLQCAAC4mKv3U3XG2FZEpRUAAACWR6UVAADAxZiGE/dptWahlUorAAAArI9KKwAAgKux0D6tNwqVVgAAAFgelVYAAAAXY6V9Wm8UKq0AAACwPCqtAAAALsZ0u3w4a2wrsmhYAAAAwP9QaQUAAHA1hnH5cNbYFkSlFQAAAJZHpRUAAMDFmG6GTCftp+qsca8XlVYAAABYHpVWAAAAF8M+rQAAAIAFUWkFAABwNcZ/D2eNbUEuV2mdP3++6tatKy8vL4WGhmr37t0F9u3QoYMMw8hzdO/e3dZn0KBBec537dr1RkwFAAAAReRSldZ33nlH0dHRWrhwoUJDQzV37lxFRETo0KFDqlWrVp7+H3zwgbKzs22vz5w5oxYtWujvf/+7Xb+uXbtqyZIltteenp7OmwQAAMB1Mg0n7h7AmtbrN3v2bA0dOlRRUVFq2rSpFi5cqIoVK2rx4sX59q9WrZr8/f1tx6ZNm1SxYsU8Saunp6ddv6pVq96I6QAAAKCIXCZpzc7OVnx8vMLDw21tbm5uCg8PV1xcXJHGWLRokfr166dKlSrZtcfGxqpWrVoKDg7WI488ojNnzpRo7AAAACXpyu4BzjqsyGWWB/z666/KycmRn5+fXbufn58OHjx4zet3796t7777TosWLbJr79q1q3r16qV69erp6NGjevLJJ9WtWzfFxcXJ3d0937GysrKUlZVle52enl6MGQEAAKCoXCZpvV6LFi1Ss2bN1LZtW7v2fv362b5u1qyZmjdvrgYNGig2NladOnXKd6yYmBhNmzbNqfECAAAUyE3O+/tyi/49vEXDyqtGjRpyd3dXSkqKXXtKSor8/f0LvTYzM1OrVq3S4MGDr3mf+vXrq0aNGjpy5EiBfSZOnKi0tDTbceLEiaJNAgAAAMXiMkmrh4eHWrdurc2bN9vacnNztXnzZoWFhRV67bvvvqusrCw99NBD17zPzz//rDNnziggIKDAPp6envL29rY7AAAAbpT8tvQsycOKXCZplaTo6Gi98cYbWrZsmQ4cOKBHHnlEmZmZioqKkiQNHDhQEydOzHPdokWL1LNnT1WvXt2uPSMjQ0888YR27typY8eOafPmzerRo4caNmyoiIiIGzInAAAAXJtLrWnt27evTp8+rcmTJys5OVkhISHasGGD7cNZx48fl5ubfR5+6NAhbd++XZ999lme8dzd3fXtt99q2bJlSk1NVWBgoLp06aIZM2awVysAALAuQ5KzKqLWLLS6VtIqSSNGjNCIESPyPRcbG5unLTg4WKZp5tu/QoUK2rhxY0mGBwAA4Hw8xhUAAACwHpertAIAAJR1zvzAFB/EAgAAAIqJSisAAICr4eECAAAAgPVQaQUAAHA1huHELa9Y0woAAAAUC5VWAAAAF8PuAQAAAIAFUWkFAABwNTwRCwAAALAeKq0AAACuht0DAAAAAOuh0goAAOBiymChlUorAAAArI9KKwAAgKspg6VWKq0AAACwPCqtAAAArsbNuHw4a2wLotIKAAAAy6PSCgAA4GIMOXFJq3OGvW5UWgEAAGB5VFoBAABcDbsHAAAAANZDpRUAAMDVGHLe4lNrFlqptAIAAMD6qLQCAAC4GMMwZDhp7amzxr1eVFoBAABgeVRaAQAAXA27BwAAAADWQ6UVAADA1bjJeaVHi5Y0LRoWAAAA8D9UWgEAAFwMuwcAAAAAFkSlFQAAwNXwRCwAAADAeqi0AgAAuBr2aQUAAACsh0orAACAiymDhVYqrQAAALA+Kq0AAACupgyWWqm0AgAAwPKotAIAALgaN+Py4ayxLYhKKwAAACyPSisAAICLKYNLWqm0AgAAoHhiYmL0l7/8RVWqVFGtWrXUs2dPHTp0yK7PhQsXNHz4cFWvXl2VK1dW7969lZKS4vC9SFoBAABczZVSq7OOItq6dauGDx+unTt3atOmTbp48aK6dOmizMxMW5/Ro0dr3bp1evfdd7V161adPHlSvXr1cnjKLA8AAABAsWzYsMHu9dKlS1WrVi3Fx8erXbt2SktL06JFi7Ry5Urdc889kqQlS5aoSZMm2rlzp26//fYi34tKK+Cgcxnn9NSk8Qppc6turldL3e4P196E+NIOC0AJ8A30U9RbczTr132ad/6gJn27QXVaN8u374MLntVC85juGfnPGxwlcGMKrenp6XZHVlbWNeNKS0uTJFWrVk2SFB8fr4sXLyo8PNzWp3HjxqpTp47i4uIcmjNJK+CgUWMeU+y2L/TqK69r25Y4dWh/j3r36aGkpJOlHRqA61DR11tPfPW+ci5e0v91G6RpTcP13phndf63tDx9Q3pGqN7tLZX6S3IpRArcGLVr15aPj4/tiImJKbR/bm6uRo0apTvvvFO33XabJCk5OVkeHh7y9fW16+vn56fkZMd+flgeADjg999/18frP9RbS9/WHWF3SpLGj31SGz/boCXL3tSTEyaXcoQAiqvL+Ed09sRJLf/nE7a2M8d+ztPPN9BPfV+ZqnkRAzVi/ZIbGSLwPzdg+4ATJ07I29vb1uzp6VnoZcOHD9d3332n7du3OyUsKq2AAy7lXFJOTo68PL3s2it4eWnn7p2lFBWAktDigXAd37NfQ1fP18yUPXpy73rdNaSfXR/DMDTorTna9OLrSvrhcClFCtwY3t7edkdhSeuIESP08ccf64svvtDNN99sa/f391d2drZSU1Pt+qekpMjf39+heEhaAQdUqVxFf2nTVrPmzFRScpJycnK0+r1V+jp+t1JO8deEgCurUb+O2j3ykE4dPqZXIiK1bcG/1WfeVN0+sLetT5fxjyj30iVtmUeFFaXMIrsHmKapESNGaM2aNdqyZYvq1atnd75169YqX768Nm/ebGs7dOiQjh8/rrCwMIem7FJJ67Zt23T//fcrMDBQhmFo7dq117wmNjZWrVq1kqenpxo2bKilS5fm6TN//nzVrVtXXl5eCg0N1e7du0s+ePxpvPrK6zJNU81aBiswqIbeWLRQvXr+TW6GS/04AfgDw83Q8b3f6cOnXtSJhO+1/Y23tf2Nt9Xu4QGSpDqtbtM9I6O0bNDYUo4UsI7hw4fr3//+t1auXKkqVaooOTlZycnJ+v333yVJPj4+Gjx4sKKjo/XFF18oPj5eUVFRCgsLc2jnAMnFktbMzEy1aNFC8+fPL1L/xMREde/eXR07dlRCQoJGjRqlIUOGaOPGjbY+77zzjqKjozVlyhTt3btXLVq0UEREhE6dOuWsacDF1atbX+vWfKqfjibpm/gD2vRprC5euqSgoLqlHRqA65CWdCrPX/knHziqanUCJUkN726rKrWq67njOzT/4hHNv3hE1everL+99JSeTXTOGj6gIIYhGW5OOhxYKrtgwQKlpaWpQ4cOCggIsB3vvPOOrc+cOXN03333qXfv3mrXrp38/f31wQcfODxnl/ogVrdu3dStW7ci91+4cKHq1aunl156SZLUpEkTbd++XXPmzFFERIQkafbs2Ro6dKiioqJs16xfv16LFy/WhAkTSn4S+NOoVLGSKlWspNTU3/RF7GZNeXp6aYcE4Doc/SpefsH17dr8bqmnMz/9Ikna9dYHOvi5fXL6+Mbl2vnWGsUtefeGxQlYiWma1+zj5eWl+fPnF7noWBCXSlodFRcXZ7cvmCRFRERo1KhRkqTs7GzFx8dr4sSJtvNubm4KDw93eO8wlB1bvvhcpmmqYcNGSkz8UVNnTFKjho30YL+HSjs0ANdh85xFGrfjfXWd+KjiV69X3bYtdNew/lox7PJ/IzLPpirzbKrdNTkXLyk9+bRS/vNjKUSMMu0G7B5gNX/qpDU5OVl+fn52bX5+fkpPT9fvv/+u3377TTk5Ofn2OXjwYIHjZmVl2W2wm56eXrKBw9LSz6Xrmeem6mTSSfn6VtX93R/QUxMmq3z58qUdGoDr8NOeb7Xwr/9Sz5hx6j55pH5NPKF3R03X7pUflnZoAPQnT1qdJSYmRtOmTSvtMFBKej7QSz0fcPyZyQCsb//6Ldq/fkuR+z9V7y4nRgMUwvjv4ayxLcilPojlKH9/f6WkpNi1paSkyNvbWxUqVFCNGjXk7u6eb5/C9g6bOHGi0tLSbMeJEyecEj8AAAAu+1MnrWFhYXb7gknSpk2bbPuCeXh4qHXr1nZ9cnNztXnz5kL3DvP09Myz4S4AAMCNcnlJq+Gko7Rnlz+XSlozMjKUkJCghIQESZe3tEpISNDx48clXa6ADhw40Nb/4Ycf1o8//qhx48bp4MGDevXVV7V69WqNHj3a1ic6OlpvvPGGli1bpgMHDuiRRx5RZmambTcBAAAAlD6XWtO6Z88edezY0fY6OjpakhQZGamlS5cqKSnJlsBKUr169bR+/XqNHj1aL7/8sm6++Wa9+eabtu2uJKlv3746ffq0Jk+erOTkZIWEhGjDhg15PpwFAABgFVeqos4a24oMsygbbKFQ6enp8vHxUeJ/flaVKiwVAP7sngpoVtohALgBspWrJTqhtLQ0yywFvJJz7P5wnypXquKUe2RknlPbHi0tNW/JxSqtAAAA0OUFns5a5GnRxaMWDQsAAAD4HyqtAAAALqYsrmklaQUAAHA1ZfAxriwPAAAAgOVRaQUAAHAxZbDQSqUVAAAA1kelFQAAwMUYboYMNyd9EMtJ414vKq0AAACwPCqtAAAArqYMLmql0goAAADLo9IKAADgYspgoZVKKwAAAKyPSisAAICrKYOlViqtAAAAsDwqrQAAAK7Gifu0in1aAQAAgOKh0goAAOBiDDlxSatzhr1uVFoBAABgeVRaAQAAXA27BwAAAADWQ6UVAADAxRhO3D3AabsSXCcqrQAAALA8Kq0AAACuxpDzPuZvzUIrlVYAAABYH5VWAAAAF2MYhgwnfcrfWeNeLyqtAAAAsDwqrQAAAC6GSisAAABgQVRaAQAAXI2bnFd6tGhJ06JhAQAAAP9DpRUAAMDFsKYVAAAAsCAqrQAAAK7GMC4fzhrbgqi0AgAAwPKotAIAALiYMlhopdIKAAAA66PSCgAA4GIMN0OGm5N2D3DSuNeLSisAAAAsj0orAACAqymDi1qptAIAAMDyqLQCAAC4mDJYaKXSCgAAAOuj0goAAOBqymCplUorAAAALI9KKwAAgIsxDCfu00qlFQAAACgeKq0AAAAupgwuaaXSCgAAAOuj0goAAOBqDDmx1OqcYa8XlVYAAABYHpVWAAAAF2MYhtM+5c/uASVg27Ztuv/++xUYGCjDMLR27dpC+3/wwQfq3LmzatasKW9vb4WFhWnjxo12faZOnWp7468cjRs3duIsAAAA4CiXSlozMzPVokULzZ8/v0j9t23bps6dO+uTTz5RfHy8OnbsqPvvv1/79u2z63frrbcqKSnJdmzfvt0Z4QMAAJQMNycfFuRSywO6deumbt26Fbn/3Llz7V4/99xz+vDDD7Vu3Tq1bNnS1l6uXDn5+/uXVJgAAAAoYRbNpZ0jNzdX586dU7Vq1ezaDx8+rMDAQNWvX18DBgzQ8ePHSylCAACAa/vj0saSPqzIpSqt12vWrFnKyMhQnz59bG2hoaFaunSpgoODlZSUpGnTpunuu+/Wd999pypVquQ7TlZWlrKysmyv09PTnR47AABAWVZmktaVK1dq2rRp+vDDD1WrVi1b+9XLDZo3b67Q0FAFBQVp9erVGjx4cL5jxcTEaNq0aU6PGQAAIF+GnLefqjULrWVjecCqVas0ZMgQrV69WuHh4YX29fX11S233KIjR44U2GfixIlKS0uzHSdOnCjpkAEAAHCVP33S+vbbbysqKkpvv/22unfvfs3+GRkZOnr0qAICAgrs4+npKW9vb7sDAADgRjGc/MeKXGp5QEZGhl0FNDExUQkJCapWrZrq1KmjiRMn6pdfftHy5cslXV4SEBkZqZdfflmhoaFKTk6WJFWoUEE+Pj6SpLFjx+r+++9XUFCQTp48qSlTpsjd3V39+/e/8RMEAABAvlyq0rpnzx61bNnStl1VdHS0WrZsqcmTJ0uSkpKS7D75//rrr+vSpUsaPny4AgICbMfIkSNtfX7++Wf1799fwcHB6tOnj6pXr66dO3eqZs2aN3ZyAAAARWU4+bAgl6q0dujQQaZpFnh+6dKldq9jY2OvOeaqVauuMyoAAAA4m0slrQAAACiTmwe41vIAAAAAlE0krQAAAK7GMJx7OGDbtm26//77FRgYKMMwtHbtWrvzpmlq8uTJCggIUIUKFRQeHq7Dhw87PGWSVgAAABRbZmamWrRoofnz5+d7fubMmZo3b54WLlyoXbt2qVKlSoqIiNCFCxccug9rWgEAAFxMMQqiDo3tiG7dutk9YfRqpmlq7ty5evrpp9WjRw9J0vLly+Xn56e1a9eqX79+Rb4PlVYAAADkkZ6ebndkZWU5PEZiYqKSk5Ptnkjq4+Oj0NBQxcXFOTQWSSsAAADyqF27tnx8fGxHTEyMw2NcebCTn5+fXbufn5/tXFGxPAAAAMDF3IjlASdOnLB7VL2np6dzblhEVFoBAACQh7e3t91RnKTV399fkpSSkmLXnpKSYjtXVCStAAAALsc1nuNar149+fv7a/Pmzba29PR07dq1S2FhYQ6NxfIAAAAAFFtGRoaOHDlie52YmKiEhARVq1ZNderU0ahRo/TMM8+oUaNGqlevniZNmqTAwED17NnTofuQtAIAALgYK215tWfPHnXs2NH2Ojo6WpIUGRmppUuXaty4ccrMzNSwYcOUmpqqu+66Sxs2bJCXl5dD9yFpBQAAQLF16NBBpmkWeN4wDE2fPl3Tp0+/rvuwphUAAACWR9IKAAAAy2N5AAAAgKsxDBlWWdR6g1BpBQAAgOVRaQUAAHA1Jbudat6xLYhKKwAAACyPSisAAICLKYOFViqtAAAAsD4qrQAAAK7GSo/EukGotAIAAMDyqLQCAAC4GNa0AgAAABZEpRUAAMDVlMFSK5VWAAAAWB6VVgAAABdjGIYMJ33K31njXi8qrQAAALA8klYAAABYHkkrAAAALI81rQAAAC7GkBMfiOWcYa8blVYAAABYHpVWAAAAl1P2Nmql0goAAADLo9IKAADgYgzDiWtarVlopdIKAAAA66PSCgAA4GrK3pJWKq0AAACwPiqtAAAALqYMFlqptAIAAMD6qLQCAAC4mjK4fQCVVgAAAFgelVYAAAAXw5pWAAAAwIKotAIAALiaMlhqpdIKAAAAy6PSCgAA4GIMw5DhpE/5O2vc60WlFQAAAJZH0goAAADLI2kFAACA5bGmFQAAwMWUwQdiuValddu2bbr//vsVGBgowzC0du3aQvvHxsbaFipffSQnJ9v1mz9/vurWrSsvLy+FhoZq9+7dTpwFAAAAHOVSSWtmZqZatGih+fPnO3TdoUOHlJSUZDtq1aplO/fOO+8oOjpaU6ZM0d69e9WiRQtFRETo1KlTJR0+AABACTGcfFiPSy0P6Natm7p16+bwdbVq1ZKvr2++52bPnq2hQ4cqKipKkrRw4UKtX79eixcv1oQJE64nXAAAAJQQl6q0FldISIgCAgLUuXNnffXVV7b27OxsxcfHKzw83Nbm5uam8PBwxcXFlUaoAAAA13RlTauzDityqUqrowICArRw4UK1adNGWVlZevPNN9WhQwft2rVLrVq10q+//qqcnBz5+fnZXefn56eDBw8WOG5WVpaysrJsr9PS0iRJ5zLOOWciACwlW7mlHQKAG+DKz7ppmqUcSV7p59Jdcuzr8adOWoODgxUcHGx7fccdd+jo0aOaM2eO3nrrrWKPGxMTo2nTpuVpb96qSbHHBAAA1nTmzBn5+PiUdhiSJA8PD/n7+6tRcAOn3sff318eHh5OvYej/tRJa37atm2r7du3S5Jq1Kghd3d3paSk2PVJSUmRv79/gWNMnDhR0dHRttepqakKCgrS8ePHLfMv9Y2Snp6u2rVr68SJE/L29i7tcG4o5s7cmXvZwdzL5tzT0tJUp04dVatWrbRDsfHy8lJiYqKys7Odeh8PDw95eXk59R6OKnNJa0JCggICAiRdfkNat26tzZs3q2fPnpKk3Nxcbd68WSNGjChwDE9PT3l6euZp9/HxKXM/0Fd4e3sz9zKIuTP3soa5l825u7lZ6yNAXl5elksobwSXSlozMjJ05MgR2+vExEQlJCSoWrVqqlOnjiZOnKhffvlFy5cvlyTNnTtX9erV06233qoLFy7ozTff1JYtW/TZZ5/ZxoiOjlZkZKTatGmjtm3bau7cucrMzLTtJgAAAIDS51JJ6549e9SxY0fb6yt/RR8ZGamlS5cqKSlJx48ft53Pzs7WmDFj9Msvv6hixYpq3ry5Pv/8c7sx+vbtq9OnT2vy5MlKTk5WSEiINmzYkOfDWQAAACg9LpW0dujQodBP8C1dutTu9bhx4zRu3LhrjjtixIhClwNci6enp6ZMmZLvkoE/O+bO3Msa5s7cyxrmXjbnbkWGacV9HAAAAICrWGtlMQAAAJAPklYAAABYHkkrAAAALI+ktQjOnj2rAQMGyNvbW76+vho8eLAyMjIKvaZDhw4yDMPuePjhh+36HD9+XN27d1fFihVVq1YtPfHEE7p06ZIzp+IwR+d+9uxZPfbYYwoODlaFChVUp04dPf7447ZH3V7xx++NYRhatWqVs6dTqPnz56tu3bry8vJSaGiodu/eXWj/d999V40bN5aXl5eaNWumTz75xO68aZqaPHmyAgICVKFCBYWHh+vw4cPOnEKxOTL3N954Q3fffbeqVq2qqlWrKjw8PE//QYMG5Xl/u3bt6uxpFIsjc1+6dGmeef1xr8Q/6/ue3+80wzDUvXt3Wx9Xed+3bdum+++/X4GBgTIMQ2vXrr3mNbGxsWrVqpU8PT3VsGHDPB/8lRz/HVIaHJ37Bx98oM6dO6tmzZry9vZWWFiYNm7caNdn6tSped73xo0bO3EWxePo3GNjY/P9dz45Odmunyu8738aJq6pa9euZosWLcydO3eaX375pdmwYUOzf//+hV7Tvn17c+jQoWZSUpLtSEtLs52/dOmSedttt5nh4eHmvn37zE8++cSsUaOGOXHiRGdPxyGOzn3//v1mr169zI8++sg8cuSIuXnzZrNRo0Zm79697fpJMpcsWWL3/fn999+dPZ0CrVq1yvTw8DAXL15sfv/99+bQoUNNX19fMyUlJd/+X331lenu7m7OnDnT/OGHH8ynn37aLF++vLl//35bn+eff9708fEx165da37zzTfmAw88YNarV69U55kfR+f+4IMPmvPnzzf37dtnHjhwwBw0aJDp4+Nj/vzzz7Y+kZGRZteuXe3e37Nnz96oKRWZo3NfsmSJ6e3tbTev5ORkuz5/1vf9zJkzdvP+7rvvTHd3d3PJkiW2Pq7yvn/yySfmU089ZX7wwQemJHPNmjWF9v/xxx/NihUrmtHR0eYPP/xgvvLKK6a7u7u5YcMGWx9Hv5+lxdG5jxw50nzhhRfM3bt3m//5z3/MiRMnmuXLlzf37t1r6zNlyhTz1ltvtXvfT58+7eSZOM7RuX/xxRemJPPQoUN2c8vJybH1cZX3/c+CpPUafvjhB1OS+fXXX9vaPv30U9MwDPOXX34p8Lr27dubI0eOLPD8J598Yrq5udn9B2/BggWmt7e3mZWVVSKxX6/izv2PVq9ebXp4eJgXL160tRXlF8aN1LZtW3P48OG21zk5OWZgYKAZExOTb/8+ffqY3bt3t2sLDQ01//Wvf5mmaZq5ubmmv7+/+eKLL9rOp6ammp6enubbb7/thBkUn6Nz/6NLly6ZVapUMZctW2Zri4yMNHv06FHSoZY4R+e+ZMkS08fHp8DxytL7PmfOHLNKlSpmRkaGrc1V3verFeV30bhx48xbb73Vrq1v375mRESE7fX1fj9LQ3F/Dzdt2tScNm2a7fWUKVPMFi1alFxgN4AjSetvv/1WYB9XfN9dGcsDriEuLk6+vr5q06aNrS08PFxubm7atWtXodeuWLFCNWrU0G233aaJEyfq/PnzduM2a9bM7iEGERERSk9P1/fff1/yEymG65n71dLS0uTt7a1y5ey3BR4+fLhq1Kihtm3bavHixYXuwetM2dnZio+PV3h4uK3Nzc1N4eHhiouLy/eauLg4u/7S5ffvSv/ExEQlJyfb9fHx8VFoaGiBY5aG4sz9j86fP6+LFy/meTZ3bGysatWqpeDgYD3yyCM6c+ZMicZ+vYo794yMDAUFBal27drq0aOH3c9rWXrfFy1apH79+qlSpUp27VZ/34vjWj/vJfH9dBW5ubk6d+5cnp/3w4cPKzAwUPXr19eAAQPsHvTj6kJCQhQQEKDOnTvrq6++srWXpffdKlzq4QKlITk5WbVq1bJrK1eunKpVq5ZnXcvVHnzwQQUFBSkwMFDffvutxo8fr0OHDumDDz6wjfvHp25deV3YuDdSced+tV9//VUzZszQsGHD7NqnT5+ue+65RxUrVtRnn32mRx99VBkZGXr88cdLLP6i+vXXX5WTk5Pv+3Hw4MF8ryno/bvyfbnyz8L6WEFx5v5H48ePV2BgoN0v7q5du6pXr16qV6+ejh49qieffFLdunVTXFyc3N3dS3QOxVWcuQcHB2vx4sVq3ry50tLSNGvWLN1xxx36/vvvdfPNN5eZ93337t367rvvtGjRIrt2V3jfi6Ogn/f09HT9/vvv+u23367758hVzJo1SxkZGerTp4+tLTQ0VEuXLlVwcLCSkpI0bdo03X333fruu+9UpUqVUoz2+gQEBGjhwoVq06aNsrKy9Oabb6pDhw7atWuXWrVqVSK/P+GYMpu0TpgwQS+88EKhfQ4cOFDs8a9O0po1a6aAgAB16tRJR48eVYMGDYo9bklw9tyvSE9PV/fu3dW0aVNNnTrV7tykSZNsX7ds2VKZmZl68cUXSyVpRfE9//zzWrVqlWJjY+0+kNSvXz/b182aNVPz5s3VoEEDxcbGqlOnTqURaokICwtTWFiY7fUdd9yhJk2a6LXXXtOMGTNKMbIba9GiRWrWrJnatm1r1/5nfd9x2cqVKzVt2jR9+OGHdgWNbt262b5u3ry5QkNDFRQUpNWrV2vw4MGlEWqJCA4OVnBwsO31HXfcoaNHj2rOnDl66623SjGysqvMJq1jxozRoEGDCu1Tv359+fv769SpU3btly5d0tmzZ+Xv71/k+4WGhkqSjhw5ogYNGsjf3z/PJwxTUlIkyaFxi+NGzP3cuXPq2rWrqlSpojVr1qh8+fKF9g8NDdWMGTOUlZV1wx+XV6NGDbm7u9u+/1ekpKQUOE9/f/9C+1/5Z0pKigICAuz6hISElGD016c4c79i1qxZev755/X555+refPmhfatX7++atSooSNHjlgmebmeuV9Rvnx5tWzZUkeOHJFUNt73zMxMrVq1StOnT7/mfaz4vhdHQT/v3t7eqlChgtzd3a/73yWrW7VqlYYMGaJ33303z1KJP/L19dUtt9xi+7n4M2nbtq22b98uqWR+h8AxZXZNa82aNdW4ceNCDw8PD4WFhSk1NVXx8fG2a7ds2aLc3FxbIloUCQkJkmT7D1lYWJj2799vlxRu2rRJ3t7eatq0aclMsgDOnnt6erq6dOkiDw8PffTRR3m2BMpPQkKCqlatWirPd/bw8FDr1q21efNmW1tubq42b95sV1W7WlhYmF1/6fL7d6V/vXr15O/vb9cnPT1du3btKnDM0lCcuUvSzJkzNWPGDG3YsMFuzXNBfv75Z505c8YukSttxZ371XJycrR//37bvP7s77t0eau3rKwsPfTQQ9e8jxXf9+K41s97Sfy7ZGVvv/22oqKi9Pbbb9ttcVaQjIwMHT161OXf9/wkJCTY5vVnf98tqbQ/CeYKunbtarZs2dLctWuXuX37drNRo0Z22z79/PPPZnBwsLlr1y7TNE3zyJEj5vTp0809e/aYiYmJ5ocffmjWr1/fbNeune2aK1tedenSxUxISDA3bNhg1qxZ05JbXjky97S0NDM0NNRs1qyZeeTIEbttQi5dumSapml+9NFH5htvvGHu37/fPHz4sPnqq6+aFStWNCdPnlwqczTNy9uWeHp6mkuXLjV/+OEHc9iwYaavr69td4d//OMf5oQJE2z9v/rqK7NcuXLmrFmzzAMHDphTpkzJd8srX19f88MPPzS//fZbs0ePHpbd+siRuT///POmh4eH+d5779m9v+fOnTNN0zTPnTtnjh071oyLizMTExPNzz//3GzVqpXZqFEj88KFC6Uyx4I4Ovdp06aZGzduNI8ePWrGx8eb/fr1M728vMzvv//e1ufP+r5fcdddd5l9+/bN0+5K7/u5c+fMffv2mfv27TMlmbNnzzb37dtn/vTTT6ZpmuaECRPMf/zjH7b+V7a8euKJJ8wDBw6Y8+fPz3fLq8K+n1bh6NxXrFhhlitXzpw/f77dz3tqaqqtz5gxY8zY2FgzMTHR/Oqrr8zw8HCzRo0a5qlTp274/Arj6NznzJljrl271jx8+LC5f/9+c+TIkaabm5v5+eef2/q4yvv+Z0HSWgRnzpwx+/fvb1auXNn09vY2o6KibP+BNk3TTExMNCWZX3zxhWmapnn8+HGzXbt2ZrVq1UxPT0+zYcOG5hNPPGG3T6tpmuaxY8fMbt26mRUqVDBr1Khhjhkzxm5bKCtwdO5XtgjJ70hMTDRN8/K2WSEhIWblypXNSpUqmS1atDAXLlxot/ddaXjllVfMOnXqmB4eHmbbtm3NnTt32s61b9/ejIyMtOu/evVq85ZbbjE9PDzMW2+91Vy/fr3d+dzcXHPSpEmmn5+f6enpaXbq1Mk8dOjQjZiKwxyZe1BQUL7v75QpU0zTNM3z58+bXbp0MWvWrGmWL1/eDAoKMocOHWrZX+KOzH3UqFG2vn5+fua9995rt1+laf5533fTNM2DBw+akszPPvssz1iu9L4X9HvqynwjIyPN9u3b57kmJCTE9PDwMOvXr2+3P+0VhX0/rcLRubdv377Q/qZ5efuvgIAA08PDw7zpppvMvn37mkeOHLmxEysCR+f+wgsvmA0aNDC9vLzMatWqmR06dDC3bNmSZ1xXeN//LAzTLKV9hgAAAIAiKrNrWgEAAOA6SFoBAABgeSStAAAAsDySVgAAAFgeSSsAAAAsj6QVAAAAlkfSCgAAAMsjaQUAAIDlkbQC+NMZNGiQevbsaXvdoUMHjRo16obHERsbK8MwlJqaWmAfwzC0du3aIo85depUhYSEXFdcx44dk2EYSkhIuK5xAOBGImkFcEMMGjRIhmHIMAx5eHioYcOGmj59ui5duuT0e3/wwQeaMWNGkfoWJdEEANx45Uo7AABlR9euXbVkyRJlZWXpk08+0fDhw1W+fHlNnDgxT9/s7Gx5eHiUyH2rVatWIuMAAEoPlVYAN4ynp6f8/f0VFBSkRx55ROHh4froo48k/e+v9J999lkFBgYqODhYknTixAn16dNHvr6+qlatmnr06KFjx47ZxszJyVF0dLR8fX1VvXp1jRs3TqZp2t33j8sDsrKyNH78eNWuXVuenp5q2LChFi1apGPHjqljx46SpKpVq8owDA0aNEiSlJubq5iYGNWrV08VKlRQixYt9N5779nd55NPPtEtt9yiChUqqGPHjnZxFtX48eN1yy23qGLFiqpfv74mTZqkixcv5un32muvqXbt2qpYsaL69OmjtLQ0u/NvvvmmmjRpIi8vLzVu3Fivvvqqw7EAgJWQtAIoNRUqVFB2drbt9ebNm3Xo0CFt2rRJH3/8sS5evKiIiAhVqVJFX375pb766itVrlxZXbt2tV330ksvaenSpVq8eLG2b9+us2fPas2aNYXed+DAgXr77bc1b948HThwQK+99poqV66s2rVr6/3335ckHTp0SElJSXr55ZclSTExMVq+fLkWLlyo77//XqNHj9ZDDz2krVu3SrqcXPfq1Uv333+/EhISNGTIEE2YMMHh70mVKlW0dOlS/fDDD3r55Zf1xhtvaM6cOXZ9jhw5otWrV2vdunXasGGD9u3bp0cffdR2fsWKFZo8ebKeffZZHThwQM8995wmTZqkZcuWORwPAFiGCQA3QGRkpNmjRw/TNE0zNzfX3LRpk+np6WmOHTvWdt7Pz8/MysqyXfPWW2+ZwcHBZm5urq0tKyvLrFChgrlx40bTNE0zICDAnDlzpu38xYsXzZtvvtl2L9M0zfbt25sjR440TdM0Dx06ZEoyN23alG+cX3zxhSnJ/O2332xtFy5cMCtWrGju2LHDru/gwYPN/v37m6ZpmhMnTjSbNm1qd378+PF5xvojSeaaNWsKPP/iiy+arVu3tr2eMmWK6e7ubv7888+2tk8//dR0c3Mzk5KSTNM0zQYNGpgrV660G2fGjBlmWFiYaZqmmZiYaEoy9+3bV+B9AcBqWNMK4Ib5+OOPVblyZV28eFG5ubl68MEHNXXqVNv5Zs2a2a1j/eabb3TkyBFVqVLFbpwLFy7o6NGjSktLU1JSkkJDQ23nypUrpzZt2uRZInBFQkKC3N3d1b59+yLHfeTIEZ0/f16dO3e2a8/OzlbLli0lSQcOHLCLQ5LCwsKKfI8r3nnnHc2bN09Hjx5VRkaGLl26JG9vb7s+derU0U033WR3n9zcXB06dEhVqlTR0aNHNXjwYA0dOtTW59KlS/Lx8XE4HgCwCpJWADdMx44dtWDBAnl4eCgwMFDlytn/CqpUqZLd64yMDLVu3VorVqzIM1bNmjWLFUOFChUcviYjI0OStH79ertkUbq8TrekxMXFacCAAZo2bZoiIiLk4+OjVatW6aWXXnI41jfeeCNPEu3u7l5isQLAjUbSCuCGqVSpkho2bFjk/q1atdI777yjWrVq5ak2XhEQEKBdu3apXbt2ki5XFOPj49WqVat8+zdr1ky5ubnaunWrwsPD85y/UunNycmxtTVt2lSenp46fvx4gRXaJk2a2D5UdsXOnTuvPcmr7NixQ0FBQXrqqadsbT/99FOefsePH9fJkycVGBhou4+bm5uCg4Pl5+enwMBA/fjjjxowYIBD9wcAK+ODWAAsa8CAAapRo4Z69OihL7/8UomJiYqNjdXjjz+un3/+WZI0cuRIPf/881q7dq0OHjyoRx99tNA9VuvWravIyEj985//1Nq1a21jrl69WpIUFBQkwzD08ccf6/Tp08rIyFCVKlU0duxYjR49WsuWLdPRo0e1d+9evfLKK7YPNz388MM6fPiwnnjiCR06dEgrV67U0qVLHZpvo0aNdPz4ca1atUpHjx7VvHnz8v1QmZeXlyIjI/XNN9/oyy+/1OOPP64+ffrI399fkjRt2jTFxMRo3rx5+s9//qP9+/dryZIlmj17tkPxAICVkLQCsKyKFStq27ZtqlOnjnr16qUmTZpo8ODBunDhgq3yOmbMGP3jH/9QZGSkwsLCVKVKFf31r38tdNwFCxbob3/7mx599FE1btxYQ4cOVWZmpiTppptu0rRp0zRhwgT5+flpxIgRkqQZM2Zo0qRJiomJUZMmTdS1a1etX79e9erVk3R5nen777+vtWvXqkWLFlq4cKGee+45h+b7wAMPaPTo0RoxYoRCQkK0Y8cOTZo0KU+/hg0bqlevXrr33nvVpUsXNW/e3G5LqyFDhujNN9/UkiVL1KxZM7Vv315Lly61xQoArsgwC/q0AgAAAGARVFoBAABgeSStAAAAsDySVgAAAFgeSSsAAAAsj6QVAAAAlkfSCgAAAMsjaQUAAIDlkbQCAADA8khaAQAAYHkkrQAAALA8klYAAABYHkkrAAAALO//AaGqpW16/2JNAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "############# plot confusion matrix ############\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import metrics\n",
    "\n",
    "cm = metrics.confusion_matrix(y_test, test_preds_Ada.round())\n",
    "# Plot confusion matrix with custom color map\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.imshow(cm, interpolation='nearest', cmap=plt.cm.PuRd)  # Set cmap to custom color map\n",
    "plt.title('Confusion Matrix')\n",
    "plt.colorbar()\n",
    "\n",
    "# Adding annotations\n",
    "thresh = cm.max() / 2.\n",
    "for i in range(cm.shape[0]):\n",
    "    for j in range(cm.shape[1]):\n",
    "        plt.text(j, i, format(cm[i, j], 'd'), #'d = integer\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.tight_layout() #improves the layout of plots by preventing overlapping elements such as axis labels, tick labels, and titles\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ############# validaition_curve #####################\n",
    "# from sklearn.model_selection import ValidationCurveDisplay\n",
    "# ValidationCurveDisplay.from_estimator(\n",
    "#    AdaBoostClassifier(**trial.params), compressed_dataset_X, label, param_name=\"n_estimators\", param_range=range(50,500,10)\n",
    "# )\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
